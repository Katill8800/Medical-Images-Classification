{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1d4922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc4f8192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization\n",
    "\n",
    "# Set TensorFlow logging verbosity\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ddad01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000108 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000109 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000109 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000109 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000112 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000113 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000114 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000114.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000115 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000115 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000115.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000116 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000116 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000116 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000117 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000117 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000117.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000118 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000118 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000119 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000119 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000119 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000120.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000121 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000121 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000121.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000122 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000122.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000123 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000123 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000123 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000124 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000124 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000125 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000125 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000125 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000125 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000125 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000126 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000127 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000128 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000129 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000129.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000130 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000131 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000132 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000132 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000132 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000132.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000133 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000133 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000134 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000134 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000134.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000135 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000136 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000136 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000137 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000137 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000137 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000138 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000138 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000139 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000139 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000139 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000139 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000139.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000140.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000141 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000142.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000143 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000143 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000144 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000144 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000145 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000146 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000146 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000147.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000148 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000148 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000148 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000148.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000149 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000149 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000149 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000151 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000153 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000155 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000155.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000156 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000157 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000157 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000158 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000158 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000158 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000158 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000158.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000160 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000160 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000161 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000161 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000163 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000163 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000164 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000165 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000166 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000166 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000166 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000167 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000167 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000168 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000171 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000171.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000172 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000173 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000173 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000174 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000176 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000177 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\adenocarcinoma\\000177.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000108.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000110.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000111 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000111.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000113 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000113.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000114.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000115 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000116.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000118.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000120.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000122.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000123.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000124 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000126.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000127 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000128 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000128.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000130.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000131 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000131.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000132 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000133 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000133.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000136 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000137.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000138 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000141.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000143.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000147 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000148 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000148.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000149.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000150.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000154 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000154.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000155.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000158.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000159 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000159.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000160.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000162.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000163.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000169.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000170.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000171.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000172 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000172.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000173 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000173.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\large.cell.carcinoma\\000174.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\10.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\11.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\12 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\21.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\22.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\23.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\24 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\24.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\25.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\6.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\7.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\8.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\normal - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\normal\\normal.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000108 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000110 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000111.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000112.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000114 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000114 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000115 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000115 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000116 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000117 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000117 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000117 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000118 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000118 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000119 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000119.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000120 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000120 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000120 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000121 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000121.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000122 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000122.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000124 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000124 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000124.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000125 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000125 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000125.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000126 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000127 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000127 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000127.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000129 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000129 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000130 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000131 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000132 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000133 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000133 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000134 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000135 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000135.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000136 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000136 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000137 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000137.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000139 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000139 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000139 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000141 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000141 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000142 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000142 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000144 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000145 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000146 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000148 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000148 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000149 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000151 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000151.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000153 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000153 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000153.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000154 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000154 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000154 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000155 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000155.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000156 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000157 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000158 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000158 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000159 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000160 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000162 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000162.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000163 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000163 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000163 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000164 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000166 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000167 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000168 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000169 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000170 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000172 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000174 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\test\\squamous.cell.carcinoma\\000177 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000000 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000005 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000005 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000008 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000009 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000009 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000013 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000013 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000014 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000015 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000015 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000015 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000016 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000017 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000017 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000018 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000019 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000020 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000020 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000020 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000021 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000021 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000021 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000021 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000021 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000022 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000022 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000022 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000022 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000022.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000023 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000023 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000023 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000023 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000024 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000024 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000024 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000024.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000025 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000026 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000026 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000027 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000027 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000029 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000029 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000029 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000030 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000031 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000032 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000033 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000034 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000035 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000035 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000035 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000035 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000036 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000036 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000040 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000040 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000040 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000041 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000041 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000041 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000041 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000042 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000044 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000044 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000046 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000048 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000048.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000049 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000049 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000050 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000050 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000050 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000050 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000051 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000051 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000052 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000054 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000054 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000054 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000054.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000055 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000056 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000057 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000057.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000058 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000058 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000059 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000061.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000063 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000063 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000063 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000065 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000065 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000065 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000066 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000066 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000067 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000067.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000068 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000068 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000068 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000069 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000071 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000072 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000074 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000075 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000077 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000077 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000078 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000079 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000080 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000080 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000081 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000083 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000083 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000084 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000084 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000084 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000084.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000085 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000085 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000085 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000086 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000086 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000087 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000087 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000089 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000090 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000091 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000091 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000091.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000092 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000093 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000093 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000093 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000095 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000095.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000096 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000097 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000097 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000097 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000098 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000098 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000099 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000100 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000101 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000102 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000102 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000102 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000102.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000103 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000104 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000104 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000105 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000105 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000105.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000106 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000106 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000106 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000107 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000118 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000118 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000119 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000119 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000119 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000119 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000121 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000121 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000121.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000122.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad1.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad10.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad11.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad12.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad13.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad14.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad15.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad16.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad17.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad18.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad19.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad2.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad20.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad21.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad22.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad3.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad4.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad5.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad6.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad7.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad8.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\ad9.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000002.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000003 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000003 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000009 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000009 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000010.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000015.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000016 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000016 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000017.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000018 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000019 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000019 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000020 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000020 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000021.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000023 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000024 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000026 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000026.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000027 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000027.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000031 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000031.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000032.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000033 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000033 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000034 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000039 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000039 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000040 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000041 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000041 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000041.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000042 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000043 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000045.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000046.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000047 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000051.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000055 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000055 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000055.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000056 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000056 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000057 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000057 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000057.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000058 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000058 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000059 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000059 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000060.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000062 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000062 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000062 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000062.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000063 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000063.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000065 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000066 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000066.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000068 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000068 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000068.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000069.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000071 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000072 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000073 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000076 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000076 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000077.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000078 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000078 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000080.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000081.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000084 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000084.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000089.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000093 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000093 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000094 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000094 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000094 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000095 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000095 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000095 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000095.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000097 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000097.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000098 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000098 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000104 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000104.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000105 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000105.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000106 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000106.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000133.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000137.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000143.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000149.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000150.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000154.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000159.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000169.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000172.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000173.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\di1.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\l1.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\l2.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\l3.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\l4.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\l5.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\l6.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\10.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\11.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\12.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\13.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\16.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\17.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\18.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\19.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\2.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\20.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\21 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\21 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\21 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\21 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\3.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\4.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\5.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\6.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\7.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 - Copy - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\8.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n6 (2) - Copy.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n6 (2).jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n6 - Copy.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n6.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n7 (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n7 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n7 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n7.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n8 (2) - Copy.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n8 (2).jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n8 - Copy.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n8.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n9 (2) - Copy.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n9 (2).jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n9 - Copy.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\normal\\n9.jpg\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000002 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000002 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000003.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000004 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000004 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000004 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000006 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000006.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000007 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000007.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000008 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000009 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000010 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000013 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000015 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000015 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000016 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000017 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000018 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000024 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000024 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000027 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000028 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000028 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000028 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000029 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000030 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000030 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000030 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000032.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000033.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000035 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000035.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000036 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000037 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000038 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000038 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000038 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000041 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000043 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000043.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000044 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000046 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000046 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000046 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000046 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000048 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000048 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000048.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000049 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000050 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000050 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000051 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000052 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000053 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000053.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000054 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000054.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000055 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000055 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000056 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000056 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000057 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000057 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000057 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000057 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000057 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000058 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000058 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000058 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000058.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000060 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000062 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000062 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000063 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000063 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000063.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000064 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000065 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000065 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000066 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000066.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000067 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000067 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000067 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000067 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000068 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000069 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000070 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000070.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000071 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000073 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000074 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000074 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000074 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000075.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000077 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000077 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000077 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000078 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000078 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000078.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000079 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000079 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000079.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000081 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000081 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000081.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000082 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000082 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000083 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000083 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000083 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000083 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000084 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000084 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000084 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000085.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000088.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000089 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000090 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000091 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000091 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000093.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000094 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000094.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000096 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000096.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000099 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000099 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000100 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000101 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000103.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000104 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000104.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000105 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000105 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000106 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000106 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000106 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000106 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000106 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000120 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000120 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000120 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000121 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000121.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000122 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000122.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\sq1.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\sq2.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\sq3.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\sq4.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\sq5.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\train\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\sq6.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000108 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000108 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000109 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000109 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000109 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000110 (7).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000111 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000112 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000112 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000113 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000113.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000114 (10).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000114.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000115 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000115 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000115 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000115.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000116 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000116 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000116 (8).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000116 (9).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000117 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib\\000117.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000108 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000108.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000109.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000110 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000110.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000111 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000111.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000112.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000113 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000113.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000114.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000115 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000115.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000116.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000118 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000120.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000122.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000126.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000128.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000130.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa\\000131.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\003828_02_01_174.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\004007_01_01_519.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\004162_01_01_150.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\4 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\4 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\5.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\6 - Copy (2) - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\6 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\6 - Copy.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\7 - Copy (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\7 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\7.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\normal\\8 - Copy (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000108 (3).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000110 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000111.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000112.png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000114 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000114 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000115 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000115 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000116 (2).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000117 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000117 (6).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000118 (4).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000118 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000119 (5).png\n",
      "C:/Users/Admin/Downloads/archive (1)/Data\\valid\\squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa\\000119.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Specify the directory you want to walk through\n",
    "directory = \"C:/Users/Admin/Downloads/archive (1)/Data\"  # Adjust this path as needed\n",
    "\n",
    "# Walk through the directory and print the filenames\n",
    "for dirname, _, filenames in os.walk(\"C:/Users/Admin/Downloads/archive (1)/Data\"):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82791297",
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_paths(dir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    folds = os.listdir(dir)\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "    return filepaths, labels\n",
    "def define_df(files, classes):\n",
    "    Fseries = pd.Series(files, name= 'filepaths')\n",
    "    Lseries = pd.Series(classes, name='labels')\n",
    "    return pd.concat([Fseries, Lseries], axis= 1)\n",
    "\n",
    "def create_df(tr_dir, val_dir, ts_dir):\n",
    "    # train dataframe\n",
    "    files, classes = define_paths(tr_dir)\n",
    "    train_df = define_df(files, classes)\n",
    "    \n",
    "    # validation dataframe\n",
    "    files, classes = define_paths(val_dir)\n",
    "    valid_df = define_df(files, classes)\n",
    "    # test dataframe\n",
    "    files, classes = define_paths(ts_dir)\n",
    "    test_df = define_df(files, classes)\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ae93e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gens(train_df, valid_df, test_df, batch_size):\n",
    "    img_size = (224, 224)\n",
    "    channels = 3\n",
    "    img_shape = (img_size[0], img_size[1], channels)\n",
    "    ts_length = len(test_df)\n",
    "    test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "    test_steps = ts_length // test_batch_size\n",
    "    def scalar(img):\n",
    "        return img\n",
    "    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
    "    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
    "    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= True, batch_size= batch_size)\n",
    "    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                         color_mode= 'rgb', shuffle= False, batch_size= test_batch_size)\n",
    "    return train_gen, valid_gen, test_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "775b128f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 613 validated image filenames belonging to 4 classes.\n",
      "Found 72 validated image filenames belonging to 4 classes.\n",
      "Found 315 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get Dataframes\n",
    "train_dir = \"C:/Users/Admin/Downloads/archive (1)/Data/train\"\n",
    "test_dir = \"C:/Users/Admin/Downloads/archive (1)/Data/test\"\n",
    "valid_dir = \"C:/Users/Admin/Downloads/archive (1)/Data/valid\"\n",
    "train_df, valid_df, test_df = create_df(train_dir, valid_dir, test_dir)\n",
    "\n",
    "# Get Generators\n",
    "batch_size = 40\n",
    "train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e131417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>C:/Users/Admin/Downloads/archive (1)/Data/trai...</td>\n",
       "      <td>squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>613 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             filepaths  \\\n",
       "0    C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "1    C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "2    C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "3    C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "4    C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "..                                                 ...   \n",
       "608  C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "609  C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "610  C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "611  C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "612  C:/Users/Admin/Downloads/archive (1)/Data/trai...   \n",
       "\n",
       "                                               labels  \n",
       "0          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "1          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "2          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "3          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "4          adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib  \n",
       "..                                                ...  \n",
       "608  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "609  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "610  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "611  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "612  squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa  \n",
       "\n",
       "[613 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1498b8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.1788 - accuracy: 0.5824\n",
      "Epoch 1: val_accuracy improved from -inf to 0.50000, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 88s 4s/step - loss: 1.1788 - accuracy: 0.5824 - val_loss: 2.7958 - val_accuracy: 0.5000\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4518 - accuracy: 0.8303\n",
      "Epoch 2: val_accuracy did not improve from 0.50000\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.4518 - accuracy: 0.8303 - val_loss: 1.9664 - val_accuracy: 0.4861\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8467\n",
      "Epoch 3: val_accuracy improved from 0.50000 to 0.58333, saving model to best_model.h5\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.4161 - accuracy: 0.8467 - val_loss: 2.2706 - val_accuracy: 0.5833\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3137 - accuracy: 0.8777\n",
      "Epoch 4: val_accuracy did not improve from 0.58333\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.3137 - accuracy: 0.8777 - val_loss: 1.3213 - val_accuracy: 0.5694\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2336 - accuracy: 0.9152\n",
      "Epoch 5: val_accuracy improved from 0.58333 to 0.62500, saving model to best_model.h5\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.2336 - accuracy: 0.9152 - val_loss: 1.1287 - val_accuracy: 0.6250\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2176 - accuracy: 0.9184\n",
      "Epoch 6: val_accuracy improved from 0.62500 to 0.66667, saving model to best_model.h5\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.2176 - accuracy: 0.9184 - val_loss: 1.1352 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1723 - accuracy: 0.9396\n",
      "Epoch 7: val_accuracy did not improve from 0.66667\n",
      "16/16 [==============================] - 51s 3s/step - loss: 0.1723 - accuracy: 0.9396 - val_loss: 0.8108 - val_accuracy: 0.6667\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1238 - accuracy: 0.9560\n",
      "Epoch 8: val_accuracy improved from 0.66667 to 0.73611, saving model to best_model.h5\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.1238 - accuracy: 0.9560 - val_loss: 0.8334 - val_accuracy: 0.7361\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1370 - accuracy: 0.9429\n",
      "Epoch 9: val_accuracy improved from 0.73611 to 0.76389, saving model to best_model.h5\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.1370 - accuracy: 0.9429 - val_loss: 0.6209 - val_accuracy: 0.7639\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1217 - accuracy: 0.9527\n",
      "Epoch 10: val_accuracy improved from 0.76389 to 0.80556, saving model to best_model.h5\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.1217 - accuracy: 0.9527 - val_loss: 0.5624 - val_accuracy: 0.8056\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1148 - accuracy: 0.9592\n",
      "Epoch 11: val_accuracy improved from 0.80556 to 0.88889, saving model to best_model.h5\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.1148 - accuracy: 0.9592 - val_loss: 0.4790 - val_accuracy: 0.8889\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1188 - accuracy: 0.9592\n",
      "Epoch 12: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.1188 - accuracy: 0.9592 - val_loss: 0.5205 - val_accuracy: 0.8611\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9674\n",
      "Epoch 13: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.1052 - accuracy: 0.9674 - val_loss: 0.5762 - val_accuracy: 0.8750\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0675 - accuracy: 0.9772\n",
      "Epoch 14: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0675 - accuracy: 0.9772 - val_loss: 0.6765 - val_accuracy: 0.8333\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9543\n",
      "Epoch 15: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.1098 - accuracy: 0.9543 - val_loss: 0.6124 - val_accuracy: 0.8194\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1081 - accuracy: 0.9641\n",
      "Epoch 16: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.1081 - accuracy: 0.9641 - val_loss: 0.4805 - val_accuracy: 0.8472\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0960 - accuracy: 0.9641\n",
      "Epoch 17: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0960 - accuracy: 0.9641 - val_loss: 0.4954 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0823 - accuracy: 0.9788\n",
      "Epoch 18: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0823 - accuracy: 0.9788 - val_loss: 0.5497 - val_accuracy: 0.8472\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1071 - accuracy: 0.9608\n",
      "Epoch 19: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.1071 - accuracy: 0.9608 - val_loss: 0.5803 - val_accuracy: 0.8611\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.9674\n",
      "Epoch 20: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0907 - accuracy: 0.9674 - val_loss: 0.5154 - val_accuracy: 0.8472\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0816 - accuracy: 0.9674\n",
      "Epoch 21: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0816 - accuracy: 0.9674 - val_loss: 0.5040 - val_accuracy: 0.8333\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0880 - accuracy: 0.9723\n",
      "Epoch 22: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0880 - accuracy: 0.9723 - val_loss: 0.4521 - val_accuracy: 0.8611\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1315 - accuracy: 0.9543\n",
      "Epoch 23: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.1315 - accuracy: 0.9543 - val_loss: 0.5005 - val_accuracy: 0.8750\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0736 - accuracy: 0.9804\n",
      "Epoch 24: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0736 - accuracy: 0.9804 - val_loss: 0.5310 - val_accuracy: 0.8750\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9804\n",
      "Epoch 25: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0574 - accuracy: 0.9804 - val_loss: 0.4509 - val_accuracy: 0.8889\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0885 - accuracy: 0.9706\n",
      "Epoch 26: val_accuracy improved from 0.88889 to 0.90278, saving model to best_model.h5\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0885 - accuracy: 0.9706 - val_loss: 0.4209 - val_accuracy: 0.9028\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9788\n",
      "Epoch 27: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0701 - accuracy: 0.9788 - val_loss: 0.4684 - val_accuracy: 0.8194\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0853 - accuracy: 0.9739\n",
      "Epoch 28: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0853 - accuracy: 0.9739 - val_loss: 0.6393 - val_accuracy: 0.8472\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9641\n",
      "Epoch 29: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.0928 - accuracy: 0.9641 - val_loss: 0.6288 - val_accuracy: 0.8194\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9723\n",
      "Epoch 30: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0852 - accuracy: 0.9723 - val_loss: 0.5401 - val_accuracy: 0.8889\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9755\n",
      "Epoch 31: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0605 - accuracy: 0.9755 - val_loss: 0.5494 - val_accuracy: 0.8611\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9853\n",
      "Epoch 32: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0411 - accuracy: 0.9853 - val_loss: 0.6068 - val_accuracy: 0.8472\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9739\n",
      "Epoch 33: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0742 - accuracy: 0.9739 - val_loss: 0.6237 - val_accuracy: 0.8194\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0611 - accuracy: 0.9788\n",
      "Epoch 34: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0611 - accuracy: 0.9788 - val_loss: 0.6220 - val_accuracy: 0.8472\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9772\n",
      "Epoch 35: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0754 - accuracy: 0.9772 - val_loss: 0.5941 - val_accuracy: 0.8611\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9772\n",
      "Epoch 36: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0635 - accuracy: 0.9772 - val_loss: 0.6140 - val_accuracy: 0.8333\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0971 - accuracy: 0.9706\n",
      "Epoch 37: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0971 - accuracy: 0.9706 - val_loss: 0.7230 - val_accuracy: 0.7917\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1174 - accuracy: 0.9625\n",
      "Epoch 38: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.1174 - accuracy: 0.9625 - val_loss: 0.5314 - val_accuracy: 0.8750\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0642 - accuracy: 0.9739\n",
      "Epoch 39: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0642 - accuracy: 0.9739 - val_loss: 0.5906 - val_accuracy: 0.8611\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0577 - accuracy: 0.9821\n",
      "Epoch 40: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0577 - accuracy: 0.9821 - val_loss: 0.6435 - val_accuracy: 0.8333\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0783 - accuracy: 0.9706\n",
      "Epoch 41: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0783 - accuracy: 0.9706 - val_loss: 0.6305 - val_accuracy: 0.8889\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0839 - accuracy: 0.9723\n",
      "Epoch 42: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0839 - accuracy: 0.9723 - val_loss: 0.5609 - val_accuracy: 0.8333\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9755\n",
      "Epoch 43: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0699 - accuracy: 0.9755 - val_loss: 0.5712 - val_accuracy: 0.8889\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0666 - accuracy: 0.9723\n",
      "Epoch 44: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0666 - accuracy: 0.9723 - val_loss: 0.5670 - val_accuracy: 0.8889\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9821\n",
      "Epoch 45: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0595 - accuracy: 0.9821 - val_loss: 0.5210 - val_accuracy: 0.8750\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0616 - accuracy: 0.9837\n",
      "Epoch 46: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.0616 - accuracy: 0.9837 - val_loss: 0.5191 - val_accuracy: 0.9028\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0690 - accuracy: 0.9821\n",
      "Epoch 47: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0690 - accuracy: 0.9821 - val_loss: 0.5531 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9853\n",
      "Epoch 48: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0280 - accuracy: 0.9853 - val_loss: 0.5395 - val_accuracy: 0.8889\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0485 - accuracy: 0.9804\n",
      "Epoch 49: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0485 - accuracy: 0.9804 - val_loss: 0.5385 - val_accuracy: 0.8750\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9853\n",
      "Epoch 50: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0413 - accuracy: 0.9853 - val_loss: 0.5465 - val_accuracy: 0.8750\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0600 - accuracy: 0.9853\n",
      "Epoch 51: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0600 - accuracy: 0.9853 - val_loss: 0.4702 - val_accuracy: 0.8750\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0466 - accuracy: 0.9853\n",
      "Epoch 52: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0466 - accuracy: 0.9853 - val_loss: 0.4575 - val_accuracy: 0.8889\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9853\n",
      "Epoch 53: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0525 - accuracy: 0.9853 - val_loss: 0.5286 - val_accuracy: 0.8611\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9902\n",
      "Epoch 54: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0337 - accuracy: 0.9902 - val_loss: 0.5149 - val_accuracy: 0.8750\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0518 - accuracy: 0.9821\n",
      "Epoch 55: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.0518 - accuracy: 0.9821 - val_loss: 0.7111 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0354 - accuracy: 0.9837\n",
      "Epoch 56: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0354 - accuracy: 0.9837 - val_loss: 0.5568 - val_accuracy: 0.9028\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0442 - accuracy: 0.9869\n",
      "Epoch 57: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 0.5238 - val_accuracy: 0.9028\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9869\n",
      "Epoch 58: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0349 - accuracy: 0.9869 - val_loss: 0.5470 - val_accuracy: 0.8611\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9853\n",
      "Epoch 59: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0444 - accuracy: 0.9853 - val_loss: 0.5132 - val_accuracy: 0.9028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9837\n",
      "Epoch 60: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0365 - accuracy: 0.9837 - val_loss: 0.5737 - val_accuracy: 0.8472\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0614 - accuracy: 0.9804\n",
      "Epoch 61: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0614 - accuracy: 0.9804 - val_loss: 0.5234 - val_accuracy: 0.8750\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9837\n",
      "Epoch 62: val_accuracy improved from 0.90278 to 0.91667, saving model to best_model.h5\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0496 - accuracy: 0.9837 - val_loss: 0.4801 - val_accuracy: 0.9167\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0694 - accuracy: 0.9821\n",
      "Epoch 63: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0694 - accuracy: 0.9821 - val_loss: 0.5411 - val_accuracy: 0.9028\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9951\n",
      "Epoch 64: val_accuracy improved from 0.91667 to 0.93056, saving model to best_model.h5\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.4635 - val_accuracy: 0.9306\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9821\n",
      "Epoch 65: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0582 - accuracy: 0.9821 - val_loss: 0.4364 - val_accuracy: 0.8889\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0472 - accuracy: 0.9886\n",
      "Epoch 66: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0472 - accuracy: 0.9886 - val_loss: 0.3579 - val_accuracy: 0.9306\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0376 - accuracy: 0.9886\n",
      "Epoch 67: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0376 - accuracy: 0.9886 - val_loss: 0.3733 - val_accuracy: 0.9167\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9853\n",
      "Epoch 68: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0362 - accuracy: 0.9853 - val_loss: 0.4732 - val_accuracy: 0.9167\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0430 - accuracy: 0.9869\n",
      "Epoch 69: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0430 - accuracy: 0.9869 - val_loss: 0.5059 - val_accuracy: 0.8889\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9772\n",
      "Epoch 70: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 50s 3s/step - loss: 0.0404 - accuracy: 0.9772 - val_loss: 0.7291 - val_accuracy: 0.8611\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0574 - accuracy: 0.9853\n",
      "Epoch 71: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0574 - accuracy: 0.9853 - val_loss: 0.6766 - val_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0321 - accuracy: 0.9886\n",
      "Epoch 72: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0321 - accuracy: 0.9886 - val_loss: 0.5837 - val_accuracy: 0.8750\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9869\n",
      "Epoch 73: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0320 - accuracy: 0.9869 - val_loss: 0.4726 - val_accuracy: 0.8889\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9902\n",
      "Epoch 74: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0284 - accuracy: 0.9902 - val_loss: 0.5689 - val_accuracy: 0.8750\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9918\n",
      "Epoch 75: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0319 - accuracy: 0.9918 - val_loss: 0.5369 - val_accuracy: 0.8750\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9853\n",
      "Epoch 76: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0487 - accuracy: 0.9853 - val_loss: 0.7001 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0622 - accuracy: 0.9837\n",
      "Epoch 77: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0622 - accuracy: 0.9837 - val_loss: 0.5384 - val_accuracy: 0.8889\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0652 - accuracy: 0.9837\n",
      "Epoch 78: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0652 - accuracy: 0.9837 - val_loss: 0.4847 - val_accuracy: 0.9306\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9935\n",
      "Epoch 79: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0236 - accuracy: 0.9935 - val_loss: 0.4482 - val_accuracy: 0.9167\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9886\n",
      "Epoch 80: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0258 - accuracy: 0.9886 - val_loss: 0.4483 - val_accuracy: 0.8750\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0255 - accuracy: 0.9935\n",
      "Epoch 81: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0255 - accuracy: 0.9935 - val_loss: 0.4500 - val_accuracy: 0.9167\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9869\n",
      "Epoch 82: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0620 - accuracy: 0.9869 - val_loss: 0.5196 - val_accuracy: 0.9028\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9951\n",
      "Epoch 83: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0338 - accuracy: 0.9951 - val_loss: 0.5464 - val_accuracy: 0.8889\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9902\n",
      "Epoch 84: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0246 - accuracy: 0.9902 - val_loss: 0.6415 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9853\n",
      "Epoch 85: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0300 - accuracy: 0.9853 - val_loss: 0.5665 - val_accuracy: 0.8889\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0561 - accuracy: 0.9853\n",
      "Epoch 86: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0561 - accuracy: 0.9853 - val_loss: 0.5521 - val_accuracy: 0.9028\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9935\n",
      "Epoch 87: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 45s 3s/step - loss: 0.0353 - accuracy: 0.9935 - val_loss: 0.5268 - val_accuracy: 0.9306\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0437 - accuracy: 0.9853\n",
      "Epoch 88: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0437 - accuracy: 0.9853 - val_loss: 0.5211 - val_accuracy: 0.8889\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9902\n",
      "Epoch 89: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 49s 3s/step - loss: 0.0312 - accuracy: 0.9902 - val_loss: 0.6454 - val_accuracy: 0.8611\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0548 - accuracy: 0.9853\n",
      "Epoch 90: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0548 - accuracy: 0.9853 - val_loss: 0.7187 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0402 - accuracy: 0.9869\n",
      "Epoch 91: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0402 - accuracy: 0.9869 - val_loss: 0.6015 - val_accuracy: 0.8750\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9886\n",
      "Epoch 92: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0620 - accuracy: 0.9886 - val_loss: 0.4929 - val_accuracy: 0.8889\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9821\n",
      "Epoch 93: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 48s 3s/step - loss: 0.0552 - accuracy: 0.9821 - val_loss: 0.5989 - val_accuracy: 0.8750\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0284 - accuracy: 0.9886\n",
      "Epoch 94: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0284 - accuracy: 0.9886 - val_loss: 0.6201 - val_accuracy: 0.9167\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0700 - accuracy: 0.9755\n",
      "Epoch 95: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 47s 3s/step - loss: 0.0700 - accuracy: 0.9755 - val_loss: 0.5404 - val_accuracy: 0.9028\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9788\n",
      "Epoch 96: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0873 - accuracy: 0.9788 - val_loss: 0.5149 - val_accuracy: 0.9028\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9821\n",
      "Epoch 97: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0604 - accuracy: 0.9821 - val_loss: 0.5874 - val_accuracy: 0.8750\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0462 - accuracy: 0.9837\n",
      "Epoch 98: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0462 - accuracy: 0.9837 - val_loss: 0.5924 - val_accuracy: 0.8750\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0418 - accuracy: 0.9837\n",
      "Epoch 99: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0418 - accuracy: 0.9837 - val_loss: 0.7360 - val_accuracy: 0.9028\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0513 - accuracy: 0.9755\n",
      "Epoch 100: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 46s 3s/step - loss: 0.0513 - accuracy: 0.9755 - val_loss: 0.8511 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained model\n",
    "base_model = tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c703e593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 21s 3s/step - loss: 1.1636e-04 - accuracy: 1.0000\n",
      "5/5 [==============================] - 6s 660ms/step - loss: 0.4635 - accuracy: 0.9306\n",
      "5/5 [==============================] - 21s 4s/step - loss: 0.6652 - accuracy: 0.8317\n",
      "Train Loss:  0.00011636471026577055\n",
      "Train Accuracy:  1.0\n",
      "--------------------\n",
      "Validation Loss:  0.4635477066040039\n",
      "Validation Accuracy:  0.9305555820465088\n",
      "--------------------\n",
      "Test Loss:  0.6652371287345886\n",
      "Test Accuracy:  0.8317460417747498\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model.h5')\n",
    "\n",
    "ts_length = len(test_df)\n",
    "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3e72257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0362 - accuracy: 0.6754\n",
      "Epoch 1: val_accuracy improved from -inf to 0.63889, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 79s 4s/step - loss: 1.0362 - accuracy: 0.6754 - val_loss: 1.9495 - val_accuracy: 0.6389\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1730 - accuracy: 0.9347\n",
      "Epoch 2: val_accuracy did not improve from 0.63889\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.1730 - accuracy: 0.9347 - val_loss: 4.1284 - val_accuracy: 0.5417\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0876 - accuracy: 0.9608\n",
      "Epoch 3: val_accuracy did not improve from 0.63889\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0876 - accuracy: 0.9608 - val_loss: 2.0272 - val_accuracy: 0.6111\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0651 - accuracy: 0.9837\n",
      "Epoch 4: val_accuracy improved from 0.63889 to 0.76389, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0651 - accuracy: 0.9837 - val_loss: 1.1610 - val_accuracy: 0.7639\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0739 - accuracy: 0.9706\n",
      "Epoch 5: val_accuracy did not improve from 0.76389\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.0739 - accuracy: 0.9706 - val_loss: 1.1352 - val_accuracy: 0.7500\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0415 - accuracy: 0.9902\n",
      "Epoch 6: val_accuracy improved from 0.76389 to 0.80556, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0415 - accuracy: 0.9902 - val_loss: 0.9245 - val_accuracy: 0.8056\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9869\n",
      "Epoch 7: val_accuracy improved from 0.80556 to 0.88889, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.5893 - val_accuracy: 0.8889\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0517 - accuracy: 0.9886\n",
      "Epoch 8: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0517 - accuracy: 0.9886 - val_loss: 0.6372 - val_accuracy: 0.8333\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9935\n",
      "Epoch 9: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0320 - accuracy: 0.9935 - val_loss: 0.9867 - val_accuracy: 0.7917\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.9984\n",
      "Epoch 10: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0169 - accuracy: 0.9984 - val_loss: 0.7794 - val_accuracy: 0.8333\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0188 - accuracy: 0.9967\n",
      "Epoch 11: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0188 - accuracy: 0.9967 - val_loss: 0.7817 - val_accuracy: 0.8194\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0391 - accuracy: 0.9918\n",
      "Epoch 12: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0391 - accuracy: 0.9918 - val_loss: 0.7872 - val_accuracy: 0.8194\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9967\n",
      "Epoch 13: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0204 - accuracy: 0.9967 - val_loss: 0.6863 - val_accuracy: 0.8611\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9967\n",
      "Epoch 14: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0151 - accuracy: 0.9967 - val_loss: 0.6390 - val_accuracy: 0.8889\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9935\n",
      "Epoch 15: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0469 - accuracy: 0.9935 - val_loss: 0.6237 - val_accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0330 - accuracy: 0.9967\n",
      "Epoch 16: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0330 - accuracy: 0.9967 - val_loss: 0.7710 - val_accuracy: 0.8611\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0191 - accuracy: 0.9984\n",
      "Epoch 17: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0191 - accuracy: 0.9984 - val_loss: 0.7477 - val_accuracy: 0.8472\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9967\n",
      "Epoch 18: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0063 - accuracy: 0.9967 - val_loss: 0.6854 - val_accuracy: 0.8333\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9935\n",
      "Epoch 19: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0110 - accuracy: 0.9935 - val_loss: 0.6911 - val_accuracy: 0.8611\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0329 - accuracy: 0.9967\n",
      "Epoch 20: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0329 - accuracy: 0.9967 - val_loss: 0.6944 - val_accuracy: 0.8472\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0068 - accuracy: 0.9967\n",
      "Epoch 21: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0068 - accuracy: 0.9967 - val_loss: 0.7196 - val_accuracy: 0.8750\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0065 - accuracy: 0.9984\n",
      "Epoch 22: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0065 - accuracy: 0.9984 - val_loss: 0.6088 - val_accuracy: 0.8611\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0225 - accuracy: 0.9935\n",
      "Epoch 23: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0225 - accuracy: 0.9935 - val_loss: 0.5798 - val_accuracy: 0.8611\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0105 - accuracy: 0.9967\n",
      "Epoch 24: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0105 - accuracy: 0.9967 - val_loss: 0.5609 - val_accuracy: 0.8472\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9984\n",
      "Epoch 25: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.5254 - val_accuracy: 0.8472\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0258 - accuracy: 0.9984\n",
      "Epoch 26: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0258 - accuracy: 0.9984 - val_loss: 0.5508 - val_accuracy: 0.8611\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9984\n",
      "Epoch 27: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.5210 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9984\n",
      "Epoch 28: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0141 - accuracy: 0.9984 - val_loss: 0.5451 - val_accuracy: 0.8750\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9984\n",
      "Epoch 29: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0126 - accuracy: 0.9984 - val_loss: 0.5529 - val_accuracy: 0.8750\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9984\n",
      "Epoch 30: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0173 - accuracy: 0.9984 - val_loss: 0.5336 - val_accuracy: 0.8750\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9984\n",
      "Epoch 31: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0109 - accuracy: 0.9984 - val_loss: 0.5690 - val_accuracy: 0.8750\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9984\n",
      "Epoch 32: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0137 - accuracy: 0.9984 - val_loss: 0.5748 - val_accuracy: 0.8750\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9984\n",
      "Epoch 33: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0161 - accuracy: 0.9984 - val_loss: 0.5830 - val_accuracy: 0.8750\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0154 - accuracy: 0.9967\n",
      "Epoch 34: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0154 - accuracy: 0.9967 - val_loss: 0.4761 - val_accuracy: 0.8750\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0172 - accuracy: 0.9967\n",
      "Epoch 35: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0172 - accuracy: 0.9967 - val_loss: 0.4943 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9967\n",
      "Epoch 36: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0175 - accuracy: 0.9967 - val_loss: 0.4967 - val_accuracy: 0.8889\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0256 - accuracy: 0.9951\n",
      "Epoch 37: val_accuracy did not improve from 0.88889\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0256 - accuracy: 0.9951 - val_loss: 0.5052 - val_accuracy: 0.8750\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 1.0000\n",
      "Epoch 38: val_accuracy improved from 0.88889 to 0.90278, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 0.5134 - val_accuracy: 0.9028\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9967\n",
      "Epoch 39: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0060 - accuracy: 0.9967 - val_loss: 0.3746 - val_accuracy: 0.9028\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0110 - accuracy: 0.9984\n",
      "Epoch 40: val_accuracy did not improve from 0.90278\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0110 - accuracy: 0.9984 - val_loss: 0.3742 - val_accuracy: 0.9028\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy improved from 0.90278 to 0.91667, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9167\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0198 - accuracy: 0.9984\n",
      "Epoch 42: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0198 - accuracy: 0.9984 - val_loss: 0.5801 - val_accuracy: 0.8889\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9967\n",
      "Epoch 43: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0086 - accuracy: 0.9967 - val_loss: 0.5133 - val_accuracy: 0.8889\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0117 - accuracy: 0.9984\n",
      "Epoch 44: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0117 - accuracy: 0.9984 - val_loss: 0.3501 - val_accuracy: 0.9028\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0549 - accuracy: 0.9821\n",
      "Epoch 45: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0549 - accuracy: 0.9821 - val_loss: 0.4630 - val_accuracy: 0.8889\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9853\n",
      "Epoch 46: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 55s 4s/step - loss: 0.0362 - accuracy: 0.9853 - val_loss: 0.6188 - val_accuracy: 0.8611\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9821\n",
      "Epoch 47: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0567 - accuracy: 0.9821 - val_loss: 0.4362 - val_accuracy: 0.8611\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0449 - accuracy: 0.9902\n",
      "Epoch 48: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0449 - accuracy: 0.9902 - val_loss: 0.6668 - val_accuracy: 0.8472\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9837\n",
      "Epoch 49: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0648 - accuracy: 0.9837 - val_loss: 0.7272 - val_accuracy: 0.8333\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0949 - accuracy: 0.9723\n",
      "Epoch 50: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0949 - accuracy: 0.9723 - val_loss: 0.2865 - val_accuracy: 0.9028\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0357 - accuracy: 0.9886\n",
      "Epoch 51: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0357 - accuracy: 0.9886 - val_loss: 0.3994 - val_accuracy: 0.9167\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0403 - accuracy: 0.9918\n",
      "Epoch 52: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0403 - accuracy: 0.9918 - val_loss: 0.3768 - val_accuracy: 0.8750\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0280 - accuracy: 0.9967\n",
      "Epoch 53: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 63s 4s/step - loss: 0.0280 - accuracy: 0.9967 - val_loss: 0.4272 - val_accuracy: 0.9028\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0121 - accuracy: 0.9967\n",
      "Epoch 54: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 88s 6s/step - loss: 0.0121 - accuracy: 0.9967 - val_loss: 0.5797 - val_accuracy: 0.8889\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9951\n",
      "Epoch 55: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 88s 5s/step - loss: 0.0408 - accuracy: 0.9951 - val_loss: 0.6590 - val_accuracy: 0.8889\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9984\n",
      "Epoch 56: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 103s 6s/step - loss: 0.0147 - accuracy: 0.9984 - val_loss: 0.5730 - val_accuracy: 0.9028\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 57: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 78s 5s/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9167\n",
      "Epoch 58/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0037 - accuracy: 0.9967\n",
      "Epoch 58: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0037 - accuracy: 0.9967 - val_loss: 0.4543 - val_accuracy: 0.8889\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.0313 - accuracy: 0.9951\n",
      "Epoch 59: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 60s 4s/step - loss: 0.0313 - accuracy: 0.9951 - val_loss: 0.6982 - val_accuracy: 0.8750\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9967\n",
      "Epoch 60: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0337 - accuracy: 0.9967 - val_loss: 0.8115 - val_accuracy: 0.8611\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9902\n",
      "Epoch 61: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 0.7158 - val_accuracy: 0.8611\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9951\n",
      "Epoch 62: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0351 - accuracy: 0.9951 - val_loss: 0.7311 - val_accuracy: 0.8472\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0218 - accuracy: 0.9918\n",
      "Epoch 63: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0218 - accuracy: 0.9918 - val_loss: 0.6397 - val_accuracy: 0.8750\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0077 - accuracy: 0.9967\n",
      "Epoch 64: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 62s 4s/step - loss: 0.0077 - accuracy: 0.9967 - val_loss: 0.7212 - val_accuracy: 0.8611\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9951\n",
      "Epoch 65: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 64s 4s/step - loss: 0.0287 - accuracy: 0.9951 - val_loss: 0.7451 - val_accuracy: 0.8611\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9935\n",
      "Epoch 66: val_accuracy did not improve from 0.91667\n",
      "16/16 [==============================] - 65s 4s/step - loss: 0.0350 - accuracy: 0.9935 - val_loss: 0.8015 - val_accuracy: 0.8472\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9967\n",
      "Epoch 67: val_accuracy improved from 0.91667 to 0.93056, saving model to best_model_resnet.h5\n",
      "16/16 [==============================] - 68s 4s/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 0.6081 - val_accuracy: 0.9306\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9967\n",
      "Epoch 68: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 64s 4s/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 0.7101 - val_accuracy: 0.8889\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0285 - accuracy: 0.9951\n",
      "Epoch 69: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0285 - accuracy: 0.9951 - val_loss: 1.2313 - val_accuracy: 0.8056\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0432 - accuracy: 0.9886\n",
      "Epoch 70: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 60s 4s/step - loss: 0.0432 - accuracy: 0.9886 - val_loss: 0.5477 - val_accuracy: 0.8889\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9935\n",
      "Epoch 71: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0262 - accuracy: 0.9935 - val_loss: 0.5659 - val_accuracy: 0.8889\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9886\n",
      "Epoch 72: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.0314 - accuracy: 0.9886 - val_loss: 1.0463 - val_accuracy: 0.8194\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9918\n",
      "Epoch 73: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 60s 4s/step - loss: 0.0205 - accuracy: 0.9918 - val_loss: 1.0927 - val_accuracy: 0.8472\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9935\n",
      "Epoch 74: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.8233 - val_accuracy: 0.8750\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 75: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 0.7449 - val_accuracy: 0.8750\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9967\n",
      "Epoch 76: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 1.0024 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9935\n",
      "Epoch 77: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0155 - accuracy: 0.9935 - val_loss: 1.0566 - val_accuracy: 0.8472\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 78: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.0662 - val_accuracy: 0.8750\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9886\n",
      "Epoch 79: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 68s 4s/step - loss: 0.0382 - accuracy: 0.9886 - val_loss: 1.1756 - val_accuracy: 0.8472\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0265 - accuracy: 0.9935\n",
      "Epoch 80: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 65s 4s/step - loss: 0.0265 - accuracy: 0.9935 - val_loss: 1.0894 - val_accuracy: 0.8472\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0319 - accuracy: 0.9902\n",
      "Epoch 81: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.0319 - accuracy: 0.9902 - val_loss: 0.8899 - val_accuracy: 0.8889\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0209 - accuracy: 0.9935\n",
      "Epoch 82: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 64s 4s/step - loss: 0.0209 - accuracy: 0.9935 - val_loss: 1.0009 - val_accuracy: 0.8889\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0081 - accuracy: 0.9951\n",
      "Epoch 83: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 60s 4s/step - loss: 0.0081 - accuracy: 0.9951 - val_loss: 0.7904 - val_accuracy: 0.8889\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9935\n",
      "Epoch 84: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0175 - accuracy: 0.9935 - val_loss: 1.2114 - val_accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9951\n",
      "Epoch 85: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 62s 4s/step - loss: 0.0079 - accuracy: 0.9951 - val_loss: 1.3711 - val_accuracy: 0.8750\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0251 - accuracy: 0.9918\n",
      "Epoch 86: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0251 - accuracy: 0.9918 - val_loss: 1.1781 - val_accuracy: 0.8750\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0099 - accuracy: 0.9935\n",
      "Epoch 87: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0099 - accuracy: 0.9935 - val_loss: 0.8662 - val_accuracy: 0.8889\n",
      "Epoch 88/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0067 - accuracy: 0.9951\n",
      "Epoch 88: val_accuracy did not improve from 0.93056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 57s 4s/step - loss: 0.0067 - accuracy: 0.9951 - val_loss: 0.7619 - val_accuracy: 0.9028\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0118 - accuracy: 0.9935\n",
      "Epoch 89: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0118 - accuracy: 0.9935 - val_loss: 0.8262 - val_accuracy: 0.8889\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0050 - accuracy: 0.9951\n",
      "Epoch 90: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0050 - accuracy: 0.9951 - val_loss: 1.0547 - val_accuracy: 0.8750\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0069 - accuracy: 0.9967\n",
      "Epoch 91: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0069 - accuracy: 0.9967 - val_loss: 1.4085 - val_accuracy: 0.8472\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9918\n",
      "Epoch 92: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0233 - accuracy: 0.9918 - val_loss: 1.0144 - val_accuracy: 0.8472\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0202 - accuracy: 0.9967\n",
      "Epoch 93: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 67s 4s/step - loss: 0.0202 - accuracy: 0.9967 - val_loss: 1.0970 - val_accuracy: 0.8611\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0049 - accuracy: 0.9984\n",
      "Epoch 94: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 75s 5s/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 1.2991 - val_accuracy: 0.8472\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0128 - accuracy: 0.9967\n",
      "Epoch 95: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.0128 - accuracy: 0.9967 - val_loss: 1.1319 - val_accuracy: 0.8889\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9804\n",
      "Epoch 96: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0632 - accuracy: 0.9804 - val_loss: 1.2015 - val_accuracy: 0.8611\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9918\n",
      "Epoch 97: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0310 - accuracy: 0.9918 - val_loss: 1.4187 - val_accuracy: 0.8611\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0086 - accuracy: 0.9984\n",
      "Epoch 98: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0086 - accuracy: 0.9984 - val_loss: 1.1637 - val_accuracy: 0.8472\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0219 - accuracy: 0.9951\n",
      "Epoch 99: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0219 - accuracy: 0.9951 - val_loss: 1.2925 - val_accuracy: 0.8611\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0130 - accuracy: 0.9935\n",
      "Epoch 100: val_accuracy did not improve from 0.93056\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0130 - accuracy: 0.9935 - val_loss: 1.6368 - val_accuracy: 0.8472\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained ResNet50 model\n",
    "base_model = ResNet50(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam()  # Using Adam optimizer\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model_resnet.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f42dc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 17s 2s/step - loss: 0.0015 - accuracy: 1.0000\n",
      "5/5 [==============================] - 4s 558ms/step - loss: 0.4635 - accuracy: 0.9306\n",
      "5/5 [==============================] - 14s 3s/step - loss: 0.6652 - accuracy: 0.8317\n",
      "Train Loss:  0.0015056416159495711\n",
      "Train Accuracy:  1.0\n",
      "--------------------\n",
      "Validation Loss:  0.4635477066040039\n",
      "Validation Accuracy:  0.9305555820465088\n",
      "--------------------\n",
      "Test Loss:  0.6652371287345886\n",
      "Test Accuracy:  0.8317460417747498\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model.h5')\n",
    "\n",
    "ts_length = len(test_df)\n",
    "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c6a2b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 6s 0us/step\n",
      "Epoch 1/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.5871 - accuracy: 0.5106\n",
      "Epoch 1: val_accuracy improved from -inf to 0.37500, saving model to best_model_inceptionv3.h5\n",
      "16/16 [==============================] - 38s 2s/step - loss: 1.5871 - accuracy: 0.5106 - val_loss: 14.8462 - val_accuracy: 0.3750\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 1.0477 - accuracy: 0.6770\n",
      "Epoch 2: val_accuracy did not improve from 0.37500\n",
      "16/16 [==============================] - 56s 3s/step - loss: 1.0477 - accuracy: 0.6770 - val_loss: 9.2758 - val_accuracy: 0.3056\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8690 - accuracy: 0.7455\n",
      "Epoch 3: val_accuracy improved from 0.37500 to 0.55556, saving model to best_model_inceptionv3.h5\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.8690 - accuracy: 0.7455 - val_loss: 4.4812 - val_accuracy: 0.5556\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.8707 - accuracy: 0.7537\n",
      "Epoch 4: val_accuracy did not improve from 0.55556\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.8707 - accuracy: 0.7537 - val_loss: 6.8750 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.7007 - accuracy: 0.7357\n",
      "Epoch 5: val_accuracy did not improve from 0.55556\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.7007 - accuracy: 0.7357 - val_loss: 3.4541 - val_accuracy: 0.4861\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.5636 - accuracy: 0.8042\n",
      "Epoch 6: val_accuracy did not improve from 0.55556\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.5636 - accuracy: 0.8042 - val_loss: 4.3045 - val_accuracy: 0.4306\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4524 - accuracy: 0.8809\n",
      "Epoch 7: val_accuracy did not improve from 0.55556\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.4524 - accuracy: 0.8809 - val_loss: 2.0036 - val_accuracy: 0.5556\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4162 - accuracy: 0.8515\n",
      "Epoch 8: val_accuracy did not improve from 0.55556\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.4162 - accuracy: 0.8515 - val_loss: 1.8754 - val_accuracy: 0.5278\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4155 - accuracy: 0.8728\n",
      "Epoch 9: val_accuracy did not improve from 0.55556\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.4155 - accuracy: 0.8728 - val_loss: 1.4986 - val_accuracy: 0.5556\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.3627 - accuracy: 0.8711\n",
      "Epoch 10: val_accuracy improved from 0.55556 to 0.66667, saving model to best_model_inceptionv3.h5\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.3627 - accuracy: 0.8711 - val_loss: 1.2432 - val_accuracy: 0.6667\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2307 - accuracy: 0.9233\n",
      "Epoch 11: val_accuracy improved from 0.66667 to 0.72222, saving model to best_model_inceptionv3.h5\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.2307 - accuracy: 0.9233 - val_loss: 1.1173 - val_accuracy: 0.7222\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2900 - accuracy: 0.9135\n",
      "Epoch 12: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.2900 - accuracy: 0.9135 - val_loss: 1.1880 - val_accuracy: 0.6806\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2157 - accuracy: 0.9184\n",
      "Epoch 13: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.2157 - accuracy: 0.9184 - val_loss: 1.1486 - val_accuracy: 0.6389\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2879 - accuracy: 0.8989\n",
      "Epoch 14: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 54s 4s/step - loss: 0.2879 - accuracy: 0.8989 - val_loss: 1.1665 - val_accuracy: 0.6528\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.9021\n",
      "Epoch 15: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.2772 - accuracy: 0.9021 - val_loss: 1.0605 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1705 - accuracy: 0.9576\n",
      "Epoch 16: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.1705 - accuracy: 0.9576 - val_loss: 0.9759 - val_accuracy: 0.6528\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9608\n",
      "Epoch 17: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.1930 - accuracy: 0.9608 - val_loss: 0.8825 - val_accuracy: 0.6806\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2057 - accuracy: 0.9445\n",
      "Epoch 18: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.2057 - accuracy: 0.9445 - val_loss: 1.1204 - val_accuracy: 0.6389\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1646 - accuracy: 0.9445\n",
      "Epoch 19: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.1646 - accuracy: 0.9445 - val_loss: 0.9871 - val_accuracy: 0.6528\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1111 - accuracy: 0.9608\n",
      "Epoch 20: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1111 - accuracy: 0.9608 - val_loss: 0.8550 - val_accuracy: 0.6944\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1495 - accuracy: 0.9478\n",
      "Epoch 21: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1495 - accuracy: 0.9478 - val_loss: 0.8734 - val_accuracy: 0.6667\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9445\n",
      "Epoch 22: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1615 - accuracy: 0.9445 - val_loss: 1.0088 - val_accuracy: 0.6806\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1738 - accuracy: 0.9445\n",
      "Epoch 23: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.1738 - accuracy: 0.9445 - val_loss: 0.9060 - val_accuracy: 0.7083\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1907 - accuracy: 0.9445\n",
      "Epoch 24: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.1907 - accuracy: 0.9445 - val_loss: 1.0152 - val_accuracy: 0.6944\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1911 - accuracy: 0.9380\n",
      "Epoch 25: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.1911 - accuracy: 0.9380 - val_loss: 1.0132 - val_accuracy: 0.6528\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1498 - accuracy: 0.9462\n",
      "Epoch 26: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.1498 - accuracy: 0.9462 - val_loss: 1.0533 - val_accuracy: 0.6528\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9592\n",
      "Epoch 27: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.1434 - accuracy: 0.9592 - val_loss: 0.9808 - val_accuracy: 0.6528\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9674\n",
      "Epoch 28: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1093 - accuracy: 0.9674 - val_loss: 1.0002 - val_accuracy: 0.6528\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.1165 - accuracy: 0.9641\n",
      "Epoch 29: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.1165 - accuracy: 0.9641 - val_loss: 0.9789 - val_accuracy: 0.6806\n",
      "Epoch 30/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0750 - accuracy: 0.9837\n",
      "Epoch 30: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0750 - accuracy: 0.9837 - val_loss: 0.8525 - val_accuracy: 0.7083\n",
      "Epoch 31/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9788\n",
      "Epoch 31: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0671 - accuracy: 0.9788 - val_loss: 0.8162 - val_accuracy: 0.7083\n",
      "Epoch 32/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0635 - accuracy: 0.9788\n",
      "Epoch 32: val_accuracy did not improve from 0.72222\n",
      "16/16 [==============================] - 52s 3s/step - loss: 0.0635 - accuracy: 0.9788 - val_loss: 0.9578 - val_accuracy: 0.7083\n",
      "Epoch 33/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0828 - accuracy: 0.9772\n",
      "Epoch 33: val_accuracy improved from 0.72222 to 0.73611, saving model to best_model_inceptionv3.h5\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0828 - accuracy: 0.9772 - val_loss: 0.9472 - val_accuracy: 0.7361\n",
      "Epoch 34/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1083 - accuracy: 0.9674\n",
      "Epoch 34: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.1083 - accuracy: 0.9674 - val_loss: 1.0235 - val_accuracy: 0.7083\n",
      "Epoch 35/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0911 - accuracy: 0.9674\n",
      "Epoch 35: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0911 - accuracy: 0.9674 - val_loss: 1.0325 - val_accuracy: 0.6944\n",
      "Epoch 36/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9690\n",
      "Epoch 36: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.1108 - accuracy: 0.9690 - val_loss: 1.1719 - val_accuracy: 0.6806\n",
      "Epoch 37/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1079 - accuracy: 0.9772\n",
      "Epoch 37: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.1079 - accuracy: 0.9772 - val_loss: 0.8990 - val_accuracy: 0.6806\n",
      "Epoch 38/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0840 - accuracy: 0.9788\n",
      "Epoch 38: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.0840 - accuracy: 0.9788 - val_loss: 0.9120 - val_accuracy: 0.7361\n",
      "Epoch 39/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1195 - accuracy: 0.9690\n",
      "Epoch 39: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.1195 - accuracy: 0.9690 - val_loss: 0.9643 - val_accuracy: 0.6667\n",
      "Epoch 40/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0654 - accuracy: 0.9739\n",
      "Epoch 40: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0654 - accuracy: 0.9739 - val_loss: 0.9074 - val_accuracy: 0.6944\n",
      "Epoch 41/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0845 - accuracy: 0.9755\n",
      "Epoch 41: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0845 - accuracy: 0.9755 - val_loss: 1.0477 - val_accuracy: 0.6806\n",
      "Epoch 42/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0933 - accuracy: 0.9690\n",
      "Epoch 42: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0933 - accuracy: 0.9690 - val_loss: 0.9743 - val_accuracy: 0.7222\n",
      "Epoch 43/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0625 - accuracy: 0.9821\n",
      "Epoch 43: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0625 - accuracy: 0.9821 - val_loss: 0.9965 - val_accuracy: 0.6944\n",
      "Epoch 44/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9869\n",
      "Epoch 44: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0605 - accuracy: 0.9869 - val_loss: 0.9643 - val_accuracy: 0.7083\n",
      "Epoch 45/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0488 - accuracy: 0.9853\n",
      "Epoch 45: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 63s 4s/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 1.0923 - val_accuracy: 0.6806\n",
      "Epoch 46/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0537 - accuracy: 0.9837\n",
      "Epoch 46: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0537 - accuracy: 0.9837 - val_loss: 0.9500 - val_accuracy: 0.7083\n",
      "Epoch 47/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0648 - accuracy: 0.9886\n",
      "Epoch 47: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 56s 4s/step - loss: 0.0648 - accuracy: 0.9886 - val_loss: 1.0987 - val_accuracy: 0.7222\n",
      "Epoch 48/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0539 - accuracy: 0.9837\n",
      "Epoch 48: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.0539 - accuracy: 0.9837 - val_loss: 1.0210 - val_accuracy: 0.7361\n",
      "Epoch 49/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0882 - accuracy: 0.9772\n",
      "Epoch 49: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.0882 - accuracy: 0.9772 - val_loss: 0.9358 - val_accuracy: 0.6806\n",
      "Epoch 50/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0786 - accuracy: 0.9723\n",
      "Epoch 50: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 62s 4s/step - loss: 0.0786 - accuracy: 0.9723 - val_loss: 1.1156 - val_accuracy: 0.7083\n",
      "Epoch 51/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0753 - accuracy: 0.9788\n",
      "Epoch 51: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0753 - accuracy: 0.9788 - val_loss: 1.0738 - val_accuracy: 0.7222\n",
      "Epoch 52/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9821\n",
      "Epoch 52: val_accuracy did not improve from 0.73611\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 1.0224 - val_accuracy: 0.7222\n",
      "Epoch 53/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0564 - accuracy: 0.9902\n",
      "Epoch 53: val_accuracy improved from 0.73611 to 0.75000, saving model to best_model_inceptionv3.h5\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.0564 - accuracy: 0.9902 - val_loss: 0.9557 - val_accuracy: 0.7500\n",
      "Epoch 54/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1078 - accuracy: 0.9755\n",
      "Epoch 54: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 61s 4s/step - loss: 0.1078 - accuracy: 0.9755 - val_loss: 0.9867 - val_accuracy: 0.7361\n",
      "Epoch 55/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0819 - accuracy: 0.9723\n",
      "Epoch 55: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 58s 4s/step - loss: 0.0819 - accuracy: 0.9723 - val_loss: 1.0118 - val_accuracy: 0.7361\n",
      "Epoch 56/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0597 - accuracy: 0.9869\n",
      "Epoch 56: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.9793 - val_accuracy: 0.7222\n",
      "Epoch 57/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1436 - accuracy: 0.9527\n",
      "Epoch 57: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.1436 - accuracy: 0.9527 - val_loss: 0.9956 - val_accuracy: 0.7083\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9592\n",
      "Epoch 58: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0861 - accuracy: 0.9592 - val_loss: 0.9715 - val_accuracy: 0.6667\n",
      "Epoch 59/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0824 - accuracy: 0.9788\n",
      "Epoch 59: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 57s 3s/step - loss: 0.0824 - accuracy: 0.9788 - val_loss: 0.9021 - val_accuracy: 0.7083\n",
      "Epoch 60/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0555 - accuracy: 0.9853\n",
      "Epoch 60: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 53s 3s/step - loss: 0.0555 - accuracy: 0.9853 - val_loss: 0.8274 - val_accuracy: 0.7361\n",
      "Epoch 61/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0725 - accuracy: 0.9788\n",
      "Epoch 61: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 59s 4s/step - loss: 0.0725 - accuracy: 0.9788 - val_loss: 0.9626 - val_accuracy: 0.7361\n",
      "Epoch 62/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9772\n",
      "Epoch 62: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 56s 3s/step - loss: 0.0923 - accuracy: 0.9772 - val_loss: 0.9778 - val_accuracy: 0.7083\n",
      "Epoch 63/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0894 - accuracy: 0.9723\n",
      "Epoch 63: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.0894 - accuracy: 0.9723 - val_loss: 1.1593 - val_accuracy: 0.6667\n",
      "Epoch 64/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1930 - accuracy: 0.9576\n",
      "Epoch 64: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.1930 - accuracy: 0.9576 - val_loss: 1.1602 - val_accuracy: 0.7222\n",
      "Epoch 65/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1425 - accuracy: 0.9543\n",
      "Epoch 65: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 54s 3s/step - loss: 0.1425 - accuracy: 0.9543 - val_loss: 0.9806 - val_accuracy: 0.7500\n",
      "Epoch 66/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.4250 - accuracy: 0.9005\n",
      "Epoch 66: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.4250 - accuracy: 0.9005 - val_loss: 1.4310 - val_accuracy: 0.6806\n",
      "Epoch 67/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1015 - accuracy: 0.9641\n",
      "Epoch 67: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 55s 3s/step - loss: 0.1015 - accuracy: 0.9641 - val_loss: 1.1993 - val_accuracy: 0.7222\n",
      "Epoch 68/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1830 - accuracy: 0.9641\n",
      "Epoch 68: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 57s 4s/step - loss: 0.1830 - accuracy: 0.9641 - val_loss: 1.3008 - val_accuracy: 0.7083\n",
      "Epoch 69/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1222 - accuracy: 0.9608\n",
      "Epoch 69: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 40s 2s/step - loss: 0.1222 - accuracy: 0.9608 - val_loss: 1.5687 - val_accuracy: 0.6667\n",
      "Epoch 70/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2498 - accuracy: 0.9299\n",
      "Epoch 70: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 34s 2s/step - loss: 0.2498 - accuracy: 0.9299 - val_loss: 1.5193 - val_accuracy: 0.7222\n",
      "Epoch 71/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.2548 - accuracy: 0.9217\n",
      "Epoch 71: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 33s 2s/step - loss: 0.2548 - accuracy: 0.9217 - val_loss: 1.2269 - val_accuracy: 0.6944\n",
      "Epoch 72/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1825 - accuracy: 0.9445\n",
      "Epoch 72: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.1825 - accuracy: 0.9445 - val_loss: 1.0754 - val_accuracy: 0.7083\n",
      "Epoch 73/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9641\n",
      "Epoch 73: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.1505 - accuracy: 0.9641 - val_loss: 1.1454 - val_accuracy: 0.6806\n",
      "Epoch 74/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0758 - accuracy: 0.9739\n",
      "Epoch 74: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 34s 2s/step - loss: 0.0758 - accuracy: 0.9739 - val_loss: 1.1856 - val_accuracy: 0.6806\n",
      "Epoch 75/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0563 - accuracy: 0.9869\n",
      "Epoch 75: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.0563 - accuracy: 0.9869 - val_loss: 1.1443 - val_accuracy: 0.6944\n",
      "Epoch 76/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0704 - accuracy: 0.9918\n",
      "Epoch 76: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.0704 - accuracy: 0.9918 - val_loss: 1.2301 - val_accuracy: 0.7222\n",
      "Epoch 77/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9902\n",
      "Epoch 77: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.0371 - accuracy: 0.9902 - val_loss: 1.3003 - val_accuracy: 0.7083\n",
      "Epoch 78/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0496 - accuracy: 0.9869\n",
      "Epoch 78: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.0496 - accuracy: 0.9869 - val_loss: 1.1949 - val_accuracy: 0.6667\n",
      "Epoch 79/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1255 - accuracy: 0.9755\n",
      "Epoch 79: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.1255 - accuracy: 0.9755 - val_loss: 0.9931 - val_accuracy: 0.7361\n",
      "Epoch 80/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1434 - accuracy: 0.9657\n",
      "Epoch 80: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.1434 - accuracy: 0.9657 - val_loss: 1.0720 - val_accuracy: 0.6944\n",
      "Epoch 81/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.1225 - accuracy: 0.9674\n",
      "Epoch 81: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.1225 - accuracy: 0.9674 - val_loss: 1.0610 - val_accuracy: 0.7083\n",
      "Epoch 82/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0541 - accuracy: 0.9869\n",
      "Epoch 82: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 34s 2s/step - loss: 0.0541 - accuracy: 0.9869 - val_loss: 1.1334 - val_accuracy: 0.7083\n",
      "Epoch 83/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0873 - accuracy: 0.9804\n",
      "Epoch 83: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 34s 2s/step - loss: 0.0873 - accuracy: 0.9804 - val_loss: 1.3735 - val_accuracy: 0.7361\n",
      "Epoch 84/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0751 - accuracy: 0.9788\n",
      "Epoch 84: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.0751 - accuracy: 0.9788 - val_loss: 1.2046 - val_accuracy: 0.6667\n",
      "Epoch 85/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0852 - accuracy: 0.9821\n",
      "Epoch 85: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.0852 - accuracy: 0.9821 - val_loss: 1.2138 - val_accuracy: 0.7222\n",
      "Epoch 86/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9723\n",
      "Epoch 86: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.0711 - accuracy: 0.9723 - val_loss: 1.2109 - val_accuracy: 0.6944\n",
      "Epoch 87/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0692 - accuracy: 0.9788\n",
      "Epoch 87: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.0692 - accuracy: 0.9788 - val_loss: 1.1838 - val_accuracy: 0.7361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0742 - accuracy: 0.9821\n",
      "Epoch 88: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.0742 - accuracy: 0.9821 - val_loss: 1.2344 - val_accuracy: 0.7222\n",
      "Epoch 89/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0672 - accuracy: 0.9772\n",
      "Epoch 89: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.0672 - accuracy: 0.9772 - val_loss: 1.2440 - val_accuracy: 0.7083\n",
      "Epoch 90/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0747 - accuracy: 0.9886\n",
      "Epoch 90: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 37s 2s/step - loss: 0.0747 - accuracy: 0.9886 - val_loss: 1.3124 - val_accuracy: 0.6389\n",
      "Epoch 91/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0365 - accuracy: 0.9853\n",
      "Epoch 91: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.0365 - accuracy: 0.9853 - val_loss: 0.9536 - val_accuracy: 0.7222\n",
      "Epoch 92/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0302 - accuracy: 0.9902\n",
      "Epoch 92: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 36s 2s/step - loss: 0.0302 - accuracy: 0.9902 - val_loss: 0.9859 - val_accuracy: 0.7222\n",
      "Epoch 93/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9918\n",
      "Epoch 93: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.0292 - accuracy: 0.9918 - val_loss: 1.0533 - val_accuracy: 0.7500\n",
      "Epoch 94/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9804\n",
      "Epoch 94: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.0749 - accuracy: 0.9804 - val_loss: 1.1237 - val_accuracy: 0.7083\n",
      "Epoch 95/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9886\n",
      "Epoch 95: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.0628 - accuracy: 0.9886 - val_loss: 1.4070 - val_accuracy: 0.6944\n",
      "Epoch 96/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9886\n",
      "Epoch 96: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.0368 - accuracy: 0.9886 - val_loss: 1.1422 - val_accuracy: 0.7083\n",
      "Epoch 97/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9918\n",
      "Epoch 97: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 39s 2s/step - loss: 0.0331 - accuracy: 0.9918 - val_loss: 1.1049 - val_accuracy: 0.7500\n",
      "Epoch 98/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9853\n",
      "Epoch 98: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 38s 2s/step - loss: 0.0412 - accuracy: 0.9853 - val_loss: 1.0398 - val_accuracy: 0.7083\n",
      "Epoch 99/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9902\n",
      "Epoch 99: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 39s 2s/step - loss: 0.0498 - accuracy: 0.9902 - val_loss: 1.2135 - val_accuracy: 0.6944\n",
      "Epoch 100/100\n",
      "16/16 [==============================] - ETA: 0s - loss: 0.0181 - accuracy: 0.9984\n",
      "Epoch 100: val_accuracy did not improve from 0.75000\n",
      "16/16 [==============================] - 35s 2s/step - loss: 0.0181 - accuracy: 0.9984 - val_loss: 1.2939 - val_accuracy: 0.6806\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained InceptionV3 model\n",
    "base_model = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(axis=-1),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = Adam()  # Using Adam optimizer\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model_inceptionv3.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=100,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abeabc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 22s 4s/step - loss: 0.0099 - accuracy: 1.0000\n",
      "5/5 [==============================] - 6s 721ms/step - loss: 0.9557 - accuracy: 0.7500\n",
      "5/5 [==============================] - 25s 5s/step - loss: 2.0243 - accuracy: 0.5143\n",
      "Train Loss:  0.009919255040585995\n",
      "Train Accuracy:  1.0\n",
      "--------------------\n",
      "Validation Loss:  0.9556882381439209\n",
      "Validation Accuracy:  0.75\n",
      "--------------------\n",
      "Test Loss:  2.0243473052978516\n",
      "Test Accuracy:  0.5142857432365417\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model_inceptionv3.h5')\n",
    "ts_length = len(test_df)\n",
    "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5d1be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "input_shape=img_shape\n",
    "\n",
    "model_inceptionv3 = load_model('best_model_inceptionv3.h5')\n",
    "model = load_model('best_model.h5')\n",
    "model_resnet = load_model('best_model_resnet.h5')\n",
    "\n",
    "# Create input layer\n",
    "input_layer = Input(shape=(input_shape))  # Replace input_shape with the appropriate shape for your models\n",
    "\n",
    "# Get outputs from all three models\n",
    "output_inceptionv3 = model_inceptionv3(input_layer)\n",
    "output_model = model(input_layer)\n",
    "output_resnet = model_resnet(input_layer)\n",
    "\n",
    "# Average the predictions from all three models\n",
    "average = Average()([output_inceptionv3, output_model, output_resnet])\n",
    "\n",
    "# Create an ensemble model\n",
    "ensemble_model = Model(inputs=input_layer, outputs=average)\n",
    "\n",
    "# Save the ensemble model\n",
    "ensemble_model.save('final_ensemble_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d560cfcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_8616\\2064879440.py:2: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  preds = model.predict_generator(test_gen)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 3 0 0 0 3 3 0\n",
      " 0 0 0 0 0 0 0 3 0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 3 0 0 0 3 1 3 0 0 0\n",
      " 0 0 1 0 0 3 3 0 0 1 1 1 1 1 0 0 1 1 3 0 0 3 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 3 1 0 0 1 1 1 1 3 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 0\n",
      " 3 3 3 3 3 3 3 3 0 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3 3 3 0 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('final_ensemble_model.h5')\n",
    "preds = model.predict_generator(test_gen)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5fd19197",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 109s 16s/step - loss: 0.5089 - accuracy: 0.8635\n",
      "Test Loss: 0.5089185237884521\n",
      "Test Accuracy: 0.8634920716285706\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Load the model\n",
    "model = tf.keras.models.load_model('final_ensemble_model.h5')\n",
    "\n",
    "# Compile the model\n",
    "# Replace 'optimizer' and 'loss' with your chosen optimizer and loss function\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Assuming you've defined test_gen and test_df\n",
    "ts_length = len(test_df)\n",
    "test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length % n == 0 and ts_length / n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "\n",
    "# Evaluate the model\n",
    "test_score = model.evaluate(test_gen, steps=test_steps, verbose=1)\n",
    "\n",
    "print(\"Test Loss:\", test_score[0])\n",
    "print(\"Test Accuracy:\", test_score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa6cdde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_confusion_matrix(cm, classes, normalize= False, title= 'Confusion Matrix', cmap= plt.cm.Blues):\n",
    "    plt.figure(figsize= (10, 10))\n",
    "    plt.imshow(cm, interpolation= 'nearest', cmap= cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation= 45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis= 1)[:, np.newaxis]\n",
    "        print('Normalized Confusion Matrix')\n",
    "    else:\n",
    "        print('Confusion Matrix, Without Normalization')\n",
    "    print(cm)\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j], horizontalalignment= 'center', color= 'white' if cm[i, j] > thresh else 'black')\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "862d9fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix, Without Normalization\n",
      "[[98  8  0 14]\n",
      " [ 9 38  0  4]\n",
      " [ 1  0 53  0]\n",
      " [ 7  0  0 83]]\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "         adenocarcinoma       0.85      0.82      0.83       120\n",
      "   large-cell-carcinoma       0.83      0.75      0.78        51\n",
      "                 normal       1.00      0.98      0.99        54\n",
      "squamous-cell-carcinoma       0.82      0.92      0.87        90\n",
      "\n",
      "               accuracy                           0.86       315\n",
      "              macro avg       0.88      0.87      0.87       315\n",
      "           weighted avg       0.86      0.86      0.86       315\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA8QAAAOzCAYAAAB+i8+OAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC50klEQVR4nOzdeVhUZf/H8c8BBQUBdxDDfUUxUdLUcl9yS1NzLdfUNMst9TE3zMclcyt3zS3NzMp8zNQ0l7Lc1yzRcsVKM1cQFQTm94c5P3EFWWYO5/3iOtfVnDlz5jPDhHz53ve5DZvNZhMAAAAAABbj4ugAAAAAAAA4AgUxAAAAAMCSKIgBAAAAAJZEQQwAAAAAsCQKYgAAAACAJVEQAwAAAAAsiYIYAAAAAGBJGRwdAAAAAACQNDdv3lRMTIyjYySJm5ubMmXK5OgYCVAQAwAAAICJ3Lx5U5m9ckix1x0dJUn8/Px08uRJpyqKKYgBAAAAwERiYmKk2OtyD+wgubo5Ok7ixMXo3OFFiomJoSAGAAAAACSTq5sMkxTENkcHeAguqgUAAAAAsCQ6xAAAAABgRobL7c0MnDSnc6YCAAAAACCVURADAAAAACyJIdMAAAAAYEaGJMNwdIrEcdKYdIgBAAAAAJZEQQwAAAAAsCQKYgAAAACAJTGHGAAAAADMiGWXks05UwEAAAAAkMooiAEAAAAAlsSQaQAAAAAwI8Mw0bJLzpmTDjEAAAAAwJIoiAEAAAAAlkRBDAAAAACwJOYQAwAAAIAZsexSsjlnKgAAAAAAUhkFMQAAAADAkhgyDQAAAABmxLJLyUaHGAAAAABgSRTEAAAAAABLoiAGAAAAAFgSc4gBAAAAwJRMtOySk/ZinTMVAAAAAACpjIIYAAAAAGBJDJkGAAAAADNi2aVko0MMAAAAALAkCmIAAAAAgCVREAMAAAAALIk5xAAAAABgRoaJll1y0pzOmQoAAAAAgFRGQQwAAAAAsCSGTAMAAACAGbHsUrLRIQYAAAAAWBIFMQAAAADAkiiIAQAAAACWxBxiAAAAADAjll1KNudMBQAAAABAKqMgBgAAAABYEkOmAQAAAMCMWHYp2egQAwAAAAAsiYIYAAAAAGBJFMQAAAAAAEtiDjEAAAAAmBHLLiWbc6YCAAAAACCVURADAAAAACyJIdMAAAAAYEaG4bRDke/DsksAAAAAADgPCmIAAAAAgCVREAMAAAAALIk5xAAAAABgRi7G7c0MnDQnHWIAAAAAgCVREAMAAAAALImCGAAAAABgScwhBgAAAAAzMlxMtA6xc+Z0zlQAAAAAAKQyCmIAAAAAgCUxZBoAAAAAzMgwbm9m4KQ56RADAAAAACyJghgAAAAAYEkUxAAAAAAAS2IOMQAAAACYEcsuJZtzpgIAAAAAIJVREAMAAAAALIkh0wAAAABgRiy7lGx0iAEAAAAAlkRBDAAAAACwJApiAAAAAIAlMYcYAAAAAMyIZZeSzTlTAQAAAACQyiiIAQAAAACWxJBpAAAAADAjll1KNjrEAAAAAABLoiAGAAAAAFgSBTEAAAAAwJKYQwwAAAAAZsSyS8nmnKkAAAAAAEhlFMQAAAAAAEtiyDQAAAAAmBHLLiUbHWIAAAAAgCVREAMAAAAALImCGAAAAABgScwhBgAAAABTMtGyS07ai3XOVAAAAAAApDIKYgAAAACAJTFkGgAAAADMiGWXko0OMQAAAADAkiiIAQAAAACWREEMAAAAALAk5hADAAAAgBkZhnmWXWIOMQAAAAAAzoOCGAAAAABgSQyZBgAAAAAzMlxMNGTaOXM6ZyoAAAAAAFIZBTEAAAAAwJIoiAEAAAAAlsQcYgAAAAAwI8Nw2uWM7uOkOekQAwAAAAAsiYIYAAAAAGBJDJkGAAAAADNi2aVkc85UAAAAAACkMgpiAAAAAIAlURADAAAAACyJOcQAAAAAYEYsu5RsdIgBAAAAAJZEQQwAAAAAsCSGTAMAAACAGbHsUrI5ZyoAAAAAAFIZBTEAAAAAwJIoiAEAAAAAlsQcYgAAAAAwI5ZdSjY6xAAAAAAAS6IgBgAAAABYEkOmAQAAAMCEDMOQ4aRDke/jpDnpEAMAkEQ///yzOnXqpIIFCypTpkzKkiWLypUrp/Hjx+vSpUup+tz79+9XtWrV5OPjI8MwNGXKlBR/DsMwFBoamuLnfZyFCxfaf7nbsmXLfffbbDYVKVJEhmGoevXqT/QcM2bM0MKFC5P0mC1btjw0EwDA3OgQAwCQBHPnzlXPnj1VvHhxDRgwQIGBgbp165b27NmjWbNmafv27frqq69S7fk7d+6sqKgoLVu2TNmyZVOBAgVS/Dm2b9+up556KsXPm1heXl6aN2/efUXv999/r+PHj8vLy+uJzz1jxgzlzJlTHTt2TPRjypUrp+3btyswMPCJnxcA4JwoiAEASKTt27erR48eqlOnjlauXCl3d3f7fXXq1FH//v21bt26VM3wyy+/qGvXrqpfv36qPcezzz6baudOjFatWumTTz7R9OnT5e3tbd8/b948VapUSREREWmS49atWzIMQ97e3g5/TwAAqYMh0wAAJNKYMWNkGIbmzJmToBi+w83NTS+++KL9dnx8vMaPH68SJUrI3d1duXPnVvv27fXHH38keFz16tVVunRp7d69W88//7w8PDxUqFAhjRs3TvHx8ZL+fzhxbGysZs6cmWDeWGho6APnkN15zKlTp+z7Nm3apOrVqytHjhzKnDmz8uXLp+bNm+v69ev2Yx40ZPqXX35RkyZNlC1bNmXKlElly5bVokWLEhxzZ2jxp59+qiFDhsjf31/e3t6qXbu2jh49mrg3WVKbNm0kSZ9++ql939WrV/Xll1+qc+fOD3zMyJEjVbFiRWXPnl3e3t4qV66c5s2bJ5vNZj+mQIEC+vXXX/X999/b3787HfY72RcvXqz+/fsrb968cnd317Fjx+4bMn3hwgUFBASocuXKunXrlv38hw8flqenp1599dVEv1YASI47P8vMsjkjCmIAABIhLi5OmzZtUvny5RUQEJCox/To0UODBg1SnTp1tGrVKo0aNUrr1q1T5cqVdeHChQTHnjt3Tu3atdMrr7yiVatWqX79+ho8eLCWLFkiSWrYsKG2b98uSWrRooW2b99uv51Yp06dUsOGDeXm5qb58+dr3bp1GjdunDw9PRUTE/PQxx09elSVK1fWr7/+qg8//FArVqxQYGCgOnbsqPHjx993/DvvvKPTp0/ro48+0pw5c/T777+rcePGiouLS1ROb29vtWjRQvPnz7fv+/TTT+Xi4qJWrVo99LV1795dy5cv14oVK9SsWTO9+eabGjVqlP2Yr776SoUKFVJwcLD9/bt3ePvgwYMVHh6uWbNm6euvv1bu3Lnve66cOXNq2bJl2r17twYNGiRJun79ul5++WXly5dPs2bNStTrBAA4HkOmAQBIhAsXLuj69esqWLBgoo4/cuSI5syZo549e2rq1Kn2/cHBwapYsaImT56s0aNH2/dfvHhRa9asUYUKFSRJtWvX1pYtW7R06VK1b99euXLlUq5cuSRJvr6+TzSEd+/evbp586bef/99Pf300/b9bdu2feTjQkNDFRMTo82bN9v/GNCgQQNduXJFI0eOVPfu3eXj42M/PjAw0F7IS5Krq6tatmyp3bt3Jzp3586dVaNGDf36668qVaqU5s+fr5dffvmh84cXLFhg/+/4+HhVr15dNptNH3zwgYYNGybDMBQcHKzMmTM/cgh04cKF9fnnnz82X5UqVTR69GgNGjRIVatW1cqVK3Xy5Ent3LlTnp6eiXqNAADHo0MMAEAq2Lx5syTdd/GmChUqqGTJktq4cWOC/X5+fvZi+I4yZcro9OnTKZapbNmycnNzU7du3bRo0SKdOHEiUY/btGmTatWqdV9nvGPHjrp+/fp9neq7h41Lt1+HpCS9lmrVqqlw4cKaP3++Dh06pN27dz90uPSdjLVr15aPj49cXV2VMWNGDR8+XBcvXtT58+cT/bzNmzdP9LEDBgxQw4YN1aZNGy1atEhTp05VUFBQoh8PAMlmmGxzQhTEAAAkQs6cOeXh4aGTJ08m6viLFy9KkvLkyXPfff7+/vb778iRI8d9x7m7u+vGjRtPkPbBChcurO+++065c+fWG2+8ocKFC6tw4cL64IMPHvm4ixcvPvR13Ln/bve+ljvzrZPyWgzDUKdOnbRkyRLNmjVLxYoV0/PPP//AY3ft2qW6detKun0V8J9++km7d+/WkCFDkvy8D3qdj8rYsWNH3bx5U35+fswdBgAToiAGACARXF1dVatWLe3du/e+i2I9yJ2i8OzZs/fd99dffylnzpwpli1TpkySpOjo6AT7752nLEnPP/+8vv76a129elU7duxQpUqV1KdPHy1btuyh58+RI8dDX4ekFH0td+vYsaMuXLigWbNmqVOnTg89btmyZcqYMaNWr16tli1bqnLlygoJCXmi50zKRV/Onj2rN954Q2XLltXFixf19ttvP9FzAgAch4IYAIBEGjx4sGw2m7p27frAi1DdunVLX3/9tSSpZs2akpRgLq0k7d69W2FhYapVq1aK5bpzpeSff/45wf47WR7E1dVVFStW1PTp0yVJ+/bte+ixtWrV0qZNm+wF8B0ff/yxPDw8Um1Jorx582rAgAFq3LixOnTo8NDjDMNQhgwZ5Orqat9348YNLV68+L5jU6rrHhcXpzZt2sgwDK1du1Zjx47V1KlTtWLFimSfGwCQdrioFgAAiVSpUiXNnDlTPXv2VPny5dWjRw+VKlVKt27d0v79+zVnzhyVLl1ajRs3VvHixdWtWzdNnTpVLi4uql+/vk6dOqVhw4YpICBAffv2TbFcDRo0UPbs2dWlSxe9++67ypAhgxYuXKgzZ84kOG7WrFnatGmTGjZsqHz58unmzZv2KznXrl37oecfMWKEVq9erRo1amj48OHKnj27PvnkE33zzTcaP358ggtqpbRx48Y99piGDRtq0qRJatu2rbp166aLFy9qwoQJD1waKygoSMuWLdNnn32mQoUKKVOmTE8073fEiBHaunWr1q9fLz8/P/Xv31/ff/+9unTpouDg4ERffA0AksOZlzO6j5PmpCAGACAJunbtqgoVKmjy5Ml67733dO7cOWXMmFHFihVT27Zt1atXL/uxM2fOVOHChTVv3jxNnz5dPj4+euGFFzR27NgHzhl+Ut7e3lq3bp369OmjV155RVmzZtVrr72m+vXr67XXXrMfV7ZsWa1fv14jRozQuXPnlCVLFpUuXVqrVq2yz8F9kOLFi2vbtm1655139MYbb+jGjRsqWbKkFixYcN9FwxyhZs2amj9/vt577z01btxYefPmVdeuXZU7d2516dIlwbEjR47U2bNn1bVrV0VGRip//vwJ1mlOjA0bNmjs2LEaNmxYgk7/woULFRwcrFatWunHH3+Um5tbSrw8AEAqMmx3r1gPAAAAAHBqERER8vHxkUfTGTIyZnZ0nESx3bqh6yt76urVq/L29nZ0HDs6xAAAAABgQgyZTj4uqgUAAAAAsCQKYgAAAACAJVEQAwAAAAAsiTnEAAAAAGBCzCFOPjrEAAAAAABLokMMpKL4+Hj99ddf8vLyMs9f7wAAACCbzabIyEj5+/vLxYU+YnpFQQykor/++ksBAQGOjgEAAIAndObMGT311FOOjvFADJlOPgpiIBV5eXlJktwCO8hwdXNwGljBoW/GODoCLMbHk59tSFt/Xrru6AiwiGuRkaparpj99zmkTxTEQCq68xc7w9WNghhpwsvb29ERYDHeFMRIY1dv8esr0pZpOrB4IgyGBwAAAABYEn9iAwAAAAAzMv7dzMBJc9IhBgAAAABYEgUxAAAAAMCSGDINAAAAACbEskvJR4cYAAAAAGBJFMQAAAAAAEuiIAYAAAAAWBJziAEAAADAhAxDJppD7OgAD0aHGAAAAABgSRTEAAAAAABLYsg0AAAAAJiQIRMtu+SkY6bpEAMAAAAALImCGAAAAABgSRTEAAAAAABLYg4xAAAAAJiQYZhoDrGT5qRDDAAAAACwJApiAAAAAIAlMWQaAAAAAMzIkLOuZnQ/J81JhxgAAAAAYEkUxAAAAAAAS6IgBgAAAABYEgUxAAAAAJjRv8sumWFL6rJLsbGxGjp0qAoWLKjMmTOrUKFCevfddxUfH28/xmazKTQ0VP7+/sqcObOqV6+uX3/9NUnPQ0EMAAAAAHAq7733nmbNmqVp06YpLCxM48eP1/vvv6+pU6fajxk/frwmTZqkadOmaffu3fLz81OdOnUUGRmZ6OehIAYAAAAAOJXt27erSZMmatiwoQoUKKAWLVqobt262rNnj6Tb3eEpU6ZoyJAhatasmUqXLq1Fixbp+vXrWrp0aaKfh4IYAAAAAEzI0cOgkzxsWlJERESCLTo6+oGv7bnnntPGjRv122+/SZIOHjyoH3/8UQ0aNJAknTx5UufOnVPdunXtj3F3d1e1atW0bdu2RL+HrEMMAAAAAEgTAQEBCW6PGDFCoaGh9x03aNAgXb16VSVKlJCrq6vi4uI0evRotWnTRpJ07tw5SZKvr2+Cx/n6+ur06dOJzkNBDAAAAABIE2fOnJG3t7f9tru7+wOP++yzz7RkyRItXbpUpUqV0oEDB9SnTx/5+/urQ4cO9uPudJ7vsNls9+17FApiAAAAAECa8Pb2TlAQP8yAAQP0n//8R61bt5YkBQUF6fTp0xo7dqw6dOggPz8/Sbc7xXny5LE/7vz58/d1jR+FOcQAAAAAYEKOnhP8JHOIE+v69etycUlYrrq6utqXXSpYsKD8/Py0YcMG+/0xMTH6/vvvVbly5UQ/Dx1iAAAAAIBTady4sUaPHq18+fKpVKlS2r9/vyZNmqTOnTtLuv3HgD59+mjMmDEqWrSoihYtqjFjxsjDw0Nt27ZN9PNQEAMAAAAAnMrUqVM1bNgw9ezZU+fPn5e/v7+6d++u4cOH248ZOHCgbty4oZ49e+ry5cuqWLGi1q9fLy8vr0Q/j2Gz2Wyp8QIA3L6svI+Pj9yDuspwdXN0HFjAyS2THB0BFpPVk59tSFtnLl53dARYxLXICJUrmkdXr15N1JzXtHTnd8wc7RbIxc3D0XESJT7mui5+0snp3k86xAAAAABgRsa/mxk4aU4uqgUAAAAAsCQKYgAAAACAJTFkGgAAAABM6EmWM3IUZ81JhxgAAAAAYEkUxAAAAAAAS6IgBgAAAABYEnOIAQAAAMCEmEOcfHSIAQAAAACWREEMAAAAALAkhkwDAAAAgAkxZDr56BADAAAAACyJghgAAAAAYEkUxAAAAAAAS2IOMQAAAACYEHOIk48OMQAAAADAkiiIAQAAAACWxJBpAAAAADAj49/NDJw0Jx1iAAAAAIAlURADAAAAACyJghgAAAAAYEnMIQYAAAAAE2LZpeSjQwwAAAAAsCQKYgAAAACAJTFkGgAAAABMiCHTyUeHGAAAAABgSRTEAAAAAABLoiAGAAAAAFgSc4gBAAAAwISYQ5x8dIgBAAAAAJZEQQwAAAAAsCSGTAMAAACAGRn/bmbgpDnpEAMAAAAALImCGIDDZPFw1/tvN9fRNe/q0vZJ2rywn8oH5rPf75nZTZMHvaxj60bp0vZJ2v/lUHV9+TkHJkZ6Ehsbq3H/HaEKZYqpoJ+PKj5dXJPeG634+HhHR0M6N3vmDJUoWlBZs2RS5Qrl9eOPWx0dCenA7u0/qvurLfTc04VVzM9TG9Z+/dBjhw14U8X8PLVwzrQ0TAg4J4ZMA3CYmcPbKrCIvzoPXaSz/1xVmwYV9M2sN1Wu+X/11z9XNf7t5qoWUkydhnys039dVO1KJfXB4JY6+89Vrd5yyNHxYXLTpkzQx/Pn6sOZH6l4iUAdPLBPfd7oKi9vb3Xt8aaj4yGd+nz5ZxrQv48+mDpDlSpX0UdzZ6tpo/ra9/Nh5cuX7/EnAB7i+vUolSgVpGatX9WbXdo+9LgNa7/WwX27ldsvTxqmA5wXHWIADpHJPaOa1iqrIVNW6qd9x3XizAWNnr1Gp/66qK4vPy9JqlimoJas3qmte39X+NlLmr/iJ/38258qF8gvjUi+vbt36IUGjVW7XgMF5C+gRk2aqVqN2jq4f5+joyEd+3DKJHXs1EWdurymEiVLasKkKXoqIEBzZ890dDSYXLVa9dT3PyNUr2GThx5z7uxfevedfpo4fb4yZsiYhumQWu4su2SWzRlREANwiAyuLsqQwVU3Y24l2H8z+pYqBxeWJG07cEKNqgXJP5ePJKlqSFEVzZ9b320LS/O8SH8qPFtFW7/frOPHfpMk/XroZ+3asU216r7g4GRIr2JiYrR/317VqlM3wf5atetqx/ZtDkoFq4iPj9fAXl30Ws8+Kloi0NFxAKfBkGkADnHterR2HDyhwV3r6+jJv/X3xQi1fCFEz5TOr2Ph/0iS+r/3uWYMb6vj60fr1q04xdvi1ePdpdp24ISD0yM96NXnbUVEXNXzz5SRq6ur4uLi9J9h7+qlFq0cHQ3p1IULFxQXF6fcuX0T7Pf19dXff59zUCpYxZxpE+WaIYPav9bT0VEAp0JBbAKnTp1SwYIFtX//fpUtW9bRcVKVlV4rpM5DP9bs0HY6sX60YmPjdODIGX22do/KlgyQJL3RproqBBVQ896zFH72kp4rV0QfDG6lcxcitHnnUQenh9n9b8XnWrH8U8346GMVLxGoXw4d1IjBb8vPL49atn3V0fGQjt07bNBmszntUEKkD78c3K+P587QVxu28VlLZ5x5KPK9nDUnBTGcSkBAgM6ePaucOXM6OgrSwMk/Lqjuax/II5ObvLNk0rkLEVo8rpNO/XlRmdwzauSbjdWq31yt+/FXSdIvv/+lMsWfUp9Xa1EQI9lGDR+sXn3eVtPmLSVJJUuV1h9nwvXh5PEUxEgVOXPmlKur633d4PPnz9/XNQZS0p6dP+nihX9UvXxx+764uDiNCx2sRXOma/MepiLBuiiIkWZsNpvi4uKUIcPDP3aurq7y8/NLw1RwBtdvxuj6zRhl9cqs2pVLasiU/yljBle5ZcygeJstwbFxcfFycXHOvzDCXG5cvy4Xl4SX0nB1dZWNZZeQStzc3BRcrrw2fbdBTZq+ZN+/aeMGNWr88AshAcnVpEUbVX6+RoJ9nds0UZMWbdS8NX8AhLVxUS0HWLdunZ577jllzZpVOXLkUKNGjXT8+HH7/bt27VJwcLAyZcqkkJAQ7d+//75zHD58WA0aNFCWLFnk6+urV199VRcuXLDfX716db311lsaOHCgsmfPLj8/P4WGhiY4R3h4uJo0aaIsWbLI29tbLVu21N9//53gmFWrVikkJESZMmVSzpw51axZM/t9S5YsUUhIiLy8vOTn56e2bdvq/Pnz9vu3bNkiwzD07bffKiQkRO7u7tq6davi4+P13nvvqUiRInJ3d1e+fPk0evRoSbeHTBuGoQMHDiQ4x8aNGxUSEiIPDw9VrlxZR48m7A7OnDlThQsXlpubm4oXL67FixcnuN8wDM2ePVuNGjWSh4eHSpYsqe3bt+vYsWOqXr26PD09ValSpQTfh+PHj6tJkyby9fVVlixZ9Mwzz+i777571LdW0dHRioiISLDh4WpXKqk6lUsqv38O1axYQuvm9tbvp87r41XbFRl1Uz/s+V1j+jTV8+WLKr9/Dr3SuKLaNaqgVZsPOjo60oE6LzTUBxPf03ffrtGZ06e05uv/afb0D1S/EYUJUs9bffppwfyPtGjBfB0JC9OA/n11Jjxcr3V73dHRYHJRUdd0+JeDOvzL7X8j/wg/pcO/HNRff5xRtuw5VKxkqQRbxgwZlSu3rwoVKebg5IBjURA7QFRUlPr166fdu3dr48aNcnFx0UsvvaT4+HhFRUWpUaNGKl68uPbu3avQ0FC9/fbbCR5/9uxZVatWTWXLltWePXu0bt06/f3332rZsmWC4xYtWiRPT0/t3LlT48eP17vvvqsNGzZIut2tbdq0qS5duqTvv/9eGzZs0PHjx9Wq1f9fTOabb75Rs2bN1LBhQ+3fv99elN4RExOjUaNG6eDBg1q5cqVOnjypjh073vd6Bw4cqLFjxyosLExlypTR4MGD9d5772nYsGE6fPiwli5dKl/fRw8VGzJkiCZOnKg9e/YoQ4YM6ty5s/2+r776Sr1791b//v31yy+/qHv37urUqZM2b96c4ByjRo1S+/btdeDAAZUoUUJt27ZV9+7dNXjwYO3Zs0eS1KtXL/vx165dU4MGDfTdd99p//79qlevnho3bqzw8PCH5hw7dqx8fHzsW0BAwCNfl9X5ZMmkKf9pqYNfDdVHo17V9v3H1ajnNMXG3u7Qtf/PfO39NVwLx3TQ/i+H6O1OdRQ6fbXmfv6jg5MjPRg9frIavviS/tO/t6pWfFrvDhukVzu9poFDQh0dDenYyy1b6f2JUzRm9LuqGFJWP239QSu/XqP8+fM7OhpM7pcD+9S0dmU1rV1ZkjR2xH/UtHZlfTB+lIOTITUZcvxSSone5Jwj/Ayb7Z7xiEhz//zzj3Lnzq1Dhw5p27ZtGjx4sM6cOSMPDw9J0qxZs9SjRw/7haaGDx+unTt36ttvv7Wf448//lBAQICOHj2qYsWKqXr16oqLi9PWrVvtx1SoUEE1a9bUuHHjtGHDBtWvX18nT560F22HDx9WqVKltGvXLj3zzDOqXLmyChUqpCVLliTqdezevVsVKlRQZGSksmTJoi1btqhGjRpauXKlmjS53XGJjIxUrly5NG3aNL322mv3nePei2rdOcd3332nWrVqSZLWrFmjhg0b6saNG8qUKZOqVKmiUqVKac6cOfbztGzZUlFRUfrmm28k3e4QDx06VKNG3f5HYceOHapUqZLmzZtnL66XLVumTp066caNGw99jaVKlVKPHj0SFM53i46OVnR0tP12RESEAgIC5B7UVYarW6LeRyA5Tm6Z5OgIsJisnvxsQ9o6c/G6oyPAIq5FRqhc0Ty6evWqvL29HR0ngYiIiNvNl+6fycXdw9FxEiU++rrOzG7ldO8nHWIHOH78uNq2batChQrJ29tbBQsWlHR7CHNYWJiefvppezEsSZUqVUrw+L1792rz5s3KkiWLfStRooT93HeUKVMmwePy5MljH9IcFhamgICABB3MwMBAZc2aVWFhty+scODAAXsR+iD79+9XkyZNlD9/fnl5eal69er213G3u7vKYWFhio6OfuR5H+Tu15InTx5JSvBaqlSpkuD4KlWq2F/Hg85xpyMdFBSUYN/Nmzftw5yjoqI0cOBA+/uSJUsWHTly5JEdYnd3d3l7eyfYAAAAADgnLqrlAI0bN1ZAQIDmzp0rf39/xcfHq3Tp0oqJiVFiGvbx8fFq3Lix3nvvvfvuu1MsSlLGjBkT3GcYhuL/vVjMw5Z4uHt/5syZH5ohKipKdevWVd26dbVkyRLlypVL4eHhqlevnmJiYhIc6+npaf/vR53zUe5+LXfyxd914ZvELGHxoHM86rwDBgzQt99+qwkTJqhIkSLKnDmzWrRocd/rAwAAAByBZZeSjw5xGrt48aLCwsI0dOhQ1apVSyVLltTly5ft9wcGBurgwYMJhu3u2LEjwTnKlSunX3/9VQUKFFCRIkUSbHcXn48SGBio8PBwnTlzxr7v8OHDunr1qkqWLCnpdkd148aND3z8kSNHdOHCBY0bN07PP/+8SpQokeCCWg9TtGhRZc6c+aHnfRIlS5bUjz8mnFO6bds2++t4Ulu3blXHjh310ksvKSgoSH5+fjp16lSyzgkAAADAeVAQp7Fs2bIpR44cmjNnjo4dO6ZNmzapX79+9vvbtm0rFxcXdenSRYcPH9aaNWs0YcKEBOd44403dOnSJbVp00a7du3SiRMntH79enXu3FlxcXGJylG7dm2VKVNG7dq10759+7Rr1y61b99e1apVsw9xHjFihD799FONGDFCYWFhOnTokMaPHy9Jypcvn9zc3DR16lSdOHFCq1atss/PfZRMmTJp0KBBGjhwoD7++GMdP35cO3bs0Lx58xL7Ft5nwIABWrhwoWbNmqXff/9dkyZN0ooVK+67GFlSFSlSRCtWrNCBAwd08OBBtW3bNkFXGgAAAIC5URCnMRcXFy1btkx79+5V6dKl1bdvX73//vv2+7NkyaKvv/5ahw8fVnBwsIYMGXLf0Gh/f3/99NNPiouLU7169VS6dGn17t1bPj4+962p+TCGYWjlypXKli2bqlatqtq1a6tQoUL67LPP7MdUr15dn3/+uVatWqWyZcuqZs2a2rlzpyQpV65cWrhwoT7//HMFBgZq3Lhx9xXuDzNs2DD1799fw4cPV8mSJdWqVatEdZcfpmnTpvrggw/0/vvvq1SpUpo9e7YWLFhgn9P8pCZPnqxs2bKpcuXKaty4serVq6dy5col65wAAAAAnAdXmQZS0Z0rAHKVaaQVrjKNtMZVppHWuMo00ooZrjKdr8dyU11lOnxmS6d7P+kQAwAAAAAsiYIYAAAAAGBJLLsEAAAAACbEskvJR4cYAAAAAGBJFMQAAAAAAEuiIAYAAAAAWBJziAEAAADAhJhDnHx0iAEAAAAAlkRBDAAAAACwJIZMAwAAAIAJGcbtzQycNScdYgAAAACAJVEQAwAAAAAsiYIYAAAAAGBJzCEGAAAAABO6PYfYSSfn3sNZY9IhBgAAAABYEgUxAAAAAMCSGDINAAAAAGZkomWX5KQ56RADAAAAACyJghgAAAAAYEkUxAAAAAAAS2IOMQAAAACYkGEYJlp2yTlz0iEGAAAAAFgSBTEAAAAAwJIYMg0AAAAAJmSYaNklZ81JhxgAAAAAYEkUxAAAAAAAS6IgBgAAAABYEnOIAQAAAMCEXFwMubg46eTce9icNCcdYgAAAACAJVEQAwAAAAAsiSHTAAAAAGBCLLuUfHSIAQAAAACWREEMAAAAALAkCmIAAAAAgCUxhxgAAAAATMgwDBnOOjn3Hs6akw4xAAAAAMCSKIgBAAAAAJbEkGkAAAAAMCGWXUo+OsQAAAAAAEuiIAYAAAAAWBIFMQAAAADAkphDDAAAAAAmxLJLyUeHGAAAAABgSRTEAAAAAABLYsg0AAAAAJgQQ6aTjw4xAAAAAMCSKIgBAAAAAJZEQQwAAAAAsCTmEAMAAACACRnG7c0MnDUnHWIAAAAAgCVREAMAAAAALIkh0wAAAABgQoZMtOySnDMnHWIAAAAAgCVREAMAAAAALImCGAAAAABgScwhBgAAAAATYtml5KNDDAAAAACwJApiAAAAAIAlMWQaAAAAAEzIMEy07JKT5qRDDAAAAACwJApiAAAAAIAlURADAAAAACyJOcQAAAAAYEIsu5R8dIgBAAAAAJZEQQwAAAAAsCQKYgAAAACAJTGHGAAAAABMiHWIk48OMQAAAADAkiiIAQAAAACWxJBpIA0cWD1GXt7ejo4BC/hf2F+OjgCL6RBSwNERYDG5vNwdHQEW4W5z/s8ayy4lHx1iAAAAAIAlURADAAAAACyJghgAAAAAYEnMIQYAAAAAE2LZpeSjQwwAAAAAsCQKYgAAAACAJTFkGgAAAADMyETLLslJc9IhBgAAAABYEgUxAAAAAMCSKIgBAAAAAJbEHGIAAAAAMCGWXUo+OsQAAAAAAEuiIAYAAAAAWBJDpgEAAADAhAwTLbvkrDnpEAMAAAAALImCGAAAAABgSRTEAAAAAABLYg4xAAAAAJgQyy4lHx1iAAAAAIAlURADAAAAACyJIdMAAAAAYEIsu5R8dIgBAAAAAJZEQQwAAAAAsCQKYgAAAACAJTGHGAAAAABMiGWXko8OMQAAAADAkiiIAQAAAACWxJBpAAAAADAhhkwnHx1iAAAAAIAlURADAAAAACyJghgAAAAAYEnMIQYAAAAAEzKM25sZOGtOOsQAAAAAAEuiIAYAAAAAWBJDpgEAAADAhFh2KfnoEAMAAAAALImCGAAAAABgSRTEAAAAAABLYg4xAAAAAJgQyy4lHx1iAAAAAIAlURADAAAAACyJIdMAAAAAYEIsu5R8dIgBAAAAAJZEQQwAAAAAsCQKYgAAAACAJTGHGAAAAABMyJDzLmd0L2eNSYcYAAAAAGBJFMQAAAAAAEtiyDQAAAAAmJCLYcjFJGOmnTUnHWIAAAAAgCVREAMAAAAALImCGAAAAABgSRTEAAAAAGBChmGuLan+/PNPvfLKK8qRI4c8PDxUtmxZ7d27136/zWZTaGio/P39lTlzZlWvXl2//vprkp6DghgAAAAA4FQuX76sKlWqKGPGjFq7dq0OHz6siRMnKmvWrPZjxo8fr0mTJmnatGnavXu3/Pz8VKdOHUVGRib6ebjKNAAAAADAqbz33nsKCAjQggUL7PsKFChg/2+bzaYpU6ZoyJAhatasmSRp0aJF8vX11dKlS9W9e/dEPQ8dYgAAAAAwIcMwTLVJUkRERIItOjr6ga9t1apVCgkJ0csvv6zcuXMrODhYc+fOtd9/8uRJnTt3TnXr1rXvc3d3V7Vq1bRt27ZEv4cUxAAAAACANBEQECAfHx/7Nnbs2Aced+LECc2cOVNFixbVt99+q9dff11vvfWWPv74Y0nSuXPnJEm+vr4JHufr62u/LzEYMg0AAAAASBNnzpyRt7e3/ba7u/sDj4uPj1dISIjGjBkjSQoODtavv/6qmTNnqn379vbj7nSe77DZbPftexQ6xAAAAACANOHt7Z1ge1hBnCdPHgUGBibYV7JkSYWHh0uS/Pz8JOm+bvD58+fv6xo/CgUxAAAAAJiQi2GuLSmqVKmio0ePJtj322+/KX/+/JKkggULys/PTxs2bLDfHxMTo++//16VK1dO9PMwZBoAAAAA4FT69u2rypUra8yYMWrZsqV27dqlOXPmaM6cOZJuD5Xu06ePxowZo6JFi6po0aIaM2aMPDw81LZt20Q/DwUxAAAAAMCpPPPMM/rqq680ePBgvfvuuypYsKCmTJmidu3a2Y8ZOHCgbty4oZ49e+ry5cuqWLGi1q9fLy8vr0Q/DwUxAAAAAJiRcf9FpZzWE8Rs1KiRGjVq9PBTGoZCQ0MVGhr6xLGYQwwAAAAAsCQKYgAAAACAJVEQAwAAAAAsiTnEAAAAAGBChnF7MwNnzUmHGAAAAABgSRTEAAAAAABLYsg0AAAAAJiQ8e+XGThrTjrEAJzGtchIjRjcXxWDiqpwHh81qVtNB/btcXQspBPfr1iiUa+8oD61gtSnVpDe69pMv2zfYr//5vUofTphuP7zYiW9Wa2EQlvX1vcrljguMNKt2TNnqETRgsqaJZMqVyivH3/c6uhIsIBJ749TNs8MGjygn6OjAE6FDjEApzGg9+s6GvarPpg1X7558mjF8k/Vpml9bdpxQHn88zo6HkwuWy4/Ne05SLmfyi9J2r7mS80c2E1DFq2Wf6Fi+vyDUfpt7w51Cp2sHHmeUtjOH/TphOHyyZlbZavWdXB6pBefL/9MA/r30QdTZ6hS5Sr6aO5sNW1UX/t+Pqx8+fI5Oh7SqX17d2vRgo9UqnQZR0cBnA4dYgBO4caNG1qz6isNCR2jZ6s8r4KFiqj/f4YpIH8BLZ4/x9HxkA6Ueb62girXkG++QvLNV0hNXx8g98weOvnLfknSyV/269kGzVS83LPKmecpPd+0rZ4qUlLhYYccnBzpyYdTJqljpy7q1OU1lShZUhMmTdFTAQGaO3umo6Mhnbp27Zq6dW6vD6bNUtZsWR0dB3A6FMQAnEJcbKzi4uLknilTgv2ZMmfWrh3bHJQK6VV8XJx2b/haMTdvqGBQOUlS4TIh+vnHjbp8/pxsNpuO7t2uv8+cVOCzVR2cFulFTEyM9u/bq1p1Eo44qFW7rnZs5+ccUseAvm+qbr36ql6ztqOjIBW4GObanBEF8V2qV6+uPn36ODpGqli4cKGyZs1qvx0aGqqyZcs6LM/D3JsT1pHFy0vln3lWU94fq3Nn/1JcXJy+/Gyp9u/ZpfN/n3V0PKQTfx47ot41S6lXteJaOn6Iuo+bJf+CRSVJrfqNUJ4CRTS4SSW98XwxTe3bUW3efldFnn7GwamRXly4cEFxcXHKnds3wX5fX1/9/fc5B6VCevbl55/pwP59Gv7uGEdHAZwWc4jhVFq1aqUGDRo4OgYc5IPZ89W/V3eFBBaUq6urSj8drKYtWuuXn/c7OhrSCd/8hTRk0Te6cS1C+zav06JRb6vfjGXyL1hUm5Yv1Mlf96vn+LnKnievft+/6/Yc4hy5VbLCc46OjnTEMBK2SWw22337gOT6448zGjygr75ctVaZ7hl9BeD/URCnEJvNpri4OGXIwFv6MLdu3VLGjBkfeUzmzJmVOXPmNEoEZ1OgYGF9+c13uh4VpcjICPn65VGPzu0UkK+Ao6MhnciQ0U25AwpIkvKXLKPTYT9r82cL9HKf4frfrAl6fdwsBVWpKUl6qkhJ/fH7YW1YOpeCGCkiZ86ccnV1va8bfP78+fu6xkByHdy/T//8c141nqtg3xcXF6dtP27V3NnT9ffl63J1dXVgQqQEwzBM8wc1Z83JkOmHWLJkiUJCQuTl5SU/Pz+1bdtW58+ft9+/ZcsWGYahb7/9ViEhIXJ3d9fWrVsVGRmpdu3aydPTU3ny5NHkyZPvG4odExOjgQMHKm/evPL09FTFihW1ZcuWx2ZatWqVQkJClClTJuXMmVPNmjVL9jkfJT4+Xu+9956KFCkid3d35cuXT6NHj7bfP2jQIBUrVkweHh4qVKiQhg0bplu3btnvvzMse/78+SpUqJDc3d1ls9l05coVdevWTb6+vsqUKZNKly6t1atXS3r40O7FixerQIEC8vHxUevWrRUZGWk/Jjo6Wm+99ZZy586tTJky6bnnntPu3bvt99/9vQoODlbmzJlVs2ZNnT9/XmvXrlXJkiXl7e2tNm3a6Pr16/bHrVu3Ts8995yyZs2qHDlyqFGjRjp+/Hiy3lMkjoenp3z98ujKlcv6fuMG1W3Q2NGRkE7ZbDbduhWjuLhbiou9JcMl4T+LLi6ustniHZQO6Y2bm5uCy5XXpu82JNi/aeMGPVupsoNSIb2qWr2mftp1QD9s32vfgsuF6OVWbfXD9r0Uw8C/aGc+RExMjEaNGqXixYvr/Pnz6tu3rzp27Kg1a9YkOG7gwIGaMGGCChUqpKxZs6pfv3766aeftGrVKvn6+mr48OHat29fgvm6nTp10qlTp7Rs2TL5+/vrq6++0gsvvKBDhw6paNGiD8zzzTffqFmzZhoyZIgWL16smJgYffPNN8k65+MMHjxYc+fO1eTJk/Xcc8/p7NmzOnLkiP1+Ly8vLVy4UP7+/jp06JC6du0qLy8vDRw40H7MsWPHtHz5cn355ZdydXVVfHy86tevr8jISC1ZskSFCxfW4cOHH/lD+fjx41q5cqVWr16ty5cvq2XLlho3bpy9OB84cKC+/PJLLVq0SPnz59f48eNVr149HTt2TNmzZ7efJzQ0VNOmTZOHh4datmypli1byt3dXUuXLtW1a9f00ksvaerUqRo0aJAkKSoqSv369VNQUJCioqI0fPhwvfTSSzpw4IBcXB78t6To6GhFR0fbb0dERDzRe29VWzaul81mU+GixXTqxHH9d/hgFSpaTK3adXB0NKQDK2e+r1KVqimbr7+io65p93df67f9O/Tm5IXK7OmlosEVtWLaWGV0z6Qcfnn12/6d2rF2hVr0Huro6EhH3urTT106vqpy5UNU8dlKmvfRHJ0JD9dr3V53dDSkM15eXgosVTrBPg9PD2XPnuO+/YCVURA/ROfOne3/XahQIX344YeqUKGCrl27pixZstjve/fdd1WnTh1JUmRkpBYtWqSlS5eqVq1akqQFCxbI39/ffvzx48f16aef6o8//rDvf/vtt7Vu3TotWLBAY8Y8+KIHo0ePVuvWrTVy5Ej7vqeffjpZ53yUyMhIffDBB5o2bZo6dLhdjBQuXFjPPff/wwaHDv3/XxILFCig/v3767PPPktQEMfExGjx4sXKlSuXJGn9+vXatWuXwsLCVKxYMUm3399HiY+P18KFC+Xl5SVJevXVV7Vx40aNHj1aUVFRmjlzphYuXKj69etLkubOnasNGzZo3rx5GjBggP08//3vf1WlShVJUpcuXTR48GAdP37c/vwtWrTQ5s2b7QVx8+bNE+SYN2+ecufOrcOHD6t06Qf/QzJ27NgE3yMkTWREhMa9O1Rn//pTWbNlV/3GTTVo6LuPHWoPJEbEpQtaMLKfIi7+o8xZvJS3cAm9OXmhAis8L0l6bdRUrZw5XvNH9NH1iCvK7pdXTV5/W1Vfaufg5EhPXm7ZSpcuXtSY0e/q3NmzKlWqtFZ+vUb58+d3dDQAsCQK4ofYv3+/QkNDdeDAAV26dEnx8beHzIWHhyswMNB+XEhIiP2/T5w4oVu3bqlChf+fq+Hj46PixYvbb+/bt082m81eDN4RHR2tHDlySFKCgvuVV17RrFmzdODAAXXt2vWBWRNzzkfZunWrvZiUpNmzZ6to0aKKjo62F/YP8sUXX2jKlCk6duyYrl27ptjYWHl7eyc4Jn/+/PZiWJIOHDigp5566r6sj1KgQAF7MSxJefLksQ9fP378uG7dumUvdCUpY8aMqlChgsLCwhKcp0yZ/1+M3tfX1z7U++59u3btst8+fvy4hg0bph07dujChQsJPgMPK4gHDx6sfv362W9HREQoICAg0a/V6hq/1EKNX2rh6BhIp9oPee+R9/vkyKUOQ99PozSwsu49eqp7j56OjgELWr1uk6MjIIUZxu3NDJw1JwXxA0RFRalu3bqqW7eulixZoly5cik8PFz16tVTTExMgmM9PT3t/22z2SQ9+OqRd8THx8vV1VV7994/d+NOIXzgwAH7vjsF5qMuNJWYcz5KSEhIguf09fXVqVOnHvmYHTt22DvW9erVk4+Pj5YtW6aJEycmOO7u9+dxr+Nh7u0OGoZhL04f9Z7fu+/u8xiG8cjzSlLjxo0VEBCguXPnyt/fX/Hx8SpduvR9n4G7ubu7y93dPQmvDgAAAICjUBA/wJEjR3ThwgWNGzfO3t3bs2fPYx9XuHBhZcyYUbt27bI/LiIiQr///ruqVasmSQoODlZcXJzOnz+v559//oHnKVKkyH37ypQpo40bN6pTp0733ZeYcz5K5syZ73vOokWLKnPmzNq4caNee+21+x7z008/KX/+/BoyZIh93+nTpx/7XGXKlNEff/yh3377LUld4ocpUqSI3Nzc9OOPP6pt27aSbl/Nes+ePclaU/rixYsKCwvT7Nmz7e/pjz/+mOy8AAAAAJwHBfED5MuXT25ubpo6dapef/11/fLLLxo1atRjH+fl5aUOHTpowIAByp49u3Lnzq0RI0bIxcXF3q0sVqyY2rVrp/bt22vixIkKDg7WhQsXtGnTJgUFBT10Dd4RI0aoVq1aKly4sFq3bq3Y2FitXbtWAwcOfOJzPkqmTJk0aNAgDRw4UG5ubqpSpYr++ecf/frrr+rSpYuKFCmi8PBwLVu2TM8884y++eYbffXVV489b7Vq1VS1alU1b95ckyZNUpEiRXTkyBEZhqEXXnghyTk9PT3Vo0cP+3ueL18+jR8/XtevX1eXLl2SfL47smXLphw5cmjOnDnKkyePwsPD9Z///OeJzwcAAACkNBfDkIuzjkW+h7PmZNmlB8iVK5cWLlyozz//XIGBgRo3bpwmTJiQqMdOmjRJlSpVUqNGjVS7dm1VqVJFJUuWTLAg+oIFC9S+fXv1799fxYsX14svvqidO3c+cq5p9erV9fnnn2vVqlUqW7asatasqZ07dybrnI8zbNgw9e/fX8OHD1fJkiXVqlUr+9zdJk2aqG/fvurVq5fKli2rbdu2adiwYYk675dffqlnnnlGbdq0UWBgoAYOHKi4uLgnzjlu3Dg1b95cr776qsqVK6djx47p22+/VbZs2Z74nC4uLlq2bJn27t2r0qVLq2/fvnr/feYWAgAAAOmJYbt7gitSXFRUlPLmzauJEycmq2MJc4qIiJCPj4/CTv8jr3suOAakhtVH/nJ0BFhMh5ACjo4Ai7kZ8+R/RAeSIiIiQvnzZNfVq1fvu3Cso935HbPR1C3KmPnx1wxyBrduXNPqN6s73fvJkOkUtn//fh05ckQVKlTQ1atX9e6770q63VEFAAAAADgPCuJUMGHCBB09elRubm4qX768tm7dqpw5czo6FgAAAIB0hGWXko+COIUFBwdr7969jo4BAAAAAHgMLqoFAAAAALAkOsQAAAAAYEKGYdiXd3V2zpqTDjEAAAAAwJIoiAEAAAAAlkRBDAAAAACwJOYQAwAAAIAJsexS8tEhBgAAAABYEgUxAAAAAMCSGDINAAAAACbkYhhycdaxyPdw1px0iAEAAAAAlkRBDAAAAACwJApiAAAAAIAlMYcYAAAAAEzI+HczA2fNSYcYAAAAAGBJFMQAAAAAAEtiyDQAAAAAmJBhGDKcdDmjezlrTjrEAAAAAABLoiAGAAAAAFgSBTEAAAAAwJKYQwwAAAAAJuRi3N7MwFlz0iEGAAAAAFgSBTEAAAAAwJIoiAEAAAAAlsQcYgAAAAAwIdYhTj46xAAAAAAAS6IgBgAAAABYEkOmAQAAAMCknHQksmnQIQYAAAAAWBIFMQAAAADAkiiIAQAAAACWxBxiAAAAADAhll1KPjrEAAAAAABLoiAGAAAAAFgSQ6YBAAAAwIRcjNubGThrTjrEAAAAAABLSlSHeNWqVYk+4YsvvvjEYQAAAAAASCuJKoibNm2aqJMZhqG4uLjk5AEAAAAAIE0kqiCOj49P7RwAAAAAgCRg2aXkS9Yc4ps3b6ZUDgAAAAAA0lSSC+K4uDiNGjVKefPmVZYsWXTixAlJ0rBhwzRv3rwUDwgAAAAAQGpIckE8evRoLVy4UOPHj5ebm5t9f1BQkD766KMUDQcAAAAAeDDDZJszSnJB/PHHH2vOnDlq166dXF1d7fvLlCmjI0eOpGg4AAAAAABSS5IL4j///FNFihS5b398fLxu3bqVIqEAAAAAAEhtSS6IS5Uqpa1bt963//PPP1dwcHCKhAIAAAAAILUlatmlu40YMUKvvvqq/vzzT8XHx2vFihU6evSoPv74Y61evTo1MgIAAAAA7uFiGHJx0uWM7uWsOZPcIW7cuLE+++wzrVmzRoZhaPjw4QoLC9PXX3+tOnXqpEZGAAAAAABSXJI7xJJUr1491atXL6WzAAAAAACQZp6oIJakPXv2KCwsTIZhqGTJkipfvnxK5gIAAAAAPIJh3N7MwFlzJrkg/uOPP9SmTRv99NNPypo1qyTpypUrqly5sj799FMFBASkdEYAAAAAAFJckucQd+7cWbdu3VJYWJguXbqkS5cuKSwsTDabTV26dEmNjAAAAAAApLgkd4i3bt2qbdu2qXjx4vZ9xYsX19SpU1WlSpUUDQcAAAAAQGpJckGcL18+3bp16779sbGxyps3b4qEAgAAAAA8mmEYMpx1cu49nDVnkodMjx8/Xm+++ab27Nkjm80m6fYFtnr37q0JEyakeEAAAAAAAFJDojrE2bJlS1DRR0VFqWLFisqQ4fbDY2NjlSFDBnXu3FlNmzZNlaAAAAAAAKSkRBXEU6ZMSeUYAAAAAICkYNml5EtUQdyhQ4fUzgEAAAAAQJpK8kW17nbjxo37LrDl7e2drEAAAAAAAKSFJF9UKyoqSr169VLu3LmVJUsWZcuWLcEGAAAAAIAZJLkgHjhwoDZt2qQZM2bI3d1dH330kUaOHCl/f399/PHHqZERAAAAAHAPF8Mw1eaMkjxk+uuvv9bHH3+s6tWrq3Pnznr++edVpEgR5c+fX5988onatWuXGjkBAAAAAEhRSe4QX7p0SQULFpR0e77wpUuXJEnPPfecfvjhh5RNBwAAAABAKklyQVyoUCGdOnVKkhQYGKjly5dLut05zpo1a0pmAwAAAAA8xJ1ll8yyOaMkF8SdOnXSwYMHJUmDBw+2zyXu27evBgwYkOIBAQAAAABIDUmeQ9y3b1/7f9eoUUNHjhzRnj17VLhwYT399NMpGg4AAAAAgNSS5A7xvfLly6dmzZope/bs6ty5c0pkAgAAAAAg1SW7IL7j0qVLWrRoUUqdDgAAAADwCIZhmGpzRilWEAMAAAAAYCZJnkMMIOmyemSUt0dGR8eABXQIKeDoCLCYbp8ddHQEWMycVlyzBmkjxs3V0RGQBiiIAQAAAMCEXGSeIb/OmjPRBXGzZs0eef+VK1eSmwUAAAAAgDST6ILYx8fnsfe3b98+2YEAAAAAAEgLiS6IFyxYkJo5AAAAAABIU8whBgAAAAATcubljO7lrDmddW4zAAAAAACpioIYAAAAAGBJDJkGAAAAABMyDMnFOUci38dJR0zTIQYAAAAAWNMTFcSLFy9WlSpV5O/vr9OnT0uSpkyZov/9738pGg4AAAAAgNSS5IJ45syZ6tevnxo0aKArV64oLi5OkpQ1a1ZNmTIlpfMBAAAAAJAqklwQT506VXPnztWQIUPk6upq3x8SEqJDhw6laDgAAAAAwIO5GObanFGSC+KTJ08qODj4vv3u7u6KiopKkVAAAAAAAKS2JBfEBQsW1IEDB+7bv3btWgUGBqZEJgAAAAAAUl2Sl10aMGCA3njjDd28eVM2m027du3Sp59+qrFjx+qjjz5KjYwAAAAAgHsYhiHDWdczuoez5kxyQdypUyfFxsZq4MCBun79utq2bau8efPqgw8+UOvWrVMjIwAAAAAAKS7JBbEkde3aVV27dtWFCxcUHx+v3Llzp3QuAAAAAABS1RMVxHfkzJkzpXIAAAAAAJCmklwQFyxY8JHjv0+cOJGsQAAAAACAx3Pm5Yzu5aw5k1wQ9+nTJ8HtW7duaf/+/Vq3bp0GDBiQUrkAAAAAAEhVSS6Ie/fu/cD906dP1549e5IdCAAAAACAtJDkdYgfpn79+vryyy9T6nQAAAAAgEcwDHNtzijFCuIvvvhC2bNnT6nTAQAAAACQqpI8ZDo4ODjBRbVsNpvOnTunf/75RzNmzEjRcAAAAAAApJYkF8RNmzZNcNvFxUW5cuVS9erVVaJEiZTKBQAAAABAqkpSQRwbG6sCBQqoXr168vPzS61MAAAAAIDHcDEMuTjr5Nx7OGvOJM0hzpAhg3r06KHo6OjUygMAAAAAQJpI8kW1KlasqP3796dGFgAAAAAA0kyS5xD37NlT/fv31x9//KHy5cvL09Mzwf1lypRJsXAAAAAAgAdzUQouG5TKnDVnogvizp07a8qUKWrVqpUk6a233rLfZxiGbDabDMNQXFxcyqcEAAAAACCFJbogXrRokcaNG6eTJ0+mZh4AAAAAANJEogtim80mScqfP3+qhQEAAAAAIK0kaQ6x4aSXygYAAAAAqzGM25sZOGvOJBXExYoVe2xRfOnSpWQFAgAAAAAgLSSpIB45cqR8fHxSKwsAAAAAAGkmSQVx69atlTt37tTKAgAAAABIJBcZcnHWscj3cJFz5kz0clDMHwYAAAAApCeJLojvXGUaAAAAAID0INFDpuPj41MzBwAAAAAAaSpJc4gBAAAAAM6BZZeSL9FDpgEAAAAASE8oiAEAAAAAlsSQaQAAAAAwIRfj9mYGzpqTDjEAAAAAwJIoiAEAAAAAlkRBDAAAAACwJOYQAwAAAIAJGYbk4qzrGd3DWWPSIQYAAAAAWBIFMQAAAADAkhgyDQAAAAAmZBjOOxT5Xs6akw4xAAAAAMCSKIgBAAAAAJZEQQwAAAAAsCTmEAMAAACACbkYtzczcNacdIgBAAAAAJZEQQwAAAAAsCSGTAMAAACACRn/fpmBs+akQwwAAAAAsCQKYgAAAACAJVEQAwAAAAAsiTnEAAAAAGBCLLuUfHSIAQAAAACWREEMAAAAALAkhkwDAAAAgAkxZDr56BADAAAAACyJghgAAAAAYEkUxAAAAAAAS2IOMQAAAACYkGEYMgwnnZx7D2fNSYcYAAAAAGBJFMQAnMaPW39Qi5deVOECeeXp7qKv/7fS0ZFgAbNnzlCJogWVNUsmVa5QXj/+uNXRkZAOvBTkq4/bPZ1g+7BZYIL7xzUqrrmtSmtmi1IaVLOQCuXwcGBipFf8jAMejSHTAJxGVFSUgsqU0asdOqptqxaOjgML+Hz5ZxrQv48+mDpDlSpX0UdzZ6tpo/ra9/Nh5cuXz9HxYHJ/XLmh9zaesN+Ot9ns/30uMlqL9/yp89di5OZqqF6JXBpYs5AGrApTZHScI+IiHeJnHPB4dIgBOI16L9TXiJH/VZOmzRwdBRbx4ZRJ6tipizp1eU0lSpbUhElT9FRAgObOnunoaEgH4uKlqzdj7dvdhe72U1f067lr+udajP68Gq2le/+Sh5urArJmdmBipDf8jEv/7qxDbJbNGVEQAwAsKSYmRvv37VWtOnUT7K9Vu652bN/moFRIT/y83fTBS4Ga2KSEelbJp1xZ3B54nKuLoRpFcygqJk7hV26kcUqkV/yMAxKHIdMAAEu6cOGC4uLilDu3b4L9vr6++vvvcw5KhfTi+MXrmr3tjM5FRssnUwa9WNpXw+oW0Turj+pazO1Ocdm8XupZJb/cMrjoyo1Yjd94XNcYLo0Uws84IHHoEANJUKBAAU2ZMsXRMQCkoHuXgbDZbE67NATM4+e/IrXnzFX9ceWmfj13TRM3n5QkPVcom/2Yw+eiNHTNbxr17TEd+itCvZ7PLy93ehVIWfyMS98Mw1ybM6IgBgBYUs6cOeXq6npfp+T8+fP3dVSA5IqJi9cfV27K18s9wb7z12J0/OJ1zdv5h+LipWpFsjswJdITfsYBiUNBjHTl1q1bjo4AwCTc3NwUXK68Nn23IcH+TRs36NlKlR2UCulVBhdD/j7uunIj9qHHGIaU0VmvOgPT4WcckDgUxHCo6tWr66233tLAgQOVPXt2+fn5KTQ01H5/eHi4mjRpoixZssjb21stW7bU33//bb8/NDRUZcuW1fz581WoUCG5u7vbhwLNnj1bjRo1koeHh0qWLKnt27fr2LFjql69ujw9PVWpUiUdP37cfq7jx4+rSZMm8vX1VZYsWfTMM8/ou+++S9LriY6OVkRERIINiXft2jUdPHhABw8ekCSdOnVSBw8e0JnwcMcGQ7r1Vp9+WjD/Iy1aMF9HwsI0oH9fnQkP12vdXnd0NJhc6+A8Kp7bUzk93VQoh4fefD6/Mmd01Y8nL8nN1UUtnvZT4RweyuGZUfmzZVbnik8pm0dG7Qq/4ujoSEf4GQc8HhNV4HCLFi1Sv379tHPnTm3fvl0dO3ZUlSpVVLt2bTVt2lSenp76/vvvFRsbq549e6pVq1basmWL/fHHjh3T8uXL9eWXX8rV1dW+f9SoUZo0aZImTZqkQYMGqW3btipUqJAGDx6sfPnyqXPnzurVq5fWrl0r6XYx1qBBA/33v/9VpkyZtGjRIjVu3FhHjx5N9Fp9Y8eO1ciRI1P0/bGSfXv3qH7dmvbb/xnYX5LU7tUOmvPRAkfFQjr2cstWunTxosaMflfnzp5VqVKltfLrNcqfP7+jo8HksntkVM8q+eXl7qqI6DgdvxClket+18WoW8roYsjf213PVS0gL3dXXYuO08mL1zV6/TH9eTXa0dGRjvAzLv1zMQy5OOvk3Hs4a07DZrtrlXggjVWvXl1xcXHaunWrfV+FChVUs2ZN1apVS/Xr19fJkycVEBAgSTp8+LBKlSqlXbt26ZlnnlFoaKjGjBmjP//8U7ly5bKfwzAMDR06VKNGjZIk7dixQ5UqVdK8efPUuXNnSdKyZcvUqVMn3bjx8CUuSpUqpR49eqhXr16Sbl9Uq0+fPurTp88Dj4+OjlZ09P//MhMREaGAgACd/eeKvL29n+xNApLAheGWSGPdPjvo6AiwmDmtnnZ0BFhERESEfHP46OrVq073e1xERIR8fHw0du1BZfL0cnScRLkZFanB9Z9+4vdz7Nixeuedd9S7d2/7RW5tNptGjhypOXPm6PLly6pYsaKmT5+uUqVKJfq8DJmGw5UpUybB7Tx58uj8+fMKCwtTQECAvRiWpMDAQGXNmlVhYWH2ffnz509QDD/ovL6+ty8eERQUlGDfzZs37cOao6KiNHDgQPtzZMmSRUeOHFF4Eobruru7y9vbO8EGAAAA4Mnt3r1bc+bMua9uGD9+vCZNmqRp06Zp9+7d8vPzU506dRQZGZnoc1MQw+EyZsyY4LZhGIqPj3/osgD37vf09Hzsee8c/6B98fHxkqQBAwboyy+/1OjRo7V161YdOHBAQUFBiomJecJXBgAAAKQeF8Nc25O4du2a2rVrp7lz5ypbtv9fus5ms2nKlCkaMmSImjVrptKlS2vRokW6fv26li5dmvj38MliAakvMDBQ4eHhOnPmjH3f4cOHdfXqVZUsWTLFn2/r1q3q2LGjXnrpJQUFBcnPz0+nTp1K8ecBAAAArOreC9DePd3wQd544w01bNhQtWvXTrD/5MmTOnfunOrWrWvf5+7urmrVqmnbtm2JzkNBDKdVu3ZtlSlTRu3atdO+ffu0a9cutW/fXtWqVVNISEiKP1+RIkW0YsUKHThwQAcPHlTbtm3t3WMAAAAAyRcQECAfHx/7Nnbs2Iceu2zZMu3du/eBx5w7d3uN7TtTI+/w9fW135cYXGUaTsswDK1cuVJvvvmmqlatKhcXF73wwguaOnVqqjzf5MmT1blzZ1WuXFk5c+bUoEGDWDYJAAAASEFnzpxJcJ0dd3f3hx7Xu3dvrV+/XpkyZXro+e6dYvmwaZcPfTxXmQZSz50rAHKVaaQVrjKNtMZVppHWuMo00ooZrjL93rcHldkkV5m+ERWpQfUSf5XplStX6qWXXkqwrGpcXJwMw5CLi4uOHj2qIkWKaN++fQoODrYf06RJE2XNmlWLFi1KVC6GTAMAAAAAnEqtWrV06NAhHThwwL6FhISoXbt2OnDggAoVKiQ/Pz9t2LDB/piYmBh9//33qly5cqKfhyHTAAAAAACn4uXlpdKlSyfY5+npqRw5ctj39+nTR2PGjFHRokVVtGhRjRkzRh4eHmrbtm2in4eCGAAAAABMyEWGXGSO6VKpkXPgwIG6ceOGevbsqcuXL6tixYpav369vLwSP4ycghgAAAAA4PS2bNmS4LZhGAoNDVVoaOgTn5M5xAAAAAAAS6IgBgAAAABYEkOmAQAAAMCEDOP2ZgbOmpMOMQAAAADAkiiIAQAAAACWxJBpAAAAADAhF+P2ZgbOmpMOMQAAAADAkiiIAQAAAACWREEMAAAAALAk5hADAAAAgAm5GIZcnHU9o3s4a046xAAAAAAAS6IgBgAAAABYEkOmAQAAAMCEDOP2ZgbOmpMOMQAAAADAkiiIAQAAAACWREEMAAAAALAk5hADAAAAgAm5yETLLsk5c9IhBgAAAABYEgUxAAAAAMCSGDINAAAAACbEskvJR4cYAAAAAGBJFMQAAAAAAEuiIAYAAAAAWBJziAEAAADAhFxkng6ns+Z01lwAAAAAAKQqCmIAAAAAgCUxZBoAAAAATMgwDBnOup7RPZw1Jx1iAAAAAIAlURADAAAAACyJghgAAAAAYEnMIQYAAAAAEzL+3czAWXPSIQYAAAAAWBIFMQAAAADAkhgyDQAAAAAm5GIYcnHS5Yzu5aw56RADAAAAACyJghgAAAAAYEkUxAAAAAAAS2IOMQAAAACYlHPOzDUPOsQAAAAAAEuiIAYAAAAAWBJDpgEAAADAhAzj9mYGzpqTDjEAAAAAwJIoiAEAAAAAlkRBDAAAAACwJOYQAwAAAIAJGYYhw1kn597DWXPSIQYAAAAAWBIFMQAAAADAkhgyDQAAAAAm5CLzdDidNaez5gIAAAAAIFVREAMAAAAALImCGAAAAABgScwhBgAAAAATYtml5KNDDAAAAACwJApiAAAAAIAlMWQaAAAAAEzI+HczA2fNSYcYAAAAAGBJFMQAAAAAAEuiIAYAAAAAWBJziAEAAADAhFh2KfnoEAMAAAAALImCGAAAAABgSQyZBgAAAAATcpF5OpzOmtNZcwEAAAAAkKooiAEAAAAAlkRBDAAAAACwJOYQAwAAAIAJsexS8lEQA2ng2s1YGW6xjo4BC/DxyOjoCLCYOa2ednQEWEzuVz92dARYhO3WDUdHQBpgyDQAAAAAwJLoEAMAAACACRn/bmbgrDnpEAMAAAAALImCGAAAAABgSRTEAAAAAABLYg4xAAAAAJiQYdzezMBZc9IhBgAAAABYEgUxAAAAAMCSGDINAAAAACbkIkMuTrugUULOmpMOMQAAAADAkiiIAQAAAACWREEMAAAAALAk5hADAAAAgAmx7FLy0SEGAAAAAFgSBTEAAAAAwJIYMg0AAAAAJmT8+2UGzpqTDjEAAAAAwJIoiAEAAAAAlkRBDAAAAACwJOYQAwAAAIAJsexS8tEhBgAAAABYEgUxAAAAAMCSGDINAAAAACZkyJCLky5ndC+WXQIAAAAAwIlQEAMAAAAALImCGAAAAABgScwhBgAAAAATYtml5KNDDAAAAACwJApiAAAAAIAlURADAAAAACyJOcQAAAAAYELMIU4+OsQAAAAAAEuiIAYAAAAAWBJDpgEAAADAhIx/v8zAWXPSIQYAAAAAWBIFMQAAAADAkiiIAQAAAACWxBxiAAAAADAhF+P2ZgbOmpMOMQAAAADAkiiIAQAAAACWxJBpAAAAADAhll1KPjrEAAAAAABLoiAGAAAAAFgSBTEAAAAAwJKYQwwAAAAAJmQYtzczcNacdIgBAAAAAJZEQQwAAAAAsCSGTAMAAACACRly3uWM7uWsKekQAwAAAAAsiYIYAAAAAGBJFMQAAAAAAEtiDjEAAAAAmJCLcXszA2fNSYcYAAAAAGBJFMQAAAAAAEtiyDQAAAAAmJDx75cZOGtOOsQAAAAAAEuiIAYAAAAAWBIFMQAAAADAkphDDAAAAAAmZBi3NzNw1px0iAEAAAAAlkRBDAAAAACwJIZMAwAAAIAJGf9uZuCsOekQAwAAAAAsiYIYAAAAAGBJFMQAAAAAAEtiDjEAAAAAmJCLDLk463pG93Bx0lnEdIgBAAAAAJZEQQwAAAAAsCSGTAMAAACACbHsUvLRIQbgNEKCisrPx+2+7T/933J0NKRjs2fOUImiBZU1SyZVrlBeP/641dGRkM7xmUNqcHUxNKxlWf38wUv6e1FbHZzykgY1K6O7p5cObv609kxoorML2uj03Fb63zt1FFI4p+NCA06ADjEAp7Fu8zbFx8XZbx85/KtaNq2vxk2bOzAV0rPPl3+mAf376IOpM1SpchV9NHe2mjaqr30/H1a+fPkcHQ/pEJ85pJa+L5ZW59rF9PrMnxR25oqCC+XQjNerKOJ6jGauOyJJOnY2Qm8v3KVT5yOVyc1Vb9QP1Ffv1FbZPl/pYmS0g18B4Bh0iAE4jZw5cym3r5992/DtGhUoWFiVn6vq6GhIpz6cMkkdO3VRpy6vqUTJkpowaYqeCgjQ3NkzHR0N6RSfOaSWCkVz6Zs9Z/Tt/j8VfiFK/9sVrk0//6XgQjnsx3y+7aS2/HJWp85f05E/ruqdJXvk4+Gm0vmyOTA54FgUxACcUkxMjL78bKnavNJBhkmWE4C5xMTEaP++vapVp26C/bVq19WO7dsclArpGZ85pKbtR8+rWuk8KuLnJUkqnS+bKpXIrfUH/nzg8RldXdSxZlFdiYrRofDLaRkVKckw2eaEGDJtEaGhoVq5cqUOHDggSerYsaOuXLmilStXOjTXve7NCetau/p/unr1ilq1a+/oKEinLly4oLi4OOXO7Ztgv6+vr/7++5yDUiE94zOH1DR51S/y9sioPRObKi7eJlcXQ+8u368vtp1KcNwLwXk1/62q8nDLoHNXbqjpmA26xHBpWBgFMZzK22+/rTfffNPRMeAEPl28UDXr1JNfHn9HR0E6d+8IBJvNxqgEpCo+c0gNzSsVUKvnCqnLtK0K++OKyuTPrnHtn9G5y9e19IcT9uN+OPy3nvvPauXwcleHmkW1sHdV1Ry2VhcibjowPeA4DJlGmomJiXnsMVmyZFGOHDkeexzStzPhp/XDlo1q176zo6MgHcuZM6dcXV3v68ydP3/+vg4ekBL4zCE1jWpXXpP/94u+3H5Kh89c0bIfT2j62sPq92JQguOuR8fqxN+R2n3sgnrN2a64OJva1yjioNRILsNkX87IoQXxF198oaCgIGXOnFk5cuRQ7dq1FRUVpbi4OPXr109Zs2ZVjhw5NHDgQHXo0EFNmza1P7ZAgQKaMmVKgvOVLVtWoaGh9tuTJk1SUFCQPD09FRAQoJ49e+ratWv2+xcuXKisWbNq9erVKl68uDw8PNSiRQtFRUVp0aJFKlCggLJly6Y333xTcXdd+fby5ctq3769smXLJg8PD9WvX1+///67/f7Q0FCVLVs2QbYpU6aoQIEC9ttbtmxRhQoV5OnpqaxZs6pKlSo6ffr0I9+v+fPnq1SpUnJ3d1eePHnUq1cv+31Xr15Vt27dlDt3bnl7e6tmzZo6ePDgI8/3ONHR0Ro4cKACAgLk7u6uokWLat68eZKkuLg4denSRQULFlTmzJlVvHhxffDBBwke37FjRzVt2lRjx46Vv7+/ihUrJkn6448/1Lp1a2XPnl2enp4KCQnRzp07Jd3/3t05x4QJE5QnTx7lyJFDb7zxhm7dumU/5nHfjyf9Pi9ZskQhISHy8vKSn5+f2rZtq/PnzyfrPUXiLPtkkXLmyq3a9Ro4OgrSMTc3NwWXK69N321IsH/Txg16tlJlB6VCesZnDqnJwy2D4m22BPvi4m1ycXl0EWIYknsG19SMBjg1hw2ZPnv2rNq0aaPx48frpZdeUmRkpLZu3SqbzaaJEydq/vz5mjdvngIDAzVx4kR99dVXqlmzZpKew8XFRR9++KEKFCigkydPqmfPnho4cKBmzJhhP+b69ev68MMPtWzZMkVGRqpZs2Zq1qyZsmbNqjVr1ujEiRNq3ry5nnvuObVq1UrS7SLt999/16pVq+Tt7a1BgwapQYMGOnz4sDJmzPjYXLGxsWratKm6du2qTz/9VDExMdq1a9cjh0vNnDlT/fr107hx41S/fn1dvXpVP/30k6TbQ60aNmyo7Nmza82aNfLx8dHs2bNVq1Yt/fbbb8qePXuS3rc72rdvr+3bt+vDDz/U008/rZMnT+rChQuSpPj4eD311FNavny5cubMqW3btqlbt27KkyePWrZsaT/Hxo0b5e3trQ0bNshms+natWuqVq2a8ubNq1WrVsnPz0/79u1TfHz8Q3Ns3rxZefLk0ebNm3Xs2DG1atVKZcuWVdeuXSUl7vvxJN/nmJgYjRo1SsWLF9f58+fVt29fdezYUWvWrHlo1ujoaEVH//88nIiIiCd6760sPj5eyz75WC3bvKIMGZjVgdT1Vp9+6tLxVZUrH6KKz1bSvI/m6Ex4uF7r9rqjoyGd4jOH1LJ23xm93TRIf1yMUtiZKypTILt6NQjU4i3HJEke7hn0dtMgrd17Rueu3FD2LO56rU5x+Wf31Fc7Tzk2POBADi2IY2Nj1axZM+XPn1+SFBR0e0jHlClTNHjwYDVvfnvt0VmzZunbb79N8nP06dPH/t8FCxbUqFGj1KNHjwQF8a1btzRz5kwVLlxYktSiRQstXrxYf//9t7JkyaLAwEDVqFFDmzdvVqtWreyF108//aTKlW//NfeTTz5RQECAVq5cqZdffvmxuSIiInT16lU1atTI/rwlS5Z85GP++9//qn///urdu7d93zPPPCPpdsF46NAhnT9/Xu7u7pKkCRMmaOXKlfriiy/UrVu3RLxbCf32229avny5NmzYoNq1a0uSChUqZL8/Y8aMGjlypP12wYIFtW3bNi1fvjxBQezp6amPPvpIbm5ukqQ5c+bon3/+0e7du+2FepEijx6mky1bNk2bNk2urq4qUaKEGjZsqI0bN6pr166J/n4k9fssSZ07//9w3UKFCunDDz9UhQoVdO3aNWXJkuWBWceOHZvgfUHS/bB5o/48E642r3Z0dBRYwMstW+nSxYsaM/pdnTt7VqVKldbKr9fY/10CUhqfOaSWAQt3aWjLsprYqaJy+WTSucs3tGDjbxr35c+SpLj4eBXz91bbqtWVw8tdl65Fa9/xi3ph5Dod+eOqg9MDjuOwgvjpp59WrVq1FBQUpHr16qlu3bpq0aKFXFxcdPbsWVWqVOn/Q2bIoJCQENnuGQbyOJs3b9aYMWN0+PBhRUREKDY2Vjdv3lRUVJQ8PT0lSR4eHvYiSbp9pccCBQokKHh8fX3tQ2XDwsKUIUMGVaxY0X5/jhw5VLx4cYWFhSUqV/bs2dWxY0fVq1dPderUUe3atdWyZUvlyZNH4eHhCgwMtB/7zjvv6LXXXtNff/2lWrVqPfB8e/fu1bVr1+6be3vjxg0dP378sXk++eQTde/e3X577dq1Onv2rFxdXVWtWrWHPm7WrFn66KOPdPr0ad24cUMxMTH3DRUPCgqyF8OSdODAAQUHByepa12qVCm5uv7/UJ48efLo0KFDkhL//Ujq91mS9u/fr9DQUB04cECXLl2yd7Hv/R7dbfDgwerXr5/9dkREhAICAhL9WiFVr1VH564+fr45kFK69+ip7j16OjoGLITPHFLDtZux+s/He/Sfj/c88P7oW/F6ZfL3aZwKqc64PezdFJw0p8MKYldXV23YsEHbtm3T+vXrNXXqVA0ZMkQbNmx4/IN1ezj0vQXy3fNKT58+rQYNGuj111/XqFGjlD17dv3444/q0qVLguPuHeJsGMYD990phh5WlN99hcjHZZOkBQsW6K233tK6dev02WefaejQodqwYYNCQkISLDmUPXv2xw7Djo+PV548ebRly5b77suaNesjHytJL774YoKCMm/evPruu+8e+Zjly5erb9++mjhxoipVqiQvLy+9//779rnAd9z5w8MdmTNnfmyeeyX3+/GwczzqvFFRUapbt67q1q2rJUuWKFeuXAoPD1e9evUeeXEwd3d3e5ceAAAAgHNz6EW1DMNQlSpVNHLkSO3fv19ubm7auHGj8uTJox07dtiPi42N1d69exM8NleuXDp79qz9dkREhE6ePGm/vWfPHsXGxmrixIl69tlnVaxYMf3111/JzhwYGKjY2NgEhd/Fixf122+/2Yc958qVS+fOnUtQrD1oXd3g4GANHjxY27ZtU+nSpbV06VJlyJBBRYoUsW/Zs2eXl5eXChQooI0bNz4wU7ly5XTu3Ln7HlukSBHlzJnzsa/Jy8srwWMyZ86soKAgxcfH6/vvH/yXxK1bt6py5crq2bOngoODVaRIkUR1o8uUKWPvuKaExHw/nsSRI0d04cIFjRs3Ts8//7xKlCjBBbUAAACAdMZhBfHOnTs1ZswY7dmzR+Hh4VqxYoX++ecflSxZUr1799a4ceP01Vdf6ciRI+rZs6euXLmS4PE1a9bU4sWLtXXrVv3yyy/q0KFDgmG1hQsXVmxsrKZOnaoTJ05o8eLFmjVrVrJzFy1aVE2aNFHXrl31448/6uDBg3rllVeUN29eNWnSRJJUvXp1/fPPPxo/fryOHz+u6dOna+3atfZznDx5UoMHD9b27dt1+vRprV+//rEFXGhoqCZOnKgPP/xQv//+u/bt26epU6dKkmrXrq1KlSqpadOm+vbbb3Xq1Clt27ZNQ4cO1Z49Dx428zgFChRQhw4d1LlzZ61cuVInT57Uli1btHz5ckm35/3u2bNH3377rX777TcNGzZMu3fvfux527RpIz8/PzVt2lQ//fSTTpw4oS+//FLbt29/opyJ+X48iXz58snNzc3++Vm1apVGjRr1xOcDAAAAUpphss0ZOawg9vb21g8//KAGDRqoWLFiGjp0qCZOnKj69eurf//+at++vTp27GgfjvvSSy8lePzgwYNVtWpVNWrUSA0aNFDTpk0TzBEtW7asJk2apPfee0+lS5fWJ598orFjx6ZI9gULFqh8+fJq1KiRKlWqJJvNpjVr1tiH4JYsWVIzZszQ9OnT9fTTT2vXrl16++237Y/38PDQkSNH1Lx5cxUrVkzdunVTr169EszjvVeHDh00ZcoUzZgxQ6VKlVKjRo3sSwsZhqE1a9aoatWq6ty5s4oVK6bWrVvr1KlT8vV98nUNZ86cqRYtWqhnz54qUaKEunbtqqioKEnS66+/rmbNmqlVq1aqWLGiLl68qJ49Hz8fys3NTevXr1fu3LnVoEEDBQUFady4cQn+mJFUj/t+PIlcuXJp4cKF+vzzzxUYGKhx48ZpwoQJT3w+AAAAAM7HsCX1SlUO0rFjR125ckUrV650dBQg0SIiIuTj46Pfz1yQl7e3o+PAAnw8nvwPQQBgBrlf/djREWARtls3dO3L13X16lV5O9nvcXd+x9x0IFxZvJwr28Nci4xQzbL5nO79dOgcYgAAAAAAHMVhV5kGAAAAACSDM0/OvZeT5jRNQbxw4UJHRwAAAAAApCMMmQYAAAAAWJJpOsQAAAAAgP9n/PtlBs6akw4xAAAAAMCSKIgBAAAAAJZEQQwAAAAAsCTmEAMAAACACRnG7c0MnDUnHWIAAAAAgCVREAMAAAAALIkh0wAAAABgQsa/mxk4a046xAAAAAAAS6IgBgAAAABYEgUxAAAAAMCSmEMMAAAAAGbEJOJko0MMAAAAALAkCmIAAAAAgCUxZBoAAAAATMj498sMnDUnHWIAAAAAgCVREAMAAAAALImCGAAAAADgVMaOHatnnnlGXl5eyp07t5o2baqjR48mOMZmsyk0NFT+/v7KnDmzqlevrl9//TVJz0NBDAAAAAAmZBjm2pLi+++/1xtvvKEdO3Zow4YNio2NVd26dRUVFWU/Zvz48Zo0aZKmTZum3bt3y8/PT3Xq1FFkZGSin4eLagEAAAAA0kRERESC2+7u7nJ3d7/vuHXr1iW4vWDBAuXOnVt79+5V1apVZbPZNGXKFA0ZMkTNmjWTJC1atEi+vr5aunSpunfvnqg8dIgBAAAAAGkiICBAPj4+9m3s2LGJetzVq1clSdmzZ5cknTx5UufOnVPdunXtx7i7u6tatWratm1bovPQIQYAAAAAEzL+3czgTs4zZ87I29vbvv9B3eF72Ww29evXT88995xKly4tSTp37pwkydfXN8Gxvr6+On36dKJzURADAAAAANKEt7d3goI4MXr16qWff/5ZP/744333GfdMTrbZbPftexSGTAMAAAAAnNKbb76pVatWafPmzXrqqafs+/38/CT9f6f4jvPnz9/XNX4UCmIAAAAAgFOx2Wzq1auXVqxYoU2bNqlgwYIJ7i9YsKD8/Py0YcMG+76YmBh9//33qly5cqKfhyHTAAAAAGBGZpxEnEhvvPGGli5dqv/973/y8vKyd4J9fHyUOXNmGYahPn36aMyYMSpatKiKFi2qMWPGyMPDQ23btk3081AQAwAAAACcysyZMyVJ1atXT7B/wYIF6tixoyRp4MCBunHjhnr27KnLly+rYsWKWr9+vby8vBL9PBTEAAAAAACnYrPZHnuMYRgKDQ1VaGjoEz8PBTEAAAAAmJDx75cZOGtOLqoFAAAAALAkCmIAAAAAgCVREAMAAAAALIk5xAAAAABgQoZxezMDZ81JhxgAAAAAYEkUxAAAAAAAS2LINAAAAACYkPHvZgbOmpMOMQAAAADAkiiIAQAAAACWREEMAAAAALAk5hADAAAAgBkxiTjZ6BADAAAAACyJghgAAAAAYEkMmQYAAAAAEzL+/TIDZ81JhxgAAAAAYEkUxAAAAAAAS6IgBgAAAABYEnOIAQAAAMCEDOP2ZgbOmpMOMQAAAADAkiiIAQAAAACWxJBpAAAAADAh49/NDJw1Jx1iAAAAAIAlURADAAAAACyJghgAAAAAYEnMIQYAAAAAM2IScbLRIQYAAAAAWBIFMQAAAADAkhgyDQAAAAAmZPz7ZQbOmpMOMQAAAADAkiiIAQAAAACWREEMAAAAALAk5hADAAAAgAkZxu3NDJw1Jx1iAAAAAIAlURADAAAAACyJghgAAAAAYEnMIQYAAAAAEzL+3czAWXPSIQYAAAAAWBIdYiAV2Ww2SVJkZKSDk8AqjNiMjo4AAKnKduuGoyPAIu581u78Pof0iYIYSEV3CuFygQUdnAQAAABPIjIyUj4+Po6O8WCMmU42CmIgFfn7++vMmTPy8vKS4ayLrzmhiIgIBQQE6MyZM/L29nZ0HFgAnzmkJT5vSGt85p6MzWZTZGSk/P39HR0FqYiCGEhFLi4ueuqppxwdw7S8vb35hxtpis8c0hKfN6Q1PnNJ57SdYaQYLqoFAAAAALAkOsQAAAAAYELGv19m4Kw56RADcDru7u4aMWKE3N3dHR0FFsFnDmmJzxvSGp854OEMG9cRBwAAAADTiIiIkI+Pj/b9fk5ZvMwxL/xaZITKFfXT1atXnWouO0OmAQAAAMCMDMk0C5k4aU6GTAMAAAAALImCGAAAAABgSRTEAAAAAABLYg4xAAAAAJiQIaedmnsfZ81JhxgAAAAAYEkUxAAAAE5qzZo1OnjwoKNjAEC6RUEMAADgZGw2m44dO6aXX35ZU6ZM0eHDhx0dCXBaNpvtvn3x8fEOSOIAhsk2J8QcYgB4CJvNJsMwdPDgQZ0+fVq3bt1SjRo1lD17dkdHg4Xd+VzeLT4+Xi4u/I07PTEMQ0WKFNGnn36qPn36yNXVVX379lWpUqUcHQ1wKnf//Dt16pQyZMggHx8feXl5PfDnJXAvCmIAeIA7/4iuWLFCr7/+ugoXLqzDhw+rVq1a6tixo1588UVHR4QF3f2L34ULFxQbGys/Pz+K4XTozs+gF198US4uLurZs6ckURQDd7n7Z+KoUaO0fPlyxcTEKD4+XsuXL1dwcLCDE8IM+BcUAB7AMAxt3rxZ3bt31+jRo7V9+3Z9/fXXWr16tSZPnqzPP//c0RFhMXf/4jd69GjVr19fVapUUe3atXX06FHFxcU5OCFSkmEY9mGgjRo10vTp07V+/XpNnjxZv/76q4PTAc7hzs/E4cOHa/r06Ro5cqRWrVolPz8/NW7cWGvWrHFwQpgBBTEAPEB0dLQ2bNig9u3bq2vXrjpx4oQ6d+6sF198UTdv3tSYMWP01VdfOTomLOTOL37Dhg3T9OnT1aNHD61atUrHjh1Tt27d9NNPP1lnzlw6d6cQvnuoZ+PGjTV16lSKYuAeO3fu1HfffadPPvlEzZo102+//aZffvlFefPmVcuWLbV27VpHR0xVhsm+nBFDpgHgAdzd3dWyZUu5u7srMjJSbdq0UbVq1TRv3jzt2rVLtWrV0tixYxUfH6/mzZs7Oi4s4ocfftDXX3+tTz75RDVq1NDGjRt16dIlxcXFqVOnTlqwYIEqV66sDBn4592s7gyV3rVrl8LCwnT58mU1bdpUTz31lJo0aSJJevPNNyVJ/fr1U2BgoCPjAg7n5eWlli1bqlatWtq4caO6du2q//73v+ratauqVKmi7t27a8qUKWrWrJmjo8JJ0SEGAD34CpXFixdXyZIltW3bNt26dUtDhw6VJF2/fl1ly5ZV/vz5VaFChbSOCgvz8PBQ9+7dVaNGDX333Xdq3bq1PvjgA508eVKxsbEaMmSINm/eTKfYpO6+dsELL7ygJUuW6P3331fHjh21YMECxcTEqEmTJpo6dao2b96sd999V0eOHHF0bCDNPOhnW2BgoNq2bStJmjNnjlq3bq2ePXvKxcVF+fPnV1xcnKZNm5bWUWEi/AkZgOXd+SV08+bN2rp1qzJnzqz27dvL19dX0u0CODIyUuHh4SpYsKA2bdqkChUqKDQ0VF5eXg5Oj/TqQVeODgkJkb+/v27duqXJkyera9eu6tSpk65fv67ChQtry5YtmjNnjurUqeOg1EgOwzD0ww8/qGfPnnr//ffVpUsX/fbbbypVqpSuXbum6OhodevWTU2aNFF0dLRGjRolHx8fR8cG0sTdPxO3bt0qFxcX5cuXTwEBAcqdO7euXLmisLAwValSxT4H3zAMffPNN3r66acdnD71GMbtzQycNScFMQDLMwxDa9asUcuWLRUUFKSLFy9qypQp2rBhgwIDA1W8eHF5enrqzTffVMaMGXX8+HFt2bKFYhip5u5f/Hbv3q2sWbPKw8NDefPmlb+/vy5duqQ///zTPgQwY8aMKlSokBYuXKinnnrKkdGRDHFxcdq9e7dat26tLl266MSJE6pfv77atGmjq1ev6v3331eGDBnUqVMntWzZUg0aNFCWLFkcHRtIE3d+Jg4YMECffPKJrly5oqpVq+rll19Wly5dlDVrVgUFBWnUqFG6dOmSvv32W928eVNBQUEyDIPl6fBQhu1B4wQBwGKGDRumfPnyqWvXrjp69KgGDRqkH374QZs2bVLZsmW1d+9ebdq0SdevX1fr1q1VvHhxR0eGBQwaNEgff/yx4uPjVbFiRfXo0UP169eXJD3zzDOSpLZt22rVqlW6fPmy9u3bJxcXF8XFxcnV1dWR0fGEfvvtN8XFxSl//vx64YUXVLRoUc2bN09nz55VqVKl5Ovrq969e+v1119njVVYwt2f84MHD6pLly6aPXu2oqKiNHfuXB0/flwvv/yy+vbtq6ioKL3xxhsKDw9X7ty5tXjxYmXMmDFd/kyMiIiQj4+PDp74W15e3o6OkyiRkRF6upCvrl69Km9v58lMhxiAJd35B/bUqVOKi4vTqVOnVKVKFUm35w7PmDFDb7zxhmrUqKEtW7aofPnyKl++vINTI727+xe/HTt2aPXq1VqxYoV+//13bdiwQQMGDFBUVJRatGihb775Ro0bN9YXX3yhbNmyaf369XJxcVF8fHy6+8UvvXpQQVuwYEFlzJhRu3bt0uXLl9W7d29J0t9//61nnnlG/v7+atCggSRRDCPdu7urGxcXJ8MwVKpUKQUHB9uHTI8dO1afffaZMmbMqF69emnhwoW6evWqfTpBbGwsFxrEI/HpAGBJdy5c061bN+XLl08///yzqlatar/f399f06dPV+/evRUcHKxDhw6pVKlSDkyM9O7e4Xy3bt1SzZo1ValSJVWqVEmlS5fWtGnTNHz4cBmGoebNm2vnzp26cuWKfHx8ZBgGv/iZyJ1ieP369Vq1apU8PT318ssvKyQkRJIUFRWl69ev69ixYypZsqRWrlypPHnyaOrUqQyThmXcvfb62rVrlTFjRmXJksW+v0CBAho8eLDGjh2rTz/9VFevXtWQIUPsxbDNZkv3PxONfzczcNacDKQHYCl3ZokcO3ZMQ4cO1bBhwzR06FC1aNFCAwYM0ObNm+3H+vv7a/LkyWrXrl26/wcVjnfnF7z33ntPzZs314QJExQREWG/v1y5cnrzzTf17LPPKjQ0VEuWLJEkZc2a1X4BGT6n5nGnGG7WrJmOHTumzZs3q2rVqvr6668lSUFBQcqXL58GDhyoMmXKaOrUqerduzfFMCzh7qtJT58+Xe+//76qVq0qwzC0adMmhYaG2u8vUKCA3nnnHeXNm1fh4eEJVo1gFAUSgznEACxny5YtOnTokI4ePWpfiiEuLk7t27fXmjVrtGLFCtWoUcN+fHqcewTncXdneMyYMZo0aZIaNmyo33//XTt27NDy5cvVokUL+/EHDhzQyJEj5eHhoU8++cRRsZECpk6dKldXV/Xs2VN//fWX3n//fU2dOlXLli1TixYtdPbsWa1Zs0bR0dGqW7euihQp4ujIQJratGmTfv/9dz311FNq2LChzp07pxkzZuiLL75Q69atNXz4cPux586dU+7cueXi4mKJ+fV35hD/bLI5xGWYQwwAjrdo0SItWrRITz/9tC5duqTs2bPL1dVVH3/8sTp06KBWrVpp8eLFqlevniRRDCNV3SmGw8LC5O7urs8//1w1atTQiRMnNHHiRHXp0sU+RFqSypYtq/Hjx6tw4cKOjI0ncOeX9KNHj+rGjRvavn27GjZsKOn2iJTQ0FAZhqHWrVvrs88+U/PmzdWlSxcHpwYcY+/evapXr54yZsyoL7/8UpLk5+en7t27yzAMLVu2TC4uLho6dKj9PunBS9ala4yZTjYLfVoA4LYFCxaob9++OnjwoFavXq0bN25Ikr0orlSpkrp3767r1687OCmsYvPmzSpVqpTGjRtnH+5XqFAhDRgwQO3bt1eXLl20YsUK+/FFixa1X0AL5mEYhr766iuVL19e7du312effaajR4/av48+Pj4aMWKE+vbtq5dfflmrV692cGLAcfLly6fJkyfLw8Mjwf8LefPmVffu3dXq/9q7z7Aor+3v49+hgx1r7L1EjRI1irHFrmDvHRF7L7HGXiJWxIKIvcZu7DVGxRoVY2yx91hiQxEQhnle+GceiJ5zknPUgeH38ZorcjfWGLhnr3vvvXazZkybNo3FixfHOy9JJcPyQaiHWESsWmyPzMuXLzEajSRLlgx7e3umTp3KkydP6NatG46OjtSrVw8nJydsbGzYuHEjDx48wMXFxdLhSxJRvHhxRo8ezbhx47hw4QKVK1cG3s6NGzBgALa2tjRu3JiffvqJSpUqmc9Twy9xiL0P3blzh/HjxzNt2jQKFCjAzp07mTBhArlz58bLywt4mxQPGzYMBwcHjQKQJON9vbrp06enTZs2mEwmhg4dSvLkyfH19QXejqjw9vYma9astGnTxhIhixVRQiwiViu2Ebp582ZmzZrF5cuXKVOmDCVLlmTAgAHmp8odOnTAxsaGOnXqmJPizJkzWzZ4sVrva/ilSZOGfv36ERYWRu/evUmbNi0tWrQAIEeOHPTs2ZMcOXJQrlw5S4Qs/6PYAlqHDx/miy++oH379tjb21OxYkUcHBzw8fHBZDLRvn174G2htHHjxln9HEgRiH9PXLRoEVevXuXu3bv4+Pjg5uZG165dARg5ciQGg4GJEycCkC1bNvOUAtX6kP+FEmIRsVoGg4Ht27fTpEkThg0bRq1atTh37hwBAQHcvn0bf39/Fi9ejL29Pc2aNWP9+vU0aNDA0mGLFYvb8Fu1ahV3797l5cuXNGrUiIIFCzJx4kRiYmJo3bq1eS4pQJ48eejbty+gNTUTk7gjVB4+fMjYsWPJmjUr9+/fJ0eOHACMHj0ag8FA9+7diYiIMDf+lQxLUhF7TxwwYABLliyhQoUK3Lt3j4YNG9KxY0d69uxpnjc8ZswYXrx4QUBAQLxrJOVk2PB/fxKDhBqnPlFFxGpFRESwdOlSevfuba5E+fTpU9asWcOUKVPInz8/PXr0ICgoCGdnZwoVKmThiMXaxW34LV68mNKlSxMSEsKGDRto1KgRgwYNYtKkSdjY2NC2bVtev36Nt7d3vGsoGU48DAYDq1atom3btkRGRhIeHk6XLl1Yvnw5PXr0MK+VOmrUKF6/fs2IESNo2bKlebtIUrF3715++OEHdu/ejZubGwBTp05l8eLFJEuWjGHDhtGiRQvCwsL4+eefk0QVafl0NPlIRKyWvb09N27ciLeWq6urK02bNqVUqVKEhISYCxj5+/tTsGBBS4UqScjWrVvNDb9t27Zx//59PD092bdvH7NnzyYmJoZhw4bRsWNHFi1aZOlw5b8Qe1958uQJ+/fvNz/k6NSpE5MmTWL48OEEBQXFuzdNmjSJixcvKhmWJCksLAwnJycyZMiA0WgEoH///ubCWY8ePSJt2rR0796d7du3m9deF/kQlBCLiNUymUy4u7vz8OFDbt26Zd7u6upK/vz5OX36NBERERaMUJKiBw8ekDJlSvLkyWNu0I0cOZLChQuzatUqTCYTKVKkYMqUKRw8eNDC0cp/w2AwcPLkSRo0aMDFixfx8PAgKioKeDs6YNKkSQwcOJAFCxbw4sUL83np0qWzVMgin0zcRDb275GRkTx79gwbGxtsbW3Nqz/07dsXGxsbgoODAUiePLk5GVYP8VsGwGBIJC9L/2P9C0qIRcQqxH6oPnr0iKdPn5rnWVavXp0DBw4wd+5cbt68aT7+jz/+IG/evEl63pF8WrFL69jY2BAVFUVkZCQGg4GoqCicnZ357rvvOHv2LAcOHADA2dlZvSCJ2MWLF3n9+jVnz57FxcUFe3t7IiMjgbdJ8ZQpU+jfvz/Lli3T/2NJMmJiYsyJrNFoNP+9adOm5MyZk/r16wNv73/w9jM9TZo0pE2bNt51lAzLh6SJSCJiFQwGA5s2bWLgwIE4OzuTIkUK1q9fT+3atZk1axa9evXizJkzpE6dGgcHBzZu3EhwcDAODg6WDl2s1F+rScf+3dPTk/79+zN48GAWLlyIvb09AC9evKBAgQJq+FmJFi1a4OjoaJ77uGnTJtKmTcubN29wcHCgX79+2NvbU7lyZf0/liTBZDKZ74MzZ87k4MGD5M6dm2+++YaaNWsyb948WrZsSZEiRZgwYQIxMTHMnz+fVKlSqcK+fFQGkx5LikgiFXv7MhgMXLhwga+//pohQ4bg4uLC6tWruXr1Krt376Zo0aLs27ePAwcOcOLECXLmzEmPHj0oUqSIhd+BWKu4w/kCAwM5c+YM2bJlo0aNGpQoUYJdu3bRpEkTatasSfv27c3L7Dx9+pTDhw9rfeFEJu46wyaTifDwcAoUKIDJZGLdunVMnTqVdOnSsWzZMtKkSUNkZCSOjo6WDlvkk4l7T5wwYQKTJ0+mYcOGnDx5kmTJkuHt7Y2Pjw9Xr16lZ8+eXLhwgRQpUpAtWzY2b96Mvb29llb6i9DQUFKlSsW5G49IkTKlpcP5W16GhlIkVwZevHhBygQUsxJiEUn0jh07xsuXLzly5AgjR44E4M8//6RNmzacOXOGPXv2xEt+tWyNfExxe4aHDRvGvHnzKFWqFA8ePCA6Oho/Pz8qV67M0aNH8fb2Jjw8HAcHB7JmzcquXbvU8EtkYhv6GzZsYMiQIURFRfH06VNatmzJ4MGDyZ49O6tXr2bGjBmkT5+ehQsXvjMKQMSaxb2f/fLLL6xYsYIGDRpQsWJFLl++jJ+fH0ePHqVLly507twZgGvXrpE8eXIyZMiAwWDQ5/Z7xCbE5xNZQlw4ASbEegQtIolK3759mTdvnvnrsLAwunbtSo0aNbhx44Z5e2xvTPHixfHw8ODXX38179OHqnwsRqPRnAz//vvvvHr1ih07drB9+3YCAwMpVqwY3t7e7N27F3d3d3755Rf27NnD5s2b2bt3L/b29kRHRysZTkQMBgMHDhygdevW9O3bl4ULF7Jo0SLWrl1Lnz59uH//Pk2aNKFnz55cvXqVbt26meeTi1izMWPGYDKZzPezTZs24ePjw759+8iVKxcA+fPnp0+fPri7uzNv3jxmz54NvF17PWPGjBgMBmJiYvS5LR+VEmIRSVRy5sxJqVKlzF8nS5aMpUuXUq1aNQ4cOMCjR4+At7026dKlY/ny5WTJkoUWLVrw5s0bS4UtVi4oKAjA3PBbv349VatW5eDBg2TJkgWAUqVK0b9/f8qXL0+nTp3Ys2cPyZMnJ1++fBQsWBAbGxs1/BKp3bt3880339ClSxcqVapEgwYN2LNnDz///DOTJ0/GxsaGJk2aMHr0aHx9fTUkXqzepk2buHDhgnkJJYDUqVOTM2dObt68aS4eCG+T4r59+1K2bFkmTpzIxo0b411Lvy/yseknTEQSld69e+Pm5saOHTvw9/cHoGjRovj5+ZEmTRoqV67M8+fPzdV506ZNy9atW9m5c6cKaMlHsWbNGpYuXYrRaDT3/Nna2lKsWDGuXLnCw4cPzccWL16cAQMGUKFCBerWrcupU6fiXUsNv8THZDKZh8PD2yHzb968oXjx4vj7+7Ny5Upu3bqFnZ0djRs3JmfOnJYNWOQTqFmzJitXrsTOzo5NmzZhNBqpVKkSw4cPp1q1asydO5f169ebj8+XLx/dunWjT58+1K1b14KRJz4WX0rpH74SIn3yikii8NdyB2fOnKFPnz7MmTMHgEKFCrFixQrs7e0pV65cvKTY1dWV7NmzWyJsSQJq1qzJgQMHsLW1Nfd61K9fn759+1K6dGnat29PSEiI+fhixYrRo0cPhg4dSvHixS0Utfy3Yu9FT58+5fXr1xgMBurUqcOBAwfYu3cvNjY25l7+5MmTkzZtWlKkSGHJkEU+qZiYGJycnLCxseH06dP06dOHVq1aERMTQ8mSJRkwYACZM2fG39+fDRs2mM8rVKgQ/fv3x9bWNl7PssjHpoRYRBKVBw8eEBUVxZAhQ5g0aRI9e/Zk1qxZwNsP05UrV+Li4kLhwoV58eKFljORjy5lypTY2Nhw4sQJqlSpwuDBgwGoUqUKAwcOJFu2bHTq1IkzZ86YzylZsiTDhw9Xwy8Ril3irW7duhQrVoyRI0fi5OREly5d6NWrF3v27DH39B8/fhwXFxfdhyTJ+Otyc59//jmDBw/m2rVrtG3blpiYGMqWLUvfvn3JmDEjs2bNYsWKFe9cR3UU5FNSQiwiCV5sFdctW7bQvn17lixZgtFoZMCAAUycOJHevXvHS4oXLlxI3rx5efLkiYUjF2sWtzCSyWSiUKFCTJ48mQULFjBs2DAAatSoQbdu3cicOTNdunThl19+eec6avglLqdPn8bLy4saNWrg4eHBtm3bWLJkCTly5DBvK1OmDOXKlWPu3LkEBQWRJk0aS4ct8tHFTYYDAgIICgoiPDwcLy8vOnTowIULF95Jig0GA0eOHLFw5JLUadklEUkUNm/eTNOmTZk4cSI1a9akYMGC5n2TJ09m8ODBzJw5k27dugHw5s0bzRmWjyZuw2/p0qU4ODjg4eGByWRi4cKFjB49mm7dujF+/HgAdu3axZgxYyhUqBDz58+3ZOjyP7h27RqrVq3CYDCYH3ps2bIFf39/0qRJQ+vWrUmdOjU7duwgTZo0NGjQgHz58lk4apFPa+DAgSxZsoSxY8dSp04dPvvsM8LDw1m6dCnz5s2jUKFCLFmyBFtbW86dO8fnn3+u+gn/hdhlly7cfJyoll36PGf6BLfskkpZikiC9/jxYyZNmsTYsWPp06ePeXtsUvLtt99iMBjo0aMH9vb2dOzYUcmwfFSxjbdvv/2WZcuWMX78eF69esVnn31Gu3btMBgMjB49GpPJxIQJE6hRowZp0qShZMmSFo5c/luhoaE0b96c27dv4+3tbd5ep04dAKZPn86SJUsYPnw433//vaXCFLGoVatWsXz5cnbs2MGXX34JvB1B4+zsTJs2bTAYDAQFBeHp6cm2bdsoUqQI8O5Qa5FPSQmxiCQ4sQNXYufdmUwmbt++bV63MFbsh2fs8Gk7OzvKlSv3aYOVJGvJkiWsWLGCrVu3UqJECfPPa5o0acwNvzFjxvDixQtmz57NV199Bajhl1ilTJmSefPm0bx5cw4dOsT58+cpXLgw8DYptrW1ZdiwYUyZMoV58+bh7OysucNi9f56P7t06RJubm4ULVoUo9EYb0qIi4sLXl5ehIWFcfbs2XjX0T1RLEkJsYgkOLGNyB9//JGXL19SrFgx7OzszHM2o6OjzVVcT58+zcmTJ/H29o7XeyzyocU2/GL/e/LkSSpUqBCv1zd2n6urKz4+Prx8+ZJDhw6Z58GDGn6JmZubG2vXrqVdu3b4+/vTq1cvc1Jcu3Zt7OzsKFCgAC4uLhaOVOTjM5lM5vvZ+vXradSoEdevX+fFixfY29sDmJNio9HIkSNHKFasGN27d8fe3h6DwaAHhB9AQl7O6K8Sapz6CRSRBCW2d/jcuXM0aNCAmJgYihYtSqlSpRgwYAB37twxJ8MAq1evZvfu3YSHh1sqZEkC4jb8jh07BsDVq1fNvR8xMTHmY6Kiojh48CAmk4l+/fqxY8cO8xJgkvh98cUXLFy4kJMnT+Ln58eFCxfM+6pXr06OHDksGJ3IpxH3Id/48eNp06YNt2/fpmnTply5coUFCxYA/79o4KNHj5g6dSpHjhzBwcHBfE9UMiwJgX4KRSRBMRgMnDhxgnv37jF8+HDatm0LgJ+fHzlz5qR06dLMnz+f+fPn07NnTwICAhgxYoTW+ZSPJiYmxtzwGzhwIOXKlSMiIgIPDw82bdrE4cOHsbGxMR/z4MED5s2bR0hIiHnYbNzGoyR+bm5uzJ8/n7NnzzJ27FguXbpk6ZBEPqnY+9kvv/zC3bt32bZtG9mzZ6d48eLUqlWL+fPnM3PmTF6/fs25c+fo3Lkz9+/fp1q1au9cQ8TSlBCLSILy6tUrvL29qVWrFleuXDFv/+yzz9ixYwc1a9Zk9uzZTJkyhd9//51Dhw7xxRdfWDBisXaxPRiXLl0iPDyc/fv34+TkhKenJzVr1qRDhw7s27ePsLAwbt++TdeuXbl69Sru7u7ma6jhZ33c3NyYNWsWf/zxB6lSpbJ0OCKf3MaNG+nUqRP79+8nZ86cAGTLlo0BAwZQrlw5Ro0aRbZs2WjUqBFPnjzh8OHDWntdEiQtuyQiCc6pU6cYOHAgN2/e5PDhw2TKlClecY7Hjx/j4OCAra0tyZMnt3C0khSsW7eOfv36kSJFCnbu3Em2bNkAOH78OPPmzWPp0qVky5YNR0dHUqZMSXBwMPb29poflwRERETg5ORk6TBEPrn9+/czdepU9u7dy4IFC2jVqpV5X1hYGM+fP+fkyZNkyJCB0qVLY2NjE68GiPxvYpddunQrcS27VDCHll0SEYnnfUNJixUrxvTp02nVqhW1a9fm0KFDJEuWjKioKOzt7UmfPr2FopWkys7OjsKFC3PgwAGePn1qTohLly6Nm5sbXl5e3L17l5QpU1KzZk1sbW3V8EsilAxLUvC+h3vffPMNyZIlA8Df358UKVJQt25dABwdHcmSJQtZsmQxH280GnVPlARJPcQiYjGxyfCxY8c4cuQIYWFheHp64ubmBsBvv/1G8+bNcXJy4uDBgyRLlkw9bvLR/av5vnv27GH06NGEhoayatUqChcu/M4SYbH+utyIiEhiFfdz9+zZs4SFhZE+fXry5s0LwMGDB/Hz8+PZs2f069fPvDa3fFzqIf5w1KoUEYsxGAxs2LCBevXqsWnTJoKDgylVqhTr1q0DoGjRovzwww8YjUaKFi3K69evlQzLRxW3gNbFixf5/fffuXr1KgDVqlVj6NChZM2aFR8fHy5cuGBeNuSvlAyLiDWIWwl62LBhtGzZklq1atGlSxcGDRoEQIUKFejduzeurq74+fmxdu1aS4ac5MQuu5RYXgmRWpYiYjFHjhyha9eujB8/noMHDxIUFERMTAxt27Zl/vz5wNukeNGiRWTMmJGHDx9aOGKxZnEbfiNHjqRFixZUqlQJHx8fZs6cCbxda7Zbt264urrSqVMnzp49q+RXRKxW3KWV5s+fj7+/P9evXydbtmzMnTuXTp06AVCxYkV69+6N0Wjk4MGDlgxZ5B9TQiwiFvHmzRtCQkLo0qULPj4+3Llzh/Lly9O1a1d69epFt27dWLlyJfC2muuBAwfIlSuXhaMWaxbb8Bs9ejQBAQFMnjyZPXv2kD17dvr06YOvry8Anp6edO/enaioKGbPnm3JkEVEPrrffvuNzZs3s2zZMipXrszp06dZu3YtNWvW5KeffqJ79+7A255iPz8/ZsyYYeGIRf4ZzWwXkU8m7txMBwcHKlSoQEREBK9fv6ZNmzbUqFGDmTNncv36dWbNmkXr1q2Jjo6mbdu2ODg4WDh6SQpOnDjBrl27WLt2LRUrVmTXrl1s2rSJOnXqMHbsWGxtbRkwYAC1a9cmderUlClTxtIhi4h8UH+t1VG0aFG8vb1xc3Pj4MGDtGnTBj8/P3x8fKhTpw7z58/n4cOHrFu3juLFi7/3GiIJmRJiEfkkYpPh/fv3c/jwYb777juKFi0KwOXLl3n58iXt27fHxsYGe3t7mjRpQp48eShVqpSFIxdr9tdGW968ealduzalSpVi3759eHl5MWXKFBo3bkzjxo0ZOHAgz549Y/z48ZQtW/a91xARSazi3s+Cg4NJkyYNhQsXpnPnzgCMGTOGRo0a0a5dOwA+//xzXr16RcaMGeOdq3vip2P4vz+JQUKNUz+tIvJJGAwG1q9fT6NGjbh16xanT5827/vzzz8JCQkhLCyMsLAwFixYwNWrV+nfvz+FChWyYNRizeI23o4fP879+/dxdXXl22+/xcXFhVWrVtGsWTO8vLxwdXWlQIECuLu78+uvv2IymcwVptXwExFrELeOwuDBg+nZsydHjhzhxYsX5mNu3LjBrVu3zOus37hxg1atWjFr1ixsbGzeW2RQJKFTD7GIfBK//vorXbp0wdfXl44dO8bbV7ZsWTp06ED16tUpXLgwd+7cYf/+/Tg7O1soWrF2cRt+Q4cO5aeffqJdu3a0b98eJycnIiMjOX36NGXKlMHBwYHXr1/z559/0qtXL5o1a2a+hoiItYid0jRx4kQWLFjA+vXrKVGiBMmSJTPf76pXr86iRYuoUaMGYWFhPH/+nFWrVmEwGOLdV0USEyXEIvJJ/P777xQsWJCWLVuae+birtUaFBREtWrViI6OpkyZMuTOndvCEYs1i234jR07lnnz5rF+/Xq++OILnJycAHB0dKRJkybMnj2bN2/ecOnSJV6/fk3jxo2Bf71WsYhIYmUymXj27Bnbt29nwoQJVKhQId4+GxsbmjdvDsCxY8fInTs3M2fOxNbWVmuvW5Lh/16JQQKNUwmxiHwSjx494vLly7x588b8tDn2wzM4OJhy5crRtGlTC0cpScm9e/fYuXMns2bNomLFiubtsQ9smjRpgtFo5MCBA+TLl4958+ap4SciVstgMGBjY8Pdu3fNhSxj74c2NjaEh4cTHR1Nr1696NWrl/m86Oho7OyUUkjipXENIvJJ5MuXD2dnZ7Zt28br16/Nw6sA/P39mTZtmoUjlKTGYDBw7dq1d4b42djYEBkZScaMGfnuu+/YtWsXixYtwt7enujoaCXDImK1bG1tsbe355dffgHi10i4fPkygYGB3Lt3z7zNZDIpGZZETwmxiHxQsUnulStXOHv2LEeOHAGgRo0auLu7M2TIENasWcP9+/d5/Pgxw4YNIzg4GE9PT0uGLUlQVFQUjo6O/PHHHwAYjUbzvpMnTzJt2jSePXtmbhCq4Sci1uJ9xa+MRiMpUqRg1KhRBAYGMnXqVPOxERERDBo0iPPnz5M5c2bzOZo6ItbAYFJVEBH5QGLnVa5fv55+/fphY2PDn3/+SdmyZfHz86NQoUJ4e3tz9OhR7ty5Q6FChXjw4AGbN2/Gzc3N0uGLlfp3Q5zHjh3LuHHj2LRpE7Vq1QIgLCyMpk2bki5dOhYvXqwGn4hYjRkzZlC/fn1y5MgRr9J+7Of39evXsbGxYe3atQwePJjq1avj6OjIkydPePHiBadOncLe3l51FBKA0NBQUqVKxZU7f5IiZUpLh/O3vAwNJV+2dLx48YKUCShmJcQi8kEdOXKEGjVqMGPGDEqUKAFAixYtSJEiBcuXLydfvnycPHmSa9eukSpVKooUKULWrFktHLVYo8DAQPPamXGT4tiG3K1bt7C1tWXSpEnMmjWLdu3amYdRP336lNOnT6vhJyJWY8eOHfTt25evvvqKCRMmkDVrVoxGo3nu8Nq1a+nUqRPHjh0jf/78HD16lAULFmBnZ8dnn33Gd999h52dneYMJxBKiD8cJcQi8kH5+fmxfv169u/fj62tLQaDgefPn/PVV19RoEABtmzZYukQJQnYunUrPj4+NGjQgICAAADz/F+DwcDatWsZPXo0GzZsIH/+/CxevJi9e/cSERFBnjx5GD9+vBp+ImJ1Zs+ezZo1a8iePTvff/+9+YH0jz/+SJMmTZg+fTrdu3f/l+erqGDCoYT4w9EcYhH5IGKfrT148IBXr15hZ2eHwWAgPDyc1KlTs2jRIg4dOsTZs2e1fqt8dGXKlGHIkCEcO3aMLl26AJh/JteuXUu7du3o0qUL+fPnB8DLy4slS5awbt06fH19sbOzw2g0KhkWkUSvZ8+ezJw5E4Du3bvTpEkTbt68yZAhQ7hz5w4AZ86cISAg4J1k+K+f10qGEx6DIXG9EiIlxCLyQcQOKa1Xrx4XL15k3rx5ADg7OwNvi3KkT5+eFClSaPipfDQdOnTg2LFjpEuXjjZt2tCuXTuOHj1qTooBDhw4wOTJk+nRo0e8c+NWU427LJiISGJ19+5dnj59SkBAAIsWLQKgR48eNGvWjJs3bzJs2DAePnzIyJEj6dChwzvn6/NakgIlxCLyX4l9avzbb7+xceNGLl26xMuXL3F3d6dPnz74+voSGBgIwOvXr9mzZw8ODg4kT57ckmGLFbt9+zbXr1+nUaNGnD59GldXV9q2bUv79u3jJcWzZs1675DAuA0/NQJFxBpkzZqV4cOHU6VKFXx9fVmwYAHwNilu3rw5169fZ8CAAeae4vdVnxaxdppDLCL/tfXr19OpUydcXFwwGo20bduWvn37Ymtry9SpU5k+fTo5cuQgWbJk3Llzh127dvHll19aOmyxYufPn2fUqFEcOnSIrVu3UrJkSZ4+fcqyZctYsGAB7u7u5gc1mgsnItYsbkHAixcvMnv2bPbu3cu3335r7g2ePXs2P/zwA7ly5TIX2lIhwcQhdg7x1buJaw5x3qwJbw6xEmIR+UfiVujt2LEjTZo0oWHDhsydO5fNmzdTrFgxxowZQ6ZMmQgJCWHfvn2kT5+e8uXLkzt3bkuHL1YqbgPu3LlzjBo1iuDg4HeS4oULF+Lu7s7cuXMB4i07IiJiLWLvbX+9NwYEBLB3714GDhwYLyleu3YtyZMnZ+HChWTIkMGSocvfFJsQX7v7JFElxHmyplVCLCKJ38mTJ1m5ciV//PEHgYGB5pvazJkzWb58OcWKFWPw4MFKgOWTiG3wxW34/fbbb4wcOZIjR468kxQvWbKEfPnysXr1agtHLiLy4cV90Hf9+nVevnxJ/vz5cXZ25s6dO3z//ff89NNP8XqKfX19uXXrFrNmzdJDwkRCCfGHo/KZIvKPrVmzhsWLF5MqVSoiIyPN23v27GneP2zYMHx9fcmePbulwpQkIG7D79GjR7x48YL8+fNTtGhRpk6dSt++ffH09DQnxW3btuXVq1dcvnxZvcMiYnVMJpP5vjZ8+HA2btxoTj5atGhBr1696NevHzY2NkyZMgWDwYC3tzeDBg0yP1TUvVGSGv20i8g/NmnSJPr3709MTAyTJk3i0aNH5n09e/akTp06PHnyBHt7ewtGKdYubsNvxIgR1KtXj5IlS1K3bl0mT55Mjhw5mDhxIuXKlaNu3bqcOnWKNGnS0KtXLxYvXoyNjY0KyIiIVYkdJTNp0iSCgoKYOnUqd+7cIXfu3AQEBHD16lXy5s1Ljx49qFq1Kv3792fr1q3mc+PeVyWRMCSyVwKkIdMi8m/FPjG+fv060dHRPHnyBHd3d+BtErJt2zZq165N7969SZcunfm8Z8+ekSZNGkuFLUnIuHHj8Pf3Z+HChXz55Ze0bt2aGzdusG3bNj7//HNzoa3169dz4cIFChYsCKDCMSJidUwmExERETRo0ICmTZvi7e3Nzp07adasGZMmTaJz585ERUVhb2/P+fPn2bVrF71791aBwUTIPGT6XiIbMp1FQ6ZFJBGJTRg2btzIsGHDsLW15fHjx1SoUAE/Pz/GjBlDdHQ027dvx9bWlm7dupmLcSgZlo/NZDLx559/snv3bubOnYunpyf79+/n+PHj+Pv78/nnnxMTE0PhwoUZMWIE+fPnJ1++fObzlQyLiDWI+3DPYDAQGRnJ/fv3qVatGvv27aNJkyZMnjyZzp07ExERweLFiylXrhxFihShcOHCgKruS9KmhFhE/iWDwcD+/ftp27Yt06dPp0WLFhw6dIjatWtTv359WrZsyYQJE7CxsWHp0qU4ODgwePBgDbeSj+avDT87OztevnxJhQoV2Lx5M61atWLq1Kl06NCBiIgIVq9eTenSpSlatChFixYF1PATEesRd77vvXv3yJIlC6lTp8bV1ZXGjRtz8eJF/P39ad++PQBPnjzhhx9+IFmyZBQpUsR8Hd0TJSlTq1VEzJ49e/bOtkOHDtG6dWt8fHx48OABPXv2pGPHjrRs2ZLYGRfjxo3Dy8uLFi1aKBmWjyYmJsacDIeGhpq3v3jxgm7duuHl5cWkSZPo0qULALdv32bFihVcvnw53nXU8BMRaxA3GZ4wYQJdunRh//79AHz77bc8f/6cL774wpwMv3z5ko4dOwLQsmVLywQtH5ylpwRbwRRiJcQi8taiRYsoXLgwV65cMW8zmUwcP34cV1dXIiMjqVixIpUrVzav4Tp79mxWrVoFvJ1PnCtXLovELtYvbsNv4sSJtG3blhs3bpAmTRrGjx/P7t27qVy5Ml27dsVoNBIWFka/fv0wGo14eHhYOHoRkQ8v9p44ZMgQ/Pz88Pb2JkeOHACUK1eOLl26cOfOHYoVK4aHhwc1a9bk/v377NmzB1tbW4xGoyXDF0kwlBCLCAAeHh5kzJiRJk2acPXqVeDtkNT69etz4MABsmXLRt26dZk7d665EuWvv/7K4cOHiYyMRPX55GOKbfgNHjyYGTNm4OnpSXR0NABVqlShX79+bNiwgfr169O8eXM8PT25ffs2O3fuVMNPRKzWqVOn2LBhAytXrqRBgwbkzp0bk8lEqlSp6NSpE1u2bKF8+fIULVqU5s2bc/LkSezt7YmOjtZoGZH/oznEIkJMTAwZMmRg//791KpVi4YNG7Ju3Try589PkSJFiIqKIn369LRu3RqDwcCrV6+YOHEi27dvZ//+/Tg6Olr6LUgSEBwczA8//MDKlSv55ptvzNszZMjAt99+y9dff83ChQtJlSoVJUuWpH///tjZ2REdHY2dnT7uRMT6PHjwgJcvX1KgQIF39jk7O/PFF18wa9aseNuNRqPuiVbEYHj7SgwSapz6bRARs3v37jFo0CAaNmyIj48PixYtwt3dnYEDB+Ln50ebNm3InDkzDg4OXLx4kW3btpE/f35Lhy1JxJ07d3BycqJUqVLmbbFDqR0cHKhSpQqVKlWK1+uhhp+IWDMHBwccHR15/Pgx2bJlA/5/8cHVq1fj6upKjRo14p2jnmGR+DRkWkSwsbFh48aNlC1bliNHjuDp6cnNmzepW7cu169fp1GjRsyYMYNRo0bxxRdf0KxZMw4dOoSbm5ulQ5ckxNnZmdevX3P79u1422NiYli+fDlXrlwxN/Rih/Cr4Sci1szNzY03b94wceJEnj59Crz9TI+MjGTFihUcOnTIwhGKJHwGkyb+iSR5jx8/pmzZsrRv356hQ4diNBq5du0azZs3582bN/z444/kyZPH0mFKEhcSEoKHhwdt2rShb9++ZMqUCYCoqCiqV69OhQoVGD16tIWjFBH5+OIuQXfq1Cm++eYbKlSogIeHB2nTpiUwMJBHjx4REhKiUTJWKjQ0lFSpUnHj/hNSpExp6XD+lpehoeTKnJYXL16QMgHFrB5iESE6OpqoqChzj6+NjQ358+dn5cqVPH36lM6dO3Px4kULRylJVUxMDPC2J2TatGnMmjWL0aNHs2LFCnbt2kWtWrV4/vw5w4cPt3CkIiIf1vv6rWKXoNu0aRPt2rWjWLFiHDt2jPDwcGbMmMGkSZNInTo1p0+fxs7OTkUFrZ4h0fxJqAsv6ZGRiPDZZ5/h4ODAli1bqFWrlvmpc86cOSlYsCA//fQTPj4+/Pzzz9jb21s4WkkqYhuCNjY2/Pjjj2zbto158+ZhNBpZvHgxK1euJG/evGTMmJETJ06YG34aJi0i1iDucnP37t0jS5YswNt74tq1a2nXrh0zZszAzs6Ozz//nG3bthEREcGbN29Inz49BoNBRQVF/gb1EIskMbFJxu+//87Jkyf5+eefAejZsyfHjh1j+vTp5mOdnJwoVKgQ+/btY+XKlUqG5aOJ7QX+K4PBwLp162jZsiWlS5cGoFWrVmzYsIELFy6wZcsWtm3bpmVERMSqxE2GR48ejZeXF2fOnMFoNPLw4UN69eqFr68vHTt2BN5+tjs5OZE6dWoyZMhgXh5RybDIf6Y5xCJJSOyco02bNtG3b1+cnZ25efMm3t7eNG3alPXr1/Pzzz/z5ZdfUrVqVYKDg1m7di0hISHm6pUiH1rcht+FCxd4+vQp+fLlw9nZ2bzk1+zZs+natWu8eXP/6hoiItZi8ODBLF26lGnTplGhQgUyZ84MwN27d8maNeu/vCeK9YudQ3zzj6cJaj7uvxMaGkrOz1wT3BxiPTYSSUIMBgO7d++mffv2+Pr64uXlxd69e/H09CQ6OppmzZpRpEgR5syZw/Hjx3FycmLv3r1KhuWjMZlM5kR26NChbNy4kZcvX5IpUyaKFy/OrFmzuHTpknl5r3/V8FMyLCLWJjg4mJUrV7J27Vq+/vproqKiePToEb///rv5c1nJsMj/Ti0IkSQkNDSU9evX07dvXzp16sS9e/fo1asXDRs2ZNWqVQQGBlK1alVCQkI4fvw4Bw8epHjx4pYOW6xYbGNu+vTpLFiwgDlz5nD37l2KFi3K+vXrOXnypNa6FpEkIXbqSOzgzefPn5M8eXKKFSvGL7/8wogRIyhXrhz16tWjV69eXLhwwZLhilgNJcQiSYiTkxPVqlWjVatWPH36lEaNGlGpUiXWrVvH3LlzWbNmDV27duX69eukSJGC5MmTWzpksXImk4moqCgOHjzId999xzfffMP27dtZv349vr6+lCtXjsjISMLCwiwdqojIRxU70uX+/fsAFC1alEuXLlGzZk2qVavG48ePGTNmDOvWrSM4OJh79+5ZMlwRq6GEWCQJcXBwwNPTkzx58rBz506cnJwYNWoU8LanrmLFily6dElFOOSjilu6Irbwy9OnT/n666/Zs2cPzZo1Y/LkyXTq1Ik3b96wfPlyTpw4YcGIRUQ+jY0bN1KkSBEOHjxIjhw5+PXXX6lcuTJLly5l6tSpNG/enPLly5M3b14iIyMtHa6IVVBCLJLEODk5AXDjxg1evnxJsmTJAPj1119p1KgRV65cIXv27JYMUaxY3AIwsb0bDg4OODk50aJFCxo3boy/vz+dO3cG4OnTp6xcuZKrV69aLGYRkU8lU6ZMVK5cmY4dOxIcHEzRokUZOXIkdevWxcnJiWfPnlG3bl0MBgO1atWydLgiVkEJsUgS5eHhwZUrV6hTpw5Vq1Zlzpw5VKhQQUsryUcTExNjToZXrlxJt27dOHr0KADTpk3DwcGB7Nmz0759eyIiInj27Bne3t5ERkbi7e1tydBFRD649y304u7uztChQylWrBheXl4cPXoUW1tbIiMjCQwMxMPDg2fPnhEcHIytrS1Go9ECkYtYFyXEIklU8eLF2b9/P7ly5aJgwYIcOXKEL774wtJhiZWKuyzS4cOH2blzJ8HBwfj5+RESEkLhwoUZOXIkjx8/Jl++fFSqVAkPDw8ePHjA/v371fATEasT+4BwyZIlnDt3zry9RIkSDBw4kBIlStCmTRt++eUXHB0dKVOmDPXr1yc4OFhrr4uZwZC4XgmR1iEWSeJie+20dIN8Cv369WPz5s3Uq1ePR48esWnTJmrXrs2QIUMoXrw4jx8/Zu7cuTg6OpIxY0Zat26Nra0t0dHRmtsuIlbn+vXrtGrVCqPRyLJlyyhQoIB5X3BwMG3btsXBwYGgoCDKly9v3mc0GpUMJ3Gx6xDfepC41iHOkSnhrUOshFhERD6Jw4cP06BBAzZt2kTZsmUBWLt2LWPHjiV//vwMGTKEEiVKvHOeGn4iYi3i1lGItWXLFubOncuzZ89YuHAhBQsWNO+rWbMmFy9epHTp0qxZs+a950vSpIT4w9HjdhER+SjiDpOGt8WzbG1tcXR0NG9r0qQJRqORVq1aYWdnR58+fShTpgzw/xuOSoZFxBrEvSeGh4cTHh6Oq6srderUwcXFBV9fXzp06MCyZcvInTs3L1++JEOGDHTv3h1PT08AJcMiH4HmEIuIyEcR2/AbPHgwgYGBvH79GqPRaK4uHRUVBUDz5s0pWLAg586dY9GiReb9aviJiLWImwx///33eHh4ULJkSVq1asXhw4epUqUKQ4cOJXny5JQtW5Z+/fpRvXp1rl27hoeHBwaDgZiYGAu/C0mIDInsT0KkhFhERD6ouDNxDhw4QGBgIG5ublSsWJGGDRvSvn17zpw5Y65o/ueff1KyZEm8vLxYvXo1p06dslToIiIfRWwyPGLECKZOnUrt2rUZOHAg586dY9CgQaxdu5ZKlSoxbdo02rZty9mzZylUqBA///wzNjY274y4EZEPR3OIRUTkowgICMBoNPLq1SsGDx4MwMuXL2nfvj07d+5k8ODBpEyZks2bNxMVFcWBAwcoUaIEX331FQEBARaOXkTkwzGZTNy+fZvatWszbtw4GjRoAMCTJ0/o0KEDDx8+ZNWqVeTMmROA169f4+LiAqCigvJesXOIbz94lqDm4/47oaGhZM+UJsHNIdajJhER+eCeP3/OwoUL6dWrFzdu3DBvT5EiBWvXrqVfv35s27aNBQsW4OLiwq5duwBwdHSMV2VVRMQaGAwG7OzsCAsLMye3b968IW3atCxZsoRr166xatUq8/GxybDJZFIyLP+WpZdRsoZll5QQi4jIB5c6dWqWL19OvXr1+PHHH7l8+TLwtmK0wWBgzJgx7Ny5k+PHj7N582acnJwYPnw4t27dMhePERFJrN43ADM2yQ0ODgbeFhqMiooiVapUfPXVVzx58uSdc1RLQeTjU0IsIiL/k78WejEajQDky5ePKVOmUKBAAapXr87du3fNawrD295iJycnLl++TOfOnQkKCmLr1q3kzZv3k78HEZEPJSYmxpzI3r59m4iICCIiIkiTJg1jx45l2rRpzJw5EwB7e3uMRiP379/H1dXVkmGLJFmaQywiIv+1uIVe5s2bx8mTJ3n58iUtWrSgbt26ANy4cYN27dpx584dgoODyZIlS7y1NJ8/f87JkyfJnTs3uXPntth7ERH5kIYPH86GDRsAaNmyJW3btiVbtmyMHz+e4cOH06BBA9KlS8eVK1d4+PAhv/76q4ZHy98WO4f4zsPENYc4W0bNIRYRESthMpniLa00ZswYoqOjSZ8+PfXr1ycgIACTyUSuXLlYsmQJOXPmJG/evDx+/DjeMMDUqVNTtWpVJcMiYjXWrVvHkiVLGDVqFF9//TU7duxg0KBB3Llzh2HDhrFz506MRiPPnz/n888/NyfDsSNsRP4uQyJ7JUTqIRYRkX8kICCAsmXLUqxYMQCWLl3KiBEjWLt2LaVKlWLXrl3UqlXLPFd46NChGAwGrly5wvTp05k5cya2trYWfhciIh/OX5dFWr58OQ8ePGDAgAEAzJ8/n6VLl5IlSxbGjRtHnjx5iIqKMi8/B6omLf9MbA/x3UTWQ5w1AfYQ67dORET+ths3bjBhwgRq165Nr169KFy4MC9evGDQoEGUKlWKbdu20bJlS+bNm8erV6/o378/qVKlolu3buTLl485c+YAb+cZKykWEWsQd7TM/PnzuX//PpcvX6ZMmTLmY3x8fDAYDCxdupThw4czYsQIChYsGO8aSoZFLEM9xCIi8o+EhITQqVMnihcvzpAhQ0iTJg3Pnj3D3t4eT09P2rdvT58+fQgJCaFs2bJERkaycOFCvLy8LB26iMgHFbdnePDgwQQGBpI3b16uXbtGqlSp2LdvX7zpIIsWLWLKlCk0btyY0aNHWypssQLqIf5wNIdYRET+ETc3N+bNm8epU6eYMGECjx8/Jnfu3Ny7d4+YmBhq1aoFgLOzM507d2bTpk20bt3awlGLiHx4scnwvXv3iIiIYN++ffzyyy8sWrSIXLly0b59+3hrsbdv3x5fX19GjBhhqZDF2lh6UrAVTCJWQiwiIv+Ym5sbCxYsICQkhMmTJ3Pp0iWSJUvG+fPnOXHiBOfOnWPAgAHcvHmTunXrYmdnZ15uSUTEmqxatYo8efJw6NAh0qVLB0C9evXo06cP9vb2eHl5xUuKPT09sbW1VQEtkQRCCbGIiPxX3NzcmD9/PqdOnWLKlCm4uLjw/fff065dO+rWrcv9+/dZu3YtoPlxImK9smbNSvXq1bl06RKRkZHm7XXr1qV37944OTnh4eHBH3/8Ee881VEQSRjUOhERkf9abE9xhw4dmDRpEkOGDKFJkyY8fPiQr776CltbW1VOFRGr8ddq0gDly5fH3t6eZ8+eUb16dQ4dOkTWrFkBqFOnDuHh4Rw5coQMGTJYImSxcob/+5MYJNQ4VVRLRET+Z7GFtnLkyIGfn5+5Mahq0iJiLeImw7/99hv29vaYTCYKFSoEwPHjxxkyZAh3797lp59+Mt8H49I9UT6U2KJa9x49T1AFqv6d0NBQsmRIraJaIiJifdzc3Jg9ezYpUqQgc+bM5u1q+ImINYi7tNLIkSNp3rw5tWrVol69egQFBQFQunRpJkyYQPbs2alatSq3bt165zq6J4okPEqIRUTkg/jqq69YuHAhNjY2xMTEWDocEZEPxmB4O9Rz9OjRBAQE4O/vz759+/j666/p3Lkz06dPB6BMmTKMHz8eR0dHBg0aZMmQReRv0qQuERH5YAwGQ7yeFBERaxESEsLBgwdZuXIlVapUYdu2bWzatIl69erRv39/bGxs6N27N6VLl2blypXmodQiH5PB8PaVGCTUONViERGRD8qQUD/xRET+gb+OdMmUKRM1a9akfPny7N+/n44dO/L999+zcuVKatWqRd++fRk7diwAhQsXxsbGRksriSQCSohFRERERP4idqTL6dOnCQ0N5bPPPqNr1644OjqyevVq6tati7e3N87OzuTOnZvSpUuzd+9e4tar1ZxhkYRPCbGIiIiIyHts3bqVhg0bsnTpUsLCwkiePDmvX7/m9OnTODo64uDgQHh4OPfu3WPIkCEcOHDAPHVE5FMwJLJXQqQ5xCIiIiIi7+Hp6cmaNWtYvHgxNjY2tG3bluTJk9OoUSOGDh1KaGgo58+fJyoqCg8PD+BtRWpNHRFJPNRDLCIiIiJJXtxe3bh/X7p0KUWLFiUoKIglS5YQHh5O9+7d8fX15fHjx3z55ZecOHECW1tbjEajkmGRRMZg0pgOEREREREAFi1ahJOTE40bN8be3t683cvLi4MHDzJ48GDatGmDs7MzkZGRODo6AhAdHY2dnQZfyqcRGhpKqlSp+OPxc1KmTGnpcP6W0NBQPkufmhcvXiSomPVbKyIiIiJJVuwQ55iYGGJiYpgzZw7R0dE4Ozvj4eFhTooXL15MyZIl8ff359mzZ/Ts2RMXFxfzNZQMi0Uk5Mm5f5VA49SQaRERERFJkuLO97179y52dnYcOHCADBkyMG7cOLZs2cKbN2/MxxcpUoTQ0FCuX7+Os7OzebuGSYskXkqIRURERCTJiYmJMSeyW7ZsoWXLlhw9ehQXFxc2btxI6tSp+f7779m8eTOvX78G3ia+K1asICAgQNWkRayE5hCLiIiISJISExNjXmd49+7drFixgh9//BF3d3dGjhxJmTJleP36NU2aNOH+/fs4OTlhMBh4/vw5v/32G7a2tvGuIfKpxc4hfvBnwpqP+++EhoaSKV2qBDeHWL/FIiIiIpKkxCay/fv3p0ePHqRLlw4PDw/OnDnD6NGjCQ4OxsXFhfXr1+Pl5UXp0qUpU6YMZ8+eVTIsYmXUQywiIiIiSc6JEydo0KABq1atokKFCgCsXr2auXPn4ujoyNixYylVqtQ756matCQE6iH+cPRoS0RERESsXkxMTLyvTSYTYWFh8ZZWatasGd7e3vz888989913HDt27J3zlQyLfFpz5swhV65cODk5UaJECQ4dOvRBr6+EWERERESsWtwhzhs2bODWrVu4urqSIUMGbty4YT4GoE2bNhQoUIBnz54xbtw4c1KsIdKSEBkMiev1T61evZo+ffowbNgwQkJCKF++PLVq1eL27dsf7N9Qv9kiIiIiYrVMJpM5mR06dCi9evViy5Yt5MuXD3d3d/r27cuRI0fMFacfPnxI/vz5adGiBdHR0UyYMIHg4GBLvgWRJGvatGl06NABHx8fChUqhJ+fH9myZSMgIOCDfQ+N+RARERERqxWb6I4dO5agoCC2b99Ovnz5AFiyZAnNmjWjUaNGtG3blowZM7J161ZiYmLo27cvBQsWZPTo0fj7+1OyZEmcnJws+VZE3hEaGmrpEP622Fj/GrOjoyOOjo7vHP/mzRtOnTrF4MGD422vXr06R44c+WBxKSEWEREREav29OlTDh48iJ+fH6VKleLevXuEhITwww8/0KhRI2xsbLhw4QK7d+8mZ86crFq1CoBatWoBULhwYSXDkqA4ODiQKVMm8uXKZulQ/pHkyZOTLVv8mEeOHMmoUaPeOfbPP//EaDSSMWPGeNszZszIgwcPPlhMSohFRERExKoZDAYuXLjAxYsXOXjwIHPmzOHGjRsYjUa2bdvG8OHD8fb2Jjw8nBQpUmAwGIiMjMTR0dGcFIskJE5OTty4cYM3b95YOpR/xGQymUdtxHpf73Bcfz3+fdf4XyghFhERERGrliZNGsaMGcO3337LzJkz6dKlCz4+PlStWpVWrVpx5MgROnfubK44HRMT8x8b6SKW5uTkZNUjF9KlS4etre07vcGPHj16p9f4f6GEWERERESsXocOHahWrRqRkZHmOcQxMTE8fPiQMmXKxDtWFaVFLM/BwYESJUqwZ88eGjRoYN6+Z88e6tWr98G+j8FkMpk+2NVERERERBK4V69ecebMGXx9fbl16xanT5/W+sIiCdDq1atp06YNc+fOxd3dnXnz5hEUFMT58+fJkSPHB/ke+s0XERERkSTDZDJx8uRJpk6dSlRUFKdOncLOzg6j0Yitra2lwxOROJo1a8aTJ08YM2YMf/zxB0WKFGH79u0fLBkG9RCLiIiISBITGRnJhQsXKFasGDY2NkRHR6uHWCSJUkIsIiIiIklWTEyM5gyLJGFKiEVERERERCRJ0uMwERERERERSZKUEIuIiIiIiEiSpIRYREREREREkiQlxCIiIiIiIpIkKSEWERERERGRJEkJsYiIiIiIiCRJSohFRESs0KhRoyhevLj5ay8vL+rXr//J47h58yYGg4EzZ858tO/x1/f63/gUcYqISMKjhFhEROQT8fLywmAwYDAYsLe3J3fu3AwYMICwsLCP/r1nzJjB4sWL/9axnzo5rFSpEn369Pkk30tERCQuO0sHICIikpTUrFmTRYsWERUVxaFDh/Dx8SEsLIyAgIB3jo2KisLe3v6DfN9UqVJ9kOuIiIhYE/UQi4iIfEKOjo5kypSJbNmy0bJlS1q1asWmTZuA/z/0d+HCheTOnRtHR0dMJhMvXrygU6dOZMiQgZQpU1K5cmV+/fXXeNedOHEiGTNmJEWKFHTo0IGIiIh4+/86ZDomJgZfX1/y5s2Lo6Mj2bNnZ/z48QDkypULADc3NwwGA5UqVTKft2jRIgoVKoSTkxMFCxZkzpw58b7PiRMncHNzw8nJiZIlSxISEvI//5sNGjSI/Pnz4+LiQu7cuRk+fDhRUVHvHBcYGEi2bNlwcXGhSZMmPH/+PN7+/xS7iIgkPeohFhERsSBnZ+d4yd3Vq1dZs2YN69evx9bWFgAPDw9cXV3Zvn07qVKlIjAwkCpVqnD58mVcXV1Zs2YNI0eOZPbs2ZQvX55ly5bh7+9P7ty5/+X3HTJkCEFBQUyfPp1y5crxxx9/cOnSJeBtUvvVV1+xd+9eChcujIODAwBBQUGMHDmSWbNm4ebmRkhICB07diRZsmS0a9eOsLAwPD09qVy5MsuXL+fGjRv07t37f/43SpEiBYsXLyZz5sz89ttvdOzYkRQpUjBw4MB3/t22bNlCaGgoHTp0oHv37qxYseJvxS4iIkmUSURERD6Jdu3amerVq2f++vjx46a0adOamjZtajKZTKaRI0ea7O3tTY8ePTIfs2/fPlPKlClNERER8a6VJ08eU2BgoMlkMpnc3d1NXbp0ibe/dOnSpmLFir33e4eGhpocHR1NQUFB743zxo0bJsAUEhISb3u2bNlMK1eujLdt7NixJnd3d5PJZDIFBgaaXF1dTWFhYeb9AQEB771WXBUrVjT17t37X+7/q0mTJplKlChh/nrkyJEmW1tb0507d8zbduzYYbKxsTH98ccffyv2f/WeRUTEuqmHWERE5BPaunUryZMnJzo6mqioKOrVq8fMmTPN+3PkyEH69OnNX586dYpXr16RNm3aeNcJDw/n2rVrAFy8eJEuXbrE2+/u7s7+/fvfG8PFixeJjIykSpUqfzvux48fc+fOHTp06EDHjh3N26Ojo83zky9evEixYsVwcXGJF8f/at26dfj5+XH16lVevXpFdHQ0KVOmjHdM9uzZyZo1a7zvGxMTw++//46tre1/jF1ERJImJcQiIiKf0DfffENAQAD29vZkzpz5naJZyZIli/d1TEwMn332GT///PM710qdOvV/FYOzs/M/PicmJgZ4O/S4dOnS8fbFDu02mUz/VTz/zrFjx2jevDmjR4+mRo0apEqVih9++IGpU6f+2/MMBoP5v38ndhERSZqUEIuIiHxCyZIlI2/evH/7+C+//JIHDx5gZ2dHzpw533tMoUKFOHbsGG3btjVvO3bs2L+8Zr58+XB2dmbfvn34+Pi8sz92zrDRaDRvy5gxI1myZOH69eu0atXqvdf9/PPPWbZsGeHh4eak+9/F8XccPnyYHDlyMGzYMPO2W7duvXPc7du3uX//PpkzZwbg6NGj2NjYkD9//r8Vu4iIJE1KiEVERBKwqlWr4u7uTv369fH19aVAgQLcv3+f7du3U79+fUqWLEnv3r1p164dJUuWpFy5cqxYsYLz58//y6JaTk5ODBo0iIEDB+Lg4MDXX3/N48ePOX/+PB06dCBDhgw4Ozuzc+dOsmbNipOTE6lSpWLUqFH06tWLlClTUqtWLSIjIzl58iTPnj2jX79+tGzZkmHDhtGhQwe+++47bt68yZQpU/7W+3z8+PE76x5nypSJvHnzcvv2bX744QdKlSrFtm3b2Lhx43vfU7t27ZgyZQqhoaH06tWLpk2bkilTJoD/GLuIiCRNWnZJREQkATMYDGzfvp0KFSrg7e1N/vz5ad68OTdv3iRjxowANGvWjBEjRjBo0CBKlCjBrVu36Nq167+97vDhw+nfvz8jRoygUKFCNGvWjEePHgFgZ2eHv78/gYGBZM6cmXr16gHg4+PD/PnzWbx4MUWLFqVixYosXrzYvExT8uTJ2bJlCxcuXMDNzY1hw4bh6+v7t97nypUrcXNzi/eaO3cu9erVo2/fvvTo0YPixYtz5MgRhg8f/s75efPmpWHDhtSuXZvq1atTpEiReMsq/afYRUQkaTKYPsaEHxEREREREZEETj3EIiIiIiIikiQpIRYREREREZEkSQmxiIiIiIiIJElKiEVERERERCRJUkIsIiIiIiIiSZISYhEREREREUmSlBCLiIiIiIhIkqSEWERERERERJIkJcQiIiIiIiKSJCkhFhERERERkSRJCbGIiIiIiIgkSf8P8MDROlJ/t/AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "target_names = ['adenocarcinoma', 'large-cell-carcinoma', 'normal', 'squamous-cell-carcinoma']\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_gen.classes, y_pred)\n",
    "plot_confusion_matrix(cm= cm, classes= target_names, title = 'Confusion Matrix')\n",
    "# Classification report\n",
    "print(classification_report(test_gen.classes, y_pred, target_names= target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90338dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
